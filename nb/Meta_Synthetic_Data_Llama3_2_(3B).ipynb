{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devigget/Story/blob/main/nb/Meta_Synthetic_Data_Llama3_2_(3B).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSNC5xPCZhkT"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "\n",
        "\n",
        "<a href=\"https://github.com/meta-llama/synthetic-data-kit\"><img src=\"https://raw.githubusercontent.com/unslothai/notebooks/refs/heads/main/assets/meta%20round%20logo.png\" width=\"137\"></a>\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
        "</div>\n",
        "\n",
        "To install Unsloth your local device, follow [our guide](https://docs.unsloth.ai/get-started/install-and-update). This notebook is licensed [LGPL-3.0](https://github.com/unslothai/notebooks?tab=LGPL-3.0-1-ov-file#readme).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om2qjxs5PSr0"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCa86oMuPSr0"
      },
      "source": [
        "\n",
        "Introducing FP8 precision training for faster RL inference. [Read Blog](https://docs.unsloth.ai/new/fp8-reinforcement-learning).\n",
        "\n",
        "Unsloth's [Docker image](https://hub.docker.com/r/unsloth/unsloth) is here! Start training with no setup & environment issues. [Read our Guide](https://docs.unsloth.ai/new/how-to-train-llms-with-unsloth-and-docker).\n",
        "\n",
        "[gpt-oss RL](https://docs.unsloth.ai/new/gpt-oss-reinforcement-learning) is now supported with the fastest inference & lowest VRAM. Try our [new notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-GRPO.ipynb) which creates kernels!\n",
        "\n",
        "Introducing [Vision](https://docs.unsloth.ai/new/vision-reinforcement-learning-vlm-rl) and [Standby](https://docs.unsloth.ai/basics/memory-efficient-rl) for RL! Train Qwen, Gemma etc. VLMs with GSPO - even faster with less VRAM.\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imwJhjjYPSr0"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "HuBm__L6ZhkY"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "!pip install --upgrade -qqq uv\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    # If you're not in Colab, just use pip install!\n",
        "    !pip install unsloth vllm synthetic-data-kit==0.0.3\n",
        "else:\n",
        "    try: import numpy, PIL; get_numpy = f\"numpy=={numpy.__version__}\"; get_pil = f\"pillow=={PIL.__version__}\"\n",
        "    except: get_numpy = \"numpy\"; get_pil = \"pillow\"\n",
        "    try: import subprocess; is_t4 = \"Tesla T4\" in str(subprocess.check_output([\"nvidia-smi\"]))\n",
        "    except: is_t4 = False\n",
        "    get_vllm, get_triton = (\"vllm==0.9.2\", \"triton==3.2.0\") if is_t4 else (\"vllm==0.10.2\", \"triton\")\n",
        "    !uv pip install -qqq --upgrade         unsloth {get_vllm} {get_numpy} {get_pil} torchvision bitsandbytes xformers\n",
        "    !uv pip install -qqq {get_triton}\n",
        "    !uv pip install synthetic-data-kit==0.0.3 pdfminer.six\n",
        "!uv pip install transformers==4.56.2\n",
        "!uv pip install --no-deps trl==0.22.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "2KKps1I_ZhkZ",
        "outputId": "1ae50e12-ed8f-4a60-e877-d4beb976109d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3533987637.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install --upgrade -qqq uv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"COLAB_\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# If you're not in Colab, just use pip install!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install unsloth vllm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    957\u001b[0m     opt_names = {\n\u001b[1;32m    958\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodulename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     }\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/importlib_metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    605\u001b[0m             make_files(\n\u001b[1;32m    606\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/importlib_metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/importlib_metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/importlib_metadata/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \"\"\"\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \"\"\"\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#@title Colab Extra Install { display-mode: \"form\" }\n",
        "%%capture\n",
        "import os\n",
        "!pip install --upgrade -qqq uv\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    # If you're not in Colab, just use pip install!\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    try: import numpy, PIL; get_numpy = f\"numpy=={numpy.__version__}\"; get_pil = f\"pillow=={PIL.__version__}\"\n",
        "    except: get_numpy = \"numpy\"; get_pil = \"pillow\"\n",
        "    try: import subprocess; is_t4 = \"Tesla T4\" in str(subprocess.check_output([\"nvidia-smi\"]))\n",
        "    except: is_t4 = False\n",
        "    get_vllm, get_triton = (\"vllm==0.9.2\", \"triton==3.2.0\") if is_t4 else (\"vllm==0.10.2\", \"triton\")\n",
        "    !uv pip install -qqq --upgrade \\\n",
        "        unsloth {get_vllm} {get_numpy} {get_pil} torchvision bitsandbytes xformers\n",
        "    !uv pip install -qqq {get_triton}\n",
        "!uv pip install transformers==4.56.2\n",
        "!uv pip install --no-deps trl==0.22.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6emn-0pZhkZ"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLQBQSn0Zhka"
      },
      "source": [
        "## Primary Goal\n",
        "Our goal is to make Llama 3.2 3B understand the \"Byte Latent Transformer: Patches Scale Better Than Tokens\" [research paper](https://ai.meta.com/research/publications/byte-latent-transformer-patches-scale-better-than-tokens/) that was published in December 2024.\n",
        "\n",
        "We'll use https://github.com/meta-llama/synthetic-data-kit to generate question and answer pairs **fully locally** which will be used for finetuning Llama 3.2 3B!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym8UA1PRiXsa",
        "outputId": "bf05f799-4f55-490d-a518-ae7aa460762e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 12-14 04:36:58 [vllm_utils.py:702] Unsloth: Patching vLLM v1 graph capture\n",
            "INFO 12-14 04:36:58 [vllm_utils.py:732] Unsloth: Patching vLLM v0 graph capture\n",
            "Unsloth: Using dtype = torch.float16 for vLLM.\n",
            "Unsloth: vLLM loading unsloth/Llama-3.2-3B-Instruct with actual GPU utilization = 72.17%\n",
            "Unsloth: Your GPU has CUDA compute capability 7.5 with VRAM = 14.74 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 2048. Num Sequences = 32.\n",
            "Unsloth: vLLM's KV Cache can use up to 4.65 GB. Also swap space = 0 GB.\n",
            "Unsloth: `cudagraph_mode` is not in `from vllm.config import CompilationConfig`\n",
            "Unsloth: Disabling `disable_cascade_attn` in vLLM to allow for better on policy RL!\n",
            "vLLM STDOUT: INFO 12-14 04:37:32 [__init__.py:244] Automatically detected platform cuda.\n",
            "vLLM STDOUT: INFO 12-14 04:37:39 [api_server.py:1395] vLLM API server version 0.9.2\n",
            "vLLM STDOUT: INFO 12-14 04:37:39 [cli_args.py:325] non-default args: {'model': 'unsloth/Llama-3.2-3B-Instruct', 'dtype': 'float16', 'seed': 0, 'max_model_len': 2048, 'max_logprobs': 0, 'disable_cascade_attn': True, 'gpu_memory_utilization': 0.7216738917112797, 'swap_space': 0.0, 'enable_prefix_caching': True, 'max_num_batched_tokens': 4096, 'max_num_seqs': 32, 'enable_chunked_prefill': True, 'disable_log_stats': True}\n",
            "vLLM STDOUT: INFO 12-14 04:38:14 [config.py:841] This model supports multiple tasks: {'embed', 'reward', 'generate', 'classify'}. Defaulting to 'generate'.\n",
            "vLLM STDOUT: WARNING 12-14 04:38:14 [config.py:3371] Casting torch.bfloat16 to torch.float16.\n",
            "vLLM STDOUT: INFO 12-14 04:38:14 [config.py:1472] Using max model len 2048\n",
            "vLLM STDOUT: WARNING 12-14 04:38:14 [arg_utils.py:1735] Compute Capability < 8.0 is not supported by the V1 Engine. Falling back to V0. \n",
            "vLLM STDOUT: INFO 12-14 04:38:18 [config.py:2285] Chunked prefill is enabled with max_num_batched_tokens=4096.\n",
            "vLLM STDOUT: INFO 12-14 04:38:18 [api_server.py:268] Started engine process with PID 13366\n",
            "vLLM STDOUT: INFO 12-14 04:38:46 [__init__.py:244] Automatically detected platform cuda.\n",
            "vLLM STDOUT: INFO 12-14 04:38:47 [llm_engine.py:230] Initializing a V0 LLM engine (v0.9.2) with config: model='unsloth/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='unsloth/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/Llama-3.2-3B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":32,\"local_cache_dir\":null}, use_cached_outputs=True, \n",
            "vLLM STDOUT: INFO 12-14 04:38:49 [cuda.py:311] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "vLLM STDOUT: INFO 12-14 04:38:49 [cuda.py:360] Using XFormers backend.\n",
            "vLLM STDOUT: INFO 12-14 04:38:49 [parallel_state.py:1076] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
            "vLLM STDOUT: INFO 12-14 04:38:49 [model_runner.py:1171] Starting to load model unsloth/Llama-3.2-3B-Instruct...\n",
            "vLLM STDOUT: INFO 12-14 04:38:50 [weight_utils.py:292] Using model weights format ['*.safetensors']\n",
            "vLLM STDOUT: INFO 12-14 04:39:17 [default_loader.py:272] Loading weights took 25.86 seconds\n",
            "vLLM STDOUT: INFO 12-14 04:39:18 [model_runner.py:1203] Model loading took 6.0160 GiB and 26.713347 seconds\n",
            "vLLM STDOUT: INFO 12-14 04:39:20 [worker.py:294] Memory profiling takes 1.86 seconds\n",
            "vLLM STDOUT: INFO 12-14 04:39:20 [worker.py:294] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.72) = 10.64GiB\n",
            "vLLM STDOUT: INFO 12-14 04:39:20 [worker.py:294] model weights take 6.02GiB; non_torch_memory takes 0.05GiB; PyTorch activation peak memory takes 0.27GiB; the rest of the memory reserved for KV Cache is 4.31GiB.\n",
            "vLLM STDOUT: INFO 12-14 04:39:20 [executor_base.py:113] # cuda blocks: 2521, # CPU blocks: 0\n",
            "vLLM STDOUT: INFO 12-14 04:39:20 [executor_base.py:118] Maximum concurrency for 2048 tokens per request: 19.70x\n",
            "vLLM STDOUT: INFO 12-14 04:39:20 [model_runner.py:1513] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
            "vLLM STDOUT: INFO 12-14 04:39:27 [model_runner.py:1671] Graph capturing finished in 7 secs, took 0.06 GiB\n",
            "vLLM STDOUT: INFO 12-14 04:39:27 [llm_engine.py:428] init engine (profile, create kv cache, warmup model) took 9.74 seconds\n",
            "vLLM STDOUT: WARNING 12-14 04:39:28 [config.py:1392] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [serving_chat.py:125] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.9}\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [serving_completion.py:72] Using default completion sampling params from model: {'temperature': 0.6, 'top_p': 0.9}\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [api_server.py:1457] Starting vLLM API server 0 on http://0.0.0.0:8000\n",
            "vLLM Server Ready Detected\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:29] Available routes are:\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /openapi.json, Methods: HEAD, GET\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /docs, Methods: HEAD, GET\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /docs/oauth2-redirect, Methods: HEAD, GET\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /redoc, Methods: HEAD, GET\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /health, Methods: GET\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /load, Methods: GET\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /ping, Methods: POST\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /ping, Methods: GET\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /tokenize, Methods: POST\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /detokenize, Methods: POST\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /v1/models, Methods: GET\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /version, Methods: GET\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /v1/chat/completions, Methods: POST\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /v1/completions, Methods: POST\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /v1/embeddings, Methods: POST\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /pooling, Methods: POST\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /classify, Methods: POST\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /score, Methods: POST\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /v1/score, Methods: POST\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /v1/audio/transcriptions, Methods: POST\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /v1/audio/translations, Methods: POST\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /rerank, Methods: POST\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /v1/rerank, Methods: POST\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /v2/rerank, Methods: POST\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /invocations, Methods: POST\n",
            "vLLM STDOUT: INFO 12-14 04:39:28 [launcher.py:37] Route: /metrics, Methods: GET\n",
            "vLLM STDOUT: INFO:     127.0.0.1:35432 - \"GET /metrics HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "from unsloth.dataprep import SyntheticDataKit\n",
        "\n",
        "generator = SyntheticDataKit.from_pretrained(\n",
        "    # Choose any model from https://huggingface.co/unsloth\n",
        "    model_name = \"unsloth/Llama-3.2-3B-Instruct\",\n",
        "    max_seq_length = 2048, # Longer sequence lengths will be slower!\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef_MnK575tr2"
      },
      "source": [
        "## Generate QA Pairs + Auto clean data\n",
        "We now use synthetic data kit for question answer pair generation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "q487TNby-nwT"
      },
      "outputs": [],
      "source": [
        "generator.prepare_qa_generation(\n",
        "    output_folder = \"data\", # Output location of synthetic data\n",
        "    temperature = 0.7, # Higher temp makes more diverse datases\n",
        "    top_p = 0.95,\n",
        "    overlap = 64, # Overlap portion during chunking\n",
        "    max_generation_tokens = 512, # Can increase for longer QA pairs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV7DyufR51IN"
      },
      "source": [
        "Check if it succeeded:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2gQZcr_Wp94",
        "outputId": "90d392f2-dbc2-4e17-d45a-b37d88fa98c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vLLM STDOUT: INFO:     127.0.0.1:38518 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "\u001b[?25l\u001b[32m VLLM server is running at \u001b[0m\u001b[4;94mhttp://localhost:8000/v1\u001b[0m\n",
            "\u001b[32m‚†ã\u001b[0m\u001b[32m Checking VLLM server at http://localhost:8000/v1...\u001b[0m\r\u001b[2KAvailable models: \u001b[1m{\u001b[0m\u001b[32m'object'\u001b[0m: \u001b[32m'list'\u001b[0m, \u001b[32m'data'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \n",
            "\u001b[32m'unsloth/Llama-3.2-3B-Instruct'\u001b[0m, \u001b[32m'object'\u001b[0m: \u001b[32m'model'\u001b[0m, \u001b[32m'created'\u001b[0m: \u001b[1;36m1765687177\u001b[0m, \n",
            "\u001b[32m'owned_by'\u001b[0m: \u001b[32m'vllm'\u001b[0m, \u001b[32m'root'\u001b[0m: \u001b[32m'unsloth/Llama-3.2-3B-Instruct'\u001b[0m, \u001b[32m'parent'\u001b[0m: \u001b[3;35mNone\u001b[0m, \n",
            "\u001b[32m'max_model_len'\u001b[0m: \u001b[1;36m2048\u001b[0m, \u001b[32m'permission'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \n",
            "\u001b[32m'modelperm-b7e301ec47054a26a27e6061a6b9e01c'\u001b[0m, \u001b[32m'object'\u001b[0m: \u001b[32m'model_permission'\u001b[0m, \n",
            "\u001b[32m'created'\u001b[0m: \u001b[1;36m1765687177\u001b[0m, \u001b[32m'allow_create_engine'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'allow_sampling'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \n",
            "\u001b[32m'allow_logprobs'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'allow_search_indices'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'allow_view'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \n",
            "\u001b[32m'allow_fine_tuning'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'organization'\u001b[0m: \u001b[32m'*'\u001b[0m, \u001b[32m'group'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'is_blocking'\u001b[0m: \n",
            "\u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\n",
            "\u001b[32m‚†ã\u001b[0m Checking VLLM server at http://localhost:8000/v1...\r\u001b[2K\u001b[32m‚†ã\u001b[0m Checking VLLM server at http://localhost:8000/v1...\n",
            "\u001b[?25h\r\u001b[1A\u001b[2K"
          ]
        }
      ],
      "source": [
        "!synthetic-data-kit system-check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdl7aPFK55M1"
      },
      "source": [
        "## Document Parsing (PDF, CSV, HTML etc.)\n",
        "Now, let's take the Byte Latent Transformer: Patches Scale Better Than Tokens research paper found at https://arxiv.org/abs/2412.09871 and covert it to Q&A pairs in order to finetune Llama 3.2!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BN1yrPGmANA",
        "outputId": "f7fe3f30-43e1-4dd6-a454-c09e45bbae38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-14 04:39:57--  https://igfgjjwlastnmrmmxpsg.supabase.co/storage/v1/object/public/test/ilovepdf_merged.pdf\n",
            "Resolving igfgjjwlastnmrmmxpsg.supabase.co (igfgjjwlastnmrmmxpsg.supabase.co)... 172.64.149.246, 104.18.38.10\n",
            "Connecting to igfgjjwlastnmrmmxpsg.supabase.co (igfgjjwlastnmrmmxpsg.supabase.co)|172.64.149.246|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Cookie coming from igfgjjwlastnmrmmxpsg.supabase.co attempted to set domain to supabase.co\n",
            "Length: 998116 (975K) [application/pdf]\n",
            "Saving to: ‚Äòilovepdf_merged.pdf‚Äô\n",
            "\n",
            "ilovepdf_merged.pdf 100%[===================>] 974.72K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-12-14 04:39:58 (35.1 MB/s) - ‚Äòilovepdf_merged.pdf‚Äô saved [998116/998116]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text extracted and saved to data/output2/ilovepdf_merged.txt\n",
            "41 ['data/output2/ilovepdf_merged_0.txt', 'data/output2/ilovepdf_merged_1.txt', 'data/output2/ilovepdf_merged_2.txt']\n"
          ]
        }
      ],
      "source": [
        "# Byte Latent Transformer: Patches Scale Better Than Tokens paper in HTML format\n",
        "import os\n",
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "pdf_url = \"https://igfgjjwlastnmrmmxpsg.supabase.co/storage/v1/object/public/test/ilovepdf_merged.pdf\"\n",
        "pdf_filename = \"ilovepdf_merged.pdf\"\n",
        "output_dir = \"data/output2\"\n",
        "output_txt_filename = os.path.join(output_dir, \"ilovepdf_merged.txt\")\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Download the PDF file\n",
        "!wget -O {pdf_filename} {pdf_url}\n",
        "\n",
        "# Extract text from PDF\n",
        "try:\n",
        "    extracted_text = extract_text(pdf_filename)\n",
        "except Exception as e:\n",
        "    print(f\"Error extracting text from PDF: {e}\")\n",
        "    extracted_text = \"\"\n",
        "\n",
        "# Save extracted text to a file\n",
        "with open(output_txt_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(extracted_text)\n",
        "\n",
        "print(f\"Text extracted and saved to {output_txt_filename}\")\n",
        "\n",
        "# Truncate document\n",
        "filenames = generator.chunk_data(output_txt_filename)\n",
        "print(len(filenames), filenames[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGdAXafV6S2M"
      },
      "source": [
        "We see around 37 chunks of data. We now call synthetic-data-kit to create some pairs of data for 3 of our chunks.\n",
        "\n",
        "You can process more chunks, but it'll be much slower!\n",
        "\n",
        "Using `--num-pairs` will generate **approximately** that many QA pairs. However it might be shorter or longer depending on the `max_seq_length` of the loaded up model. So if you specify 100, you might only get 10 since the model's max sequence length is capped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYYYlMJ7ZtT7",
        "outputId": "5bd89b50-88c6-4ee2-e51b-75bf6d622f8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vLLM STDOUT: INFO:     127.0.0.1:32804 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:32808 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:53:25 [logger.py:43] Received request chatcmpl-b1a9f0c07b5e41829cafcc1b56866dcb: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nüìù Extracted Text from Charge Sheets \\n\\nHere is the extracted text from the provided PDF, segmented by page for clarity. \\n\\nPage 1 \\n\\nSCCORE NO 400. 1Agaciam P3-75/21 2FINAL FORM/REPORT 3863 404/02/22 5 (Under \\nSection 173 Cr. P.C.) 6IN THE COURT OF THE DISTRICT SESSION JUDGE, AT 7PANAJI-GOA. 8 \\n1.District: N-Goa P.S. Agacaim Year: 2022 9FIR No.79/2021 10Date: 11.12.2021 113)Date: \\n4.02.2022. 12Sections:- 363, 376. 13Sections:- 4. 14 \\n2. Charge Sheet No. 08/2022. 15 \\n4. (i) Act :- IPC 16 (ii) Act:-POCSO Act, 2012 17 (iii) Act:-Sections: - 18 (iv) Other Acts & \\nSections: 19 \\n5. Type of final Form/Report; Charge sheet/Not Charge Sheeted for want of evidence/FR True, \\nUndetected true, Untraced/FR true, offence abated/FR Unoccurred. 20Charge sheet (Tick '' \\napplicable portion). 21 \\nPage 2 \\n\\n6.  If FR Unoccurred: False/Mistake of fact/mistake of law/Non cognizable/Civil Nature.N. A. \\n\\n(Tick '‚àö' applicable portion). 22 \\n\\n7.  If Charge sheet: Original/Supplementary. - Original. 23 (Tick'' applicable portion). 24 \\n\\n8.  Name of I.O.: Shri. Sujay Korgaonkar. 25Rank: Police Sub Inspector (at the time of charge \\n\\nsheet). 269.(a) Name of Complainant :-Amida @ Roshan W/o late Khajasab Budihal, R/o c/o \\nAdalpalkar's constructions site Curca, Tiswadi Goa N/o Bagalkot, Karnataka 27 \\n(b)-Father's/Husband's Name: -Khajasab Budihal. 28 \\n\\n9.  Details of properties/Articles/Documents recovered/Seized during investigation and \\n\\nrelied Upon (Separate list can be 29attached, if necessary). 30 \\n\\nS1. No. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\n1. \\n\\nThis packed \\nand sealed \\nenvelop \\ncontains in \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\n01/22 \\n\\nDisposal \\n\\nFrom \\nwhom/Wh\\nere \\nrecovered \\nor seized. \\n\\nAttached \\nunder \\narrest cum \\nattachment \\n\\nSent to FSL \\nVerna for \\nexamin \\nation. 31 \\n\\n \\n \\n \\n \\n \\n\\x0cpanchanam \\nat Agacaim \\nPS on \\n05/01/2022 \\nby PSI \\nYogesh \\nGadkar, \\nbelongs to \\n\\nit one black \\ncolour long \\nsleeves \\nshirt having \\nwhite \\ncolour \\nflower \\ndesign on it \\nand greyish \\nblack \\ncolour long \\njeans pant, \\nbelongs to \\nthe \\naccused \\nShobhit \\nKumar, \\nduring \\nattached \\narrest cum \\nattachment \\npanchanam \\n\\nPage 3 \\n\\n11. Particulars of accused person charge sheeted: 32 (Use separate sheet for each accused) \\n33Sr. No. A-1 34 (i) Name: Shobhit Kumar 35Whether Verified: Yes 36 (ii) Mothers's Name: \\nDevi Charan 37 (iii) Date/Year of birth: 26 years. 38 (iv) Sex: Male 39 (v) Nationality: Indian 40 \\n(vi) Passport No.: --Date of issue: -- Place of issue: 41 (vii) Religion: Hindu (viii) Whether \\nSC/ST/OBC: 42 (ix) Occupation: Private Job. 43 (x) Address: Abul Haipur, Kora, Jahananad, \\nFatehpur, Uttar 44 Pradesh. Whether Verified: Yes 45<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:53:25 [engine.py:317] Added request chatcmpl-b1a9f0c07b5e41829cafcc1b56866dcb.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_0.txt...vLLM STDOUT: INFO:     127.0.0.1:32812 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:53:31 [logger.py:43] Received request chatcmpl-cc49705c806d489e9dae508a4c589e18: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nüìù Extracted Text from Charge Sheets \\n\\nHere is the extracted text from the provided PDF, segmented by page for clarity. \\n\\nPage 1 \\n\\nSCCORE NO 400. 1Agaciam P3-75/21 2FINAL FORM/REPORT 3863 404/02/22 5 (Under \\nSection 173 Cr. P.C.) 6IN THE COURT OF THE DISTRICT SESSION JUDGE, AT 7PANAJI-GOA. 8 \\n1.District: N-Goa P.S. Agacaim Year: 2022 9FIR No.79/2021 10Date: 11.12.2021 113)Date: \\n4.02.2022. 12Sections:- 363, 376. 13Sections:- 4. 14 \\n2. Charge Sheet No. 08/2022. 15 \\n4. (i) Act :- IPC 16 (ii) Act:-POCSO Act, 2012 17 (iii) Act:-Sections: - 18 (iv) Other Acts & \\nSections: 19 \\n5. Type of final Form/Report; Charge sheet/Not Charge Sheeted for want of evidence/FR True, \\nUndetected true, Untraced/FR true, offence abated/FR Unoccurred. 20Charge sheet (Tick \\'\\' \\napplicable portion). 21 \\nPage 2 \\n\\n6.  If FR Unoccurred: False/Mistake of fact/mistake of law/Non cognizable/Civil Nature.N. A. \\n\\n(Tick \\'‚àö\\' applicable portion). 22 \\n\\n7.  If Charge sheet: Original/Supplementary. - Original. 23 (Tick\\'\\' applicable portion). 24<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2KProcessing 3 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_0.txt...vLLM STDOUT: INFO 12-14 04:53:31 [engine.py:317] Added request chatcmpl-cc49705c806d489e9dae508a4c589e18.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_0.txt...vLLM STDOUT: INFO:     127.0.0.1:50970 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:53:47 [logger.py:43] Received request chatcmpl-d1f2a98d253e435f8fc5c812004991f1: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n- Original. 23 (Tick\\'\\' applicable portion). 24 \\n\\n8.  Name of I.O.: Shri. Sujay Korgaonkar. 25Rank: Police Sub Inspector (at the time of charge \\n\\nsheet). 269.(a) Name of Complainant :-Amida @ Roshan W/o late Khajasab Budihal, R/o c/o \\nAdalpalkar\\'s constructions site Curca, Tiswadi Goa N/o Bagalkot, Karnataka 27 \\n(b)-Father\\'s/Husband\\'s Name: -Khajasab Budihal. 28 \\n\\n9.  Details of properties/Articles/Documents recovered/Seized during investigation and \\n\\nrelied Upon (Separate list can be 29attached, if necessary). 30 \\n\\nS1. No. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\n1. \\n\\nThis packed \\nand sealed \\nenvelop \\ncontains in \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\n01/22 \\n\\nDisposal \\n\\nFrom \\nwhom/Wh\\nere \\nrecovered \\nor seized. \\n\\nAttached \\nunder \\narrest cum \\nattachment \\n\\nSent to FSL \\nVerna for \\nexamin \\nation. 31 \\n\\n \\n \\n \\n \\n \\n\\x0cpanchanam \\nat Agacaim \\nPS on \\n05/01/2022 \\nby PSI \\nYogesh \\nGadkar, \\nbelongs to<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:53:47 [engine.py:317] Added request chatcmpl-d1f2a98d253e435f8fc5c812004991f1.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_0.txt...vLLM STDOUT: INFO:     127.0.0.1:58156 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:54:04 [logger.py:43] Received request chatcmpl-847fd97efeef464fbd41ee89028c5dd7: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n\\n01/22 \\n\\nDisposal \\n\\nFrom \\nwhom/Wh\\nere \\nrecovered \\nor seized. \\n\\nAttached \\nunder \\narrest cum \\nattachment \\n\\nSent to FSL \\nVerna for \\nexamin \\nation. 31 \\n\\n \\n \\n \\n \\n \\n\\x0cpanchanam \\nat Agacaim \\nPS on \\n05/01/2022 \\nby PSI \\nYogesh \\nGadkar, \\nbelongs to \\n\\nit one black \\ncolour long \\nsleeves \\nshirt having \\nwhite \\ncolour \\nflower \\ndesign on it \\nand greyish \\nblack \\ncolour long \\njeans pant, \\nbelongs to \\nthe \\naccused \\nShobhit \\nKumar, \\nduring \\nattached \\narrest cum \\nattachment \\npanchanam \\n\\nPage 3 \\n\\n11. Particulars of accused person charge sheeted: 32 (Use separate sheet for each accused) \\n33Sr. No. A-1 34 (i) Name: Shobhit Kumar 35Whether Verified: Yes 36 (ii) Mothers\\'s Name: \\nDevi Charan 37 (iii) Date/Year of birth: 26 years. 38 (iv) Sex: Male 39 (v) Nationality: Indian 40 \\n(vi) Passport No.: --Date of issue: -- Place of issue: 41 (vii) Religion: Hindu (viii) Whether \\nSC/ST/OBC: 42 (ix) Occupation: Private Job. 43 (x) Address: Abul Haipur, Kora, Jahananad, \\nFatehpur, Uttar 44 Pradesh. Whether Verified: Yes 45<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:54:04 [engine.py:317] Added request chatcmpl-847fd97efeef464fbd41ee89028c5dd7.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_0.txt...vLLM STDOUT: INFO:     127.0.0.1:42330 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 48 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_0_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_0_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_0.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_0_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:52582 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:52596 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:54:22 [logger.py:43] Received request chatcmpl-24ff7047990e46f790e092cdce20da80: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nii) Religion: Hindu (viii) Whether \\nSC/ST/OBC: 42 (ix) Occupation: Private Job. 43 (x) Address: Abul Haipur, Kora, Jahananad, \\nFatehpur, Uttar 44 Pradesh. Whether Verified: Yes 45 (xi) Provisional criminal No. 46 (xii) \\nRegular criminal No. (if known) - 47 (xiii) Date of arrest: 05.01.2022 at 22.00 hrs. 48 (xiv) \\nDate of release on bail: Presently in Judicial Custody. 49 (xv) Date on which forwarded to \\ncourt: --. 50 (xvi) Under Acts & Sections: 363, 376 IPC, Sec. 4 of POCSO 51Act, 2012. 52 \\n(xvii) Details of bailers/sureties:---------- 53 (xvii) Previous convictions with case \\nreferences...... 54 (xix) Status of the accused:-Forwarded/Bailed by Police/Under Police \\nCustody/Bailed by court/Judicial Custody/Absconding/ Proclaimed Offender (tick \\n$\\\\sqrt{}$ applicable). 55 \\n\\n \\n \\n\\x0cPage 4 \\n\\n12. Particulars of accused persons-not charge sheeted (suspect): 56 Sl. No: Nil (Use separate \\nsheet for each suspect). 57 (i) 58Name:---Whether verified : 59 (ii) 60Father's Husband's \\nname: 61 (iii) 62 (iii) Date/Year of birth: 63 (iv) 64Sex... 65 (v) Nationality: -- 66 (vi) Passport No: \\n67Date of issue-... Place of issue.......... 68 (vii) Religion 69 (viii) Whether SC/ST/OBC. 70 (ix) \\nOccupation: - 71 (x)Address...--..... 72Whether verified 73Yes/No. 74 (xi) Provisional criminal \\nNo....... 75 (xii) Suspicion Approved: 76 (xiii) Status of the accused (suspect):Bailed by \\nRolice/Bailed by 77court/Judicial Custody/Not arrested (tick'' applicable portion) 78 (xiv) \\nUnder Acts & Sections............ 79 (xv) Any special remarks including reasons for not charge \\nsheeting... 80 \\n\\n13. Particulars of witnesses to be examined: 81 \\n\\nDate/yea\\nr of birth \\n\\nOccupat\\nion \\n\\nAddress \\n\\nType of \\nevidence \\n\\n38 yrs \\n\\nLabour \\n\\nComplain \\nant 82 \\n\\nc/o \\nAdalpalka\\nr's \\nconstruct\\nions site \\nCurca, \\nTiswadi \\nGoa N/o \\nBagalkot, \\nKarnatak\\na. \\n\\n16 yrs \\n\\nStudent \\n\\n--do-- \\n\\nVictim 83 \\n\\nSr. No. \\n\\nName \\n\\n1. \\n\\nAmida@ \\nRoshan \\n\\nFathers/ \\nHusband \\nName \\n\\nw/o late \\nKhajasab \\nBudihal. \\n\\n2. \\n\\nD/o \\nKhajasab \\nBudihal. \\n\\nMiss. \\nGausiya \\n@ \\nKhushbu \\nBudhyal \\n\\nPage 5 \\n\\n \\n \\n \\n \\n\\x0c(3.) \\n\\n4.) \\n\\n5. \\n\\n29 yrs \\n\\nBusiness \\n\\nEmran \\nSab \\nHiremat\\nh \\n\\nKasim \\nHiremat\\nh \\n\\n50 yrs \\n\\nDriver \\n\\nShri. \\nSachit \\nMulgaonk \\nar \\n\\nDattaram \\nMulgaonk \\nar \\n\\nRamana \\nMalagiti \\n\\n46 yr \\n\\nContract\\nor \\n\\nShri. \\nKrishnap\\np a \\nMalagiti \\n\\nKasim \\nHeramani \\n\\nMhaboos\\na b \\n\\n51 yrs \\n\\nBusiness \\n\\n177. \\n\\nDr. \\nChetan \\nLavu \\nKarekar \\n\\nMajor \\n\\nAsst. \\nLectur er \\n\\nPanch \\nwitness \\n\\nPanch \\nwitness 85 \\n\\nPanch \\nWitness. \\n86 \\n\\nWitness \\n87 \\n\\nMedical \\nOfficer 88 \\n\\nH.No.108\\n3/2 Near \\nSuccor \\nChurch<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:54:22 [engine.py:317] Added request chatcmpl-24ff7047990e46f790e092cdce20da80.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_1.txt...vLLM STDOUT: INFO:     127.0.0.1:52610 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:54:26 [logger.py:43] Received request chatcmpl-73918a56f2174be0ac9c9c6e1792bdd4: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nii) Religion: Hindu (viii) Whether \\nSC/ST/OBC: 42 (ix) Occupation: Private Job. 43 (x) Address: Abul Haipur, Kora, Jahananad, \\nFatehpur, Uttar 44 Pradesh. Whether Verified: Yes 45 (xi) Provisional criminal No. 46 (xii) \\nRegular criminal No. (if known) - 47 (xiii) Date of arrest: 05.01.2022 at 22.00 hrs. 48 (xiv) \\nDate of release on bail: Presently in Judicial Custody. 49 (xv) Date on which forwarded to \\ncourt: --. 50 (xvi) Under Acts & Sections: 363, 376 IPC, Sec. 4 of POCSO 51Act, 2012. 52 \\n(xvii) Details of bailers/sureties:---------- 53 (xvii) Previous convictions with case \\nreferences...... 54 (xix) Status of the accused:-Forwarded/Bailed by Police/Under Police \\nCustody/Bailed by court/Judicial Custody/Absconding/ Proclaimed Offender (tick \\n$\\\\sqrt{}$ applicable). 55 \\n\\n \\n \\n\\x0cPage 4<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:54:26 [engine.py:317] Added request chatcmpl-73918a56f2174be0ac9c9c6e1792bdd4.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_1.txt...vLLM STDOUT: INFO:     127.0.0.1:52612 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:54:42 [logger.py:43] Received request chatcmpl-a9d3046bc3144f73812d69303d899989: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n52 \\n(xvii) Details of bailers/sureties:---------- 53 (xvii) Previous convictions with case \\nreferences...... 54 (xix) Status of the accused:-Forwarded/Bailed by Police/Under Police \\nCustody/Bailed by court/Judicial Custody/Absconding/ Proclaimed Offender (tick \\n$\\\\sqrt{}$ applicable). 55 \\n\\n \\n \\n\\x0cPage 4 \\n\\n12. Particulars of accused persons-not charge sheeted (suspect): 56 Sl. No: Nil (Use separate \\nsheet for each suspect). 57 (i) 58Name:---Whether verified : 59 (ii) 60Father\\'s Husband\\'s \\nname: 61 (iii) 62 (iii) Date/Year of birth: 63 (iv) 64Sex... 65 (v) Nationality: -- 66 (vi) Passport No: \\n67Date of issue-... Place of issue.......... 68 (vii) Religion 69 (viii) Whether SC/ST/OBC. 70 (ix) \\nOccupation: - 71 (x)Address...--..... 72Whether verified 73Yes/No. 74 (xi) Provisional criminal \\nNo....... 75 (xii) Suspicion Approved: 76 (xiii) Status of the accused (suspect):Bailed by \\nRolice/Bailed by 77court/Judicial Custody/Not arrested (tick\\'\\' applicable portion) 78 (xiv) \\nUnder Acts & Sections............ 79 (xv) Any special remarks including reasons for not charge \\nsheeting... 80<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:54:42 [engine.py:317] Added request chatcmpl-a9d3046bc3144f73812d69303d899989.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_1.txt...vLLM STDOUT: INFO:     127.0.0.1:43220 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:54:57 [logger.py:43] Received request chatcmpl-b779b3fe29c3455599861a1158fb1deb: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n75 (xii) Suspicion Approved: 76 (xiii) Status of the accused (suspect):Bailed by \\nRolice/Bailed by 77court/Judicial Custody/Not arrested (tick\\'\\' applicable portion) 78 (xiv) \\nUnder Acts & Sections............ 79 (xv) Any special remarks including reasons for not charge \\nsheeting... 80 \\n\\n13. Particulars of witnesses to be examined: 81 \\n\\nDate/yea\\nr of birth \\n\\nOccupat\\nion \\n\\nAddress \\n\\nType of \\nevidence \\n\\n38 yrs \\n\\nLabour \\n\\nComplain \\nant 82 \\n\\nc/o \\nAdalpalka\\nr\\'s \\nconstruct\\nions site \\nCurca, \\nTiswadi \\nGoa N/o \\nBagalkot, \\nKarnatak\\na. \\n\\n16 yrs \\n\\nStudent \\n\\n--do-- \\n\\nVictim 83 \\n\\nSr. No. \\n\\nName \\n\\n1. \\n\\nAmida@ \\nRoshan \\n\\nFathers/ \\nHusband \\nName \\n\\nw/o late \\nKhajasab \\nBudihal. \\n\\n2. \\n\\nD/o \\nKhajasab \\nBudihal. \\n\\nMiss. \\nGausiya \\n@ \\nKhushbu \\nBudhyal \\n\\nPage 5 \\n\\n \\n \\n \\n \\n\\x0c(3.) \\n\\n4.) \\n\\n5. \\n\\n29 yrs \\n\\nBusiness \\n\\nEmran \\nSab \\nHiremat\\nh \\n\\nKasim \\nHiremat\\nh \\n\\n50 yrs \\n\\nDriver \\n\\nShri. \\nSachit \\nMulgaonk \\nar \\n\\nDattaram \\nMulgaonk \\nar \\n\\nRamana \\nMalagiti \\n\\n46 yr \\n\\nContract\\nor \\n\\nShri. \\nKrishnap\\np a \\nMalagiti \\n\\nKasim \\nHeramani \\n\\nMhaboos\\na b \\n\\n51 yrs<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_1.txt...vLLM STDOUT: INFO 12-14 04:54:57 [engine.py:317] Added request chatcmpl-b779b3fe29c3455599861a1158fb1deb.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_1.txt...vLLM STDOUT: INFO:     127.0.0.1:57608 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:55:13 [logger.py:43] Received request chatcmpl-5bace7e477b94fefb3a031d44b316e02: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n\\n29 yrs \\n\\nBusiness \\n\\nEmran \\nSab \\nHiremat\\nh \\n\\nKasim \\nHiremat\\nh \\n\\n50 yrs \\n\\nDriver \\n\\nShri. \\nSachit \\nMulgaonk \\nar \\n\\nDattaram \\nMulgaonk \\nar \\n\\nRamana \\nMalagiti \\n\\n46 yr \\n\\nContract\\nor \\n\\nShri. \\nKrishnap\\np a \\nMalagiti \\n\\nKasim \\nHeramani \\n\\nMhaboos\\na b \\n\\n51 yrs \\n\\nBusiness \\n\\n177. \\n\\nDr. \\nChetan \\nLavu \\nKarekar \\n\\nMajor \\n\\nAsst. \\nLectur er \\n\\nPanch \\nwitness \\n\\nPanch \\nwitness 85 \\n\\nPanch \\nWitness. \\n86 \\n\\nWitness \\n87 \\n\\nMedical \\nOfficer 88 \\n\\nH.No.108\\n3/2 Near \\nSuccor \\nChurch<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_1.txt...vLLM STDOUT: INFO 12-14 04:55:13 [engine.py:317] Added request chatcmpl-5bace7e477b94fefb3a031d44b316e02.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_1.txt...vLLM STDOUT: INFO:     127.0.0.1:60202 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 68 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_1_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_1_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_1.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_1_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:50458 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:50464 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:55:31 [logger.py:43] Received request chatcmpl-d10ae6304ad04995b478ccc549476352: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nKarekar \\n\\nMajor \\n\\nAsst. \\nLectur er \\n\\nPanch \\nwitness \\n\\nPanch \\nwitness 85 \\n\\nPanch \\nWitness. \\n86 \\n\\nWitness \\n87 \\n\\nMedical \\nOfficer 88 \\n\\nH.No.108\\n3/2 Near \\nSuccor \\nChurch \\nSuccor \\nPorvorim \\nBardez \\nGoa \\n\\nH.No.234, \\nRumadwa\\nda, \\nVelguem, \\nBicholim \\nGoa. \\n\\nH.No.669, \\nValant \\nVerem \\nBetim, \\nReis \\nMagos, \\nBardez \\nGoa. \\n\\nH.No.108\\n3/2 \\nWado, \\nZas Near \\nSucorro \\nChurch, \\nPorvorim \\nBardez \\nGoa. \\n\\nof Dept. \\nForensic \\nMedicine \\n& \\nToxicolog\\ny, GMC \\n\\n \\n \\n \\n \\n \\n \\n\\x0c8. \\n\\nDr. Rupa \\nPadwalka\\nr \\n\\nMajor \\n\\nLectur er \\n\\n9. 10 \\n\\nDr. Nisha \\nNaik Dr. \\nNikhila K. \\nGaude \\n\\nMajor \\nMajor \\n\\nSenior \\nReside nt \\nAsst. \\nLectur er \\n\\nPage 6 \\n\\n11 \\n\\n12 \\n\\n13 \\n\\nMs. \\nVaishali \\nKerkar \\n\\nMs. \\nPratiksha \\nParvatkar \\n\\nShri. \\nYogesh \\nGadkar \\n\\nMajor \\n\\nMajor \\n\\n42 yrs \\n\\nVAU/ \\nOSC \\n(NGO) \\n\\nVAU/ \\nOSC \\n(NGO) \\n\\nPolice \\nSub \\nInspec \\ntor \\n\\nBamboli\\nm. \\n\\nof Dept. \\nObstetric\\ns & \\nGynecolo\\ngy, GMC \\nBamboli\\nm. \\n\\n--do-- \\nBlood \\nBank, \\nGMC \\nBamboli\\nm. \\n\\nVAU/ \\nOSC, \\nGMC, \\nBamboli\\nm Goa. \\n\\nVAU/ \\nOSC, \\nGMC, \\nBamboli\\nm Goa. \\n\\nAgacaim \\nPolice \\nStation. \\n\\nMedical \\nOfficer 89 \\n\\nMedical \\nOfficer \\nMedical \\nOfficer 90 \\n\\nWitness \\n\\nWitness \\n92 \\n\\n11.0 93 \\n\\n14) \\n\\nShri. \\nSujay \\n\\nS/o \\nShantara\\n\\n31 yrs \\n\\nPolice \\nSub \\n\\nAgacaim \\nPolice \\n\\n$2^{rd}I.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cKorgaonk \\nar \\n\\nm \\nKorgaonk \\nar \\n\\nInspec \\ntor \\n\\nStation. \\n\\nO$ 94 \\n\\n14. If FR is false, indicate action taken or proposed to be taken u/s.182/211 I.P.C. : 95 \\n\\n15. Result of Laboratory analysis: 96The Exhibits marked as Exhibit-A and Exhibit-B, attached \\n\\nby the police and Exhibit-P, Exhibit-Q and Exhibit-R, attached by the Police \\nSurgeon/Medical Officer, GMC Bambolim, have been sent for examination at G.S.F.S.L. \\n97Verna Goa through the Office of the Supdt. of Police, North, Porvorim Goa, vide No. \\nSP/North/Reader/47/2022, dated: 21.01.2022 and No. SP/North/ Reader/46/2022, dated: \\n21.01.2022, respectively. 98The report of the said exhibits is not yet received. 99The \\nexamination reports will be submitted before your Hon'ble Court, on receipt of the same \\nfrom GSFSL Verna Goa. 100 \\n\\nPage 7 \\n\\n16. Brief facts of the case (add separate sheet, if necessary). 101MAY IT PLEASE YOUR \\n\\nHONOUR 102In the limits of your Hon'ble Court and within the jurisdiction of Agacaim \\nPolice Station that on 11.12.2021at 10.30 hrs, the accused person mentioned at column \\nNo.11 at Sr.No.A- 1, kidnapped the complainant's minor daughter age: 16 years from \\ncomplainant's lawful guardianship and took her to Aslali, Ahmadabad, Gujarat and had \\nforceful sexual intercourse with her, against her wish. 103Thereby committed rape. 104 \\nThus, the accused person committed an offence<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:55:31 [engine.py:317] Added request chatcmpl-d10ae6304ad04995b478ccc549476352.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_2.txt...vLLM STDOUT: INFO:     127.0.0.1:50472 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:55:35 [logger.py:43] Received request chatcmpl-6f894e37878b406ea8e87e4a31f9006e: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nKarekar \\n\\nMajor \\n\\nAsst. \\nLectur er \\n\\nPanch \\nwitness \\n\\nPanch \\nwitness 85 \\n\\nPanch \\nWitness. \\n86 \\n\\nWitness \\n87 \\n\\nMedical \\nOfficer 88 \\n\\nH.No.108\\n3/2 Near \\nSuccor \\nChurch \\nSuccor \\nPorvorim \\nBardez \\nGoa \\n\\nH.No.234, \\nRumadwa\\nda, \\nVelguem, \\nBicholim \\nGoa. \\n\\nH.No.669, \\nValant \\nVerem \\nBetim, \\nReis \\nMagos, \\nBardez \\nGoa. \\n\\nH.No.108\\n3/2 \\nWado, \\nZas Near \\nSucorro \\nChurch, \\nPorvorim \\nBardez \\nGoa. \\n\\nof Dept. \\nForensic \\nMedicine \\n& \\nToxicolog\\ny, GMC \\n\\n \\n \\n \\n \\n \\n \\n\\x0c8. \\n\\nDr. Rupa \\nPadwalka\\nr \\n\\nMajor \\n\\nLectur er \\n\\n9. 10 \\n\\nDr. Nisha \\nNaik Dr. \\nNikhila K. \\nGaude \\n\\nMajor \\nMajor \\n\\nSenior \\nReside nt \\nAsst. \\nLectur er \\n\\nPage 6 \\n\\n11 \\n\\n12 \\n\\n13 \\n\\nMs. \\nVaishali \\nKerkar \\n\\nMs. \\nPratiksha \\nParvatkar \\n\\nShri. \\nYogesh \\nGadkar \\n\\nMajor \\n\\nMajor \\n\\n42 yrs \\n\\nVAU/ \\nOSC \\n(NGO) \\n\\nVAU/ \\nOSC \\n(NGO) \\n\\nPolice \\nSub \\nInspec \\ntor \\n\\nBamboli\\nm. \\n\\nof Dept. \\nObstetric\\ns & \\nGynecolo\\ngy, GMC \\nBamboli\\nm. \\n\\n--do-- \\nBlood \\nBank, \\nGMC \\nBamboli\\nm. \\n\\nVAU/ \\nOSC, \\nGMC, \\nBamboli\\nm Goa. \\n\\nVAU/ \\nOSC, \\nGMC, \\nBamboli\\nm Goa. \\n\\nAgacaim \\nPolice \\nStation. \\n\\nMedical \\nOfficer 89<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:55:35 [engine.py:317] Added request chatcmpl-6f894e37878b406ea8e87e4a31f9006e.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_2.txt...vLLM STDOUT: INFO:     127.0.0.1:50488 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:55:50 [logger.py:43] Received request chatcmpl-c728741294064329bfbfd942cb7b980c: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n\\nVAU/ \\nOSC, \\nGMC, \\nBamboli\\nm Goa. \\n\\nAgacaim \\nPolice \\nStation. \\n\\nMedical \\nOfficer 89 \\n\\nMedical \\nOfficer \\nMedical \\nOfficer 90 \\n\\nWitness \\n\\nWitness \\n92 \\n\\n11.0 93 \\n\\n14) \\n\\nShri. \\nSujay \\n\\nS/o \\nShantara\\n\\n31 yrs \\n\\nPolice \\nSub \\n\\nAgacaim \\nPolice \\n\\n$2^{rd}I.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cKorgaonk \\nar \\n\\nm \\nKorgaonk \\nar \\n\\nInspec \\ntor \\n\\nStation. \\n\\nO$ 94 \\n\\n14. If FR is false, indicate action taken or proposed to be taken u/s.182/211 I.P.C. : 95 \\n\\n15. Result of Laboratory analysis: 96The Exhibits marked as Exhibit-A and Exhibit-B, attached<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_2.txt...vLLM STDOUT: INFO 12-14 04:55:50 [engine.py:317] Added request chatcmpl-c728741294064329bfbfd942cb7b980c.\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_2.txt...vLLM STDOUT: INFO:     127.0.0.1:56498 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:56:06 [logger.py:43] Received request chatcmpl-c50afb9409a24457ab4312015c56eed8: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nIf FR is false, indicate action taken or proposed to be taken u/s.182/211 I.P.C. : 95 \\n\\n15. Result of Laboratory analysis: 96The Exhibits marked as Exhibit-A and Exhibit-B, attached \\n\\nby the police and Exhibit-P, Exhibit-Q and Exhibit-R, attached by the Police \\nSurgeon/Medical Officer, GMC Bambolim, have been sent for examination at G.S.F.S.L. \\n97Verna Goa through the Office of the Supdt. of Police, North, Porvorim Goa, vide No. \\nSP/North/Reader/47/2022, dated: 21.01.2022 and No. SP/North/ Reader/46/2022, dated: \\n21.01.2022, respectively. 98The report of the said exhibits is not yet received. 99The \\nexamination reports will be submitted before your Hon\\'ble Court, on receipt of the same \\nfrom GSFSL Verna Goa. 100 \\n\\nPage 7 \\n\\n16. Brief facts of the case (add separate sheet, if necessary). 101MAY IT PLEASE YOUR<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:56:06 [engine.py:317] Added request chatcmpl-c50afb9409a24457ab4312015c56eed8.\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/output2/ilovepdf_merged_2.txt...vLLM STDOUT: INFO:     127.0.0.1:53486 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:56:21 [logger.py:43] Received request chatcmpl-1e9b8433ce5545be9a9e5a897352a155: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n100 \\n\\nPage 7 \\n\\n16. Brief facts of the case (add separate sheet, if necessary). 101MAY IT PLEASE YOUR \\n\\nHONOUR 102In the limits of your Hon\\'ble Court and within the jurisdiction of Agacaim \\nPolice Station that on 11.12.2021at 10.30 hrs, the accused person mentioned at column \\nNo.11 at Sr.No.A- 1, kidnapped the complainant\\'s minor daughter age: 16 years from \\ncomplainant\\'s lawful guardianship and took her to Aslali, Ahmadabad, Gujarat and had \\nforceful sexual intercourse with her, against her wish. 103Thereby committed rape. 104 \\nThus, the accused person committed an offence<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:56:21 [engine.py:317] Added request chatcmpl-1e9b8433ce5545be9a9e5a897352a155.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_2.txt...vLLM STDOUT: INFO:     127.0.0.1:41790 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 48 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_2_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_2_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_2.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_2_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:56110 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:56116 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:56:39 [logger.py:43] Received request chatcmpl-f5d214739ca74f478283e3db94c4ec2c: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nthe complainant's minor daughter age: 16 years from \\ncomplainant's lawful guardianship and took her to Aslali, Ahmadabad, Gujarat and had \\nforceful sexual intercourse with her, against her wish. 103Thereby committed rape. 104 \\nThus, the accused person committed an offence punishable u/s 363, 376 IPC and sec. 4 \\nof POCSO Act, 2012. 105Hence the charge. 106 \\n\\n17. Refer Notice served: 107Yes/No 108Date: 109/ /2022 110 \\n\\n18. Dispatched On: 08 111 (Acknowledgement to be placed) 112 \\n\\n19. No of enclosures: As per index. 113 \\n\\n20. List of enclosures: As annexed. 114102/2022. 115W 116Forwarded by Station House Officer/ \\nSignature of the Investigation Officer 117Officer in charge of police Station 118 Name: Shri. \\nT. S. Naik. 119Rank: Police Inspector. 120Agacaim Police Station. 121NOTE: 122Submitting \\nCharge sheet. 123 Name: Shri. Sujay Korgaonkar 124Rank :Police Sub Inspector. 125Agacaim \\nPolice Station. 126 \\n\\n21. Original Charge sheet along with original case papers sent to the Court along with the \\n\\ncopy of the accused person. 127 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c22. Duplicate Charge sheet along with the copy of case papers sent to P.P. 128Panaji with a \\n\\nrequest to conduct prosecution of the case at the time of trial. 129 \\n\\n23. Summons to the witnesses may be send through this office for service and return in time. \\n\\n130 \\n\\n24. Examination reports of the exhibits will be submitted before your Hon'ble Court, on \\n\\nreceipt of the same from GSFSL Verna Goa. 131 \\n\\n25. Permission may please be accorded to produce more evidence & 132witnesses at the time \\n\\nof trial if needed. 133 \\n\\nPage 8 \\n\\nJ 134œÑŒ∑Œ≥Œ±ŒΩŒπŒø 13518/5/2018 136INSPECTOR HAPUSA POLICE S 137ON 138RAPUSA-GOA 139FINAL \\nFORM/REPORT 140 (Under Section 173 Cr. P.C.) 141MAPUSA POLICE STA 142W. 143QW 1447677 \\n14518/5/18 146IN THE CHILDREN'S COURT FOR THE STATE OF GOA, AT PANAJI GOA. 147 \\n\\n1.  District: N.Goa. P.S.: Mapusa Year: 2018 FIR No. 85/2018 Date: 20.03.2018. 148 \\n\\n2.  Charge Sheet No. 94/2018 149 \\n\\n3.  (i) Act: I.P.C. 150 (ii) Act 151Goa Children's Act 152 (iii) Act: POCSO Act 153 (iv) Other Acts \\n& Sections: 1543) Date: 18/5/2018 155Sections: 363, 376, 506 IPC 156Sections: 8 of Goa \\nChildren's Act. 157Sections: 4, 8, 12 of POCSO Act. 158 \\n5.Type of final Form/Report; Charge sheet/Not Charge Sheeted for want of evidence/FR \\nTrue, Undetected true, Untraced/FR true, offence abated/FR Unoccurred. 159 (Tick'' \\napplicable portion). CHARGE SHEET 160 \\n\\n4.  If FR Unoccurred: False/Mistake of fact/mistake of law/Non cognizable/Civil Nature. (Tick'\\n\\n' applicable portion). N.A. 161 \\n\\n5.  If Charge sheet: Original/Supplementary. Original 162 (Tick'' applicable portion). 163 \\n\\n6.  Name of I.O.: Shri Paresh G. Ramnathkar Rank: Police Sub Inspector No: (at the time of \\n\\ncharge sheet). 164 \\n\\nPage 9 \\n\\n9.  (a) Name of Complainant/informant:. Gauri Virnodkar 165 (b) Husband's Name/address<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:56:39 [engine.py:317] Added request chatcmpl-f5d214739ca74f478283e3db94c4ec2c.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_3.txt...vLLM STDOUT: INFO:     127.0.0.1:56128 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_3.txt...vLLM STDOUT: INFO 12-14 04:56:44 [logger.py:43] Received request chatcmpl-c9b7c2355cc747d6ad74e9bbed35afa6: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n the complainant\\'s minor daughter age: 16 years from \\ncomplainant\\'s lawful guardianship and took her to Aslali, Ahmadabad, Gujarat and had \\nforceful sexual intercourse with her, against her wish. 103Thereby committed rape. 104 \\nThus, the accused person committed an offence punishable u/s 363, 376 IPC and sec. 4 \\nof POCSO Act, 2012. 105Hence the charge. 106 \\n\\n17. Refer Notice served: 107Yes/No 108Date: 109/ /2022 110 \\n\\n18. Dispatched On: 08 111 (Acknowledgement to be placed) 112 \\n\\n19. No of enclosures: As per index. 113 \\n\\n20. List of enclosures: As annexed. 114102/2022. 115W 116Forwarded by Station House Officer/ \\nSignature of the Investigation Officer 117Officer in charge of police Station 118 Name: Shri. \\nT. S. Naik. 119Rank: Police Inspector. 120Agacaim Police Station. 121NOTE: 122Submitting \\nCharge sheet. 123 Name: Shri. Sujay Korgaonkar 124Rank :Police Sub Inspector. 125Agacaim \\nPolice Station. 126 \\n\\n21. Original Charge sheet along with original case papers sent to the Court along with the<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:56:44 [engine.py:317] Added request chatcmpl-c9b7c2355cc747d6ad74e9bbed35afa6.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_3.txt...vLLM STDOUT: INFO:     127.0.0.1:56144 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:57:00 [logger.py:43] Received request chatcmpl-3d88229b825944dc9943b2e7a584dd5f: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n125Agacaim \\nPolice Station. 126 \\n\\n21. Original Charge sheet along with original case papers sent to the Court along with the \\n\\ncopy of the accused person. 127 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c22. Duplicate Charge sheet along with the copy of case papers sent to P.P. 128Panaji with a \\n\\nrequest to conduct prosecution of the case at the time of trial. 129 \\n\\n23. Summons to the witnesses may be send through this office for service and return in time. \\n\\n130 \\n\\n24. Examination reports of the exhibits will be submitted before your Hon\\'ble Court, on \\n\\nreceipt of the same from GSFSL Verna Goa. 131 \\n\\n25. Permission may please be accorded to produce more evidence & 132witnesses at the time \\n\\nof trial if needed. 133 \\n\\nPage 8 \\n\\nJ 134œÑŒ∑Œ≥Œ±ŒΩŒπŒø 13518/5/2018 136INSPECTOR HAPUSA POLICE S 137ON 138RAPUSA-GOA 139FINAL \\nFORM/REPORT 140 (Under Section 173 Cr. P.C.) 141MAPUSA POLICE STA 142W. 143QW 1447677 \\n14518/5/18 146IN THE CHILDREN\\'S COURT FOR THE STATE OF GOA, AT PANAJI GOA. 147<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:57:00 [engine.py:317] Added request chatcmpl-3d88229b825944dc9943b2e7a584dd5f.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_3.txt...vLLM STDOUT: INFO:     127.0.0.1:60016 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:57:15 [logger.py:43] Received request chatcmpl-b22eba3e84a5416097f901aaeb04616f: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nP.C.) 141MAPUSA POLICE STA 142W. 143QW 1447677 \\n14518/5/18 146IN THE CHILDREN\\'S COURT FOR THE STATE OF GOA, AT PANAJI GOA. 147 \\n\\n1.  District: N.Goa. P.S.: Mapusa Year: 2018 FIR No. 85/2018 Date: 20.03.2018. 148 \\n\\n2.  Charge Sheet No. 94/2018 149 \\n\\n3.  (i) Act: I.P.C. 150 (ii) Act 151Goa Children\\'s Act 152 (iii) Act: POCSO Act 153 (iv) Other Acts \\n& Sections: 1543) Date: 18/5/2018 155Sections: 363, 376, 506 IPC 156Sections: 8 of Goa \\nChildren\\'s Act. 157Sections: 4, 8, 12 of POCSO Act. 158 \\n5.Type of final Form/Report; Charge sheet/Not Charge Sheeted for want of evidence/FR \\nTrue, Undetected true, Untraced/FR true, offence abated/FR Unoccurred. 159 (Tick\\'\\' \\napplicable portion). CHARGE SHEET 160 \\n\\n4.  If FR Unoccurred: False/Mistake of fact/mistake of law/Non cognizable/Civil Nature. (Tick\\'\\n\\n\\' applicable portion). N.A. 161 \\n\\n5.  If Charge sheet: Original/Supplementary. Original 162 (Tick\\'\\' applicable portion). 163 \\n\\n6.  Name of I.O.: Shri Paresh G. Ramnathkar Rank: Police Sub Inspector No: (at the time of<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_3.txt...vLLM STDOUT: INFO 12-14 04:57:15 [engine.py:317] Added request chatcmpl-b22eba3e84a5416097f901aaeb04616f.\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_3.txt...vLLM STDOUT: INFO:     127.0.0.1:58082 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:57:31 [logger.py:43] Received request chatcmpl-1edafb3864e84a998527562c689eb8b4: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n163 \\n\\n6.  Name of I.O.: Shri Paresh G. Ramnathkar Rank: Police Sub Inspector No: (at the time of \\n\\ncharge sheet). 164 \\n\\nPage 9 \\n\\n9.  (a) Name of Complainant/informant:. Gauri Virnodkar 165 (b) Husband\\'s Name/address<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:57:31 [engine.py:317] Added request chatcmpl-1edafb3864e84a998527562c689eb8b4.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_3.txt...vLLM STDOUT: INFO:     127.0.0.1:39842 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 58 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_3_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_3_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_3.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_3_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:43578 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:43584 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:57:42 [logger.py:43] Received request chatcmpl-7129d26b60ec42b384494b53abf1c94b: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nShri Paresh G. Ramnathkar Rank: Police Sub Inspector No: (at the time of \\n\\ncharge sheet). 164 \\n\\nPage 9 \\n\\n9.  (a) Name of Complainant/informant:. Gauri Virnodkar 165 (b) Husband's Name/address: \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cGurudas Virnodkar R/o Khorlim, Bardez Goa. 166 \\n\\n10. Details of properties/Articles/Documents recovered/Seized during investigation and \\n\\nrelied Upon (Separate list can be attached, if necessary). 167 \\n\\nSI. No. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\nDisposal \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\nFrom \\nwhom/Wh\\nere \\nrecovered \\nor seized \\n\\n11. Particulars of accused person charge sheeted (Use separate sheet for each accused) 168 \\nSl. No: A-1 169 (i) Name: Mr. Pandurang Pednekar 170 (ii) Father's Name: Vithu Pednekar 171 \\n(iv) Sex: Male. 172 (vi) Passport No.: 173Whether Verified: Yes. 174 (iii) Date/Year of birth: 41 \\nyrs. 175 (v) Nationality: Indian 176Date of issue: 177Place of issue: 178 (vii) Religion: Hindu 179 \\n(viii) Whether SC/ST/OBC: -- (ix) Occupation: -Business 180 (x) Address: Amurlim, Khorlim, \\nMapusa Bardez Goa. 181 (xi) Provisional criminal No. :- A-1 182 (xii) Regular criminal No. (if \\nKnown)...-- 183 (xiv) Date of release on bail : 184 (xiii) Date of arrest: 20.03.2018 185 (xv) \\nDate on which forwarded to court:- 186 (xvi) Under Acts & Sections: U/s 363, 376, 506 IPC, \\n8 of Goa Children's Act and Sec 4, 8, 18712 of POCSO Act. 188 (xvii) Details of \\nbailers/sureties 189Name: 190Occupation 191Identification....... 192Father's name: Address:..... \\n193 (xvii) Previous convictions with case references... 194 (xix) Status of the accused: \\nJUDICIAL CUSTODY. 195Forwarded / Bailed by Police / Bailed by Court / Police Custody / \\nAbsconding / 196JUDICIAL CUSTODY / Proclaimed offender (tick'' applicable portion) 197 \\n\\nPage 10 \\n\\n12. Particulars of accused persons-not charge sheeted (suspect): (Use separate sheet 198for \\n\\neach suspect) 199 Sl. No: NIL. 200 (i) Name:--- 201 (ii) Father's/Husband's name: 202 \\n(iv)Sex................. 203 (vi) Passport No: 204 (vii) Religion 205 (ix) Occupation: ---- 206 (x) \\nAddress. 207Date of issue................. 208 (xi) Provisional criminal No. 209 (xii) Suspicion \\nApproved: 210 (xiii) Status of the accused (suspect): 211Whether verified: 212 (iii) Date/Year \\nof birth: 213 (v) Nationality: -- 214Place of issue........... 215 (viii) Whether SC/ST/OBC....... \\n216Whether verified. 217Yes/No. 218Bailed by Police/Bailed by court/Judicial Custody/Not \\narrested 219 (tick'' applicable portion). 220 (xiv) Under Acts & Sections..... 221 (xv) Any \\nspecial remarks including reasons for not charge sheeting......-- 222to be examined: 223 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c13. \\nParticula\\nrs of \\nwitnesse\\ns Sl. No \\n\\nName \\n\\nFather's/ \\nHusband\\n's Name \\n\\nDate/ \\nYear of \\nbirth \\n\\nOccupat\\nion \\n\\nAddress \\n\\nType of \\nEvidence \\nto be \\ntendered<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:57:42 [engine.py:317] Added request chatcmpl-7129d26b60ec42b384494b53abf1c94b.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_4.txt...vLLM STDOUT: INFO:     127.0.0.1:43596 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:57:47 [logger.py:43] Received request chatcmpl-48f3c0366b054f5fbbb0011454781e1f: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 20 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n Shri Paresh G. Ramnathkar Rank: Police Sub Inspector No: (at the time of \\n\\ncharge sheet). 164 \\n\\nPage 9 \\n\\n9.  (a) Name of Complainant/informant:. Gauri Virnodkar 165 (b) Husband\\'s Name/address: \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cGurudas Virnodkar R/o Khorlim, Bardez Goa. 166 \\n\\n10. Details of properties/Articles/Documents recovered/Seized during investigation and \\n\\nrelied Upon (Separate list can be attached, if necessary). 167 \\n\\nSI. No. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\nDisposal \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\nFrom \\nwhom/Wh\\nere \\nrecovered \\nor seized<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:57:47 [engine.py:317] Added request chatcmpl-48f3c0366b054f5fbbb0011454781e1f.\n",
            "\u001b[2KProcessing 5 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_4.txt...vLLM STDOUT: INFO:     127.0.0.1:34648 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:58:03 [logger.py:43] Received request chatcmpl-4e5581e05390466bb885557d4b80edce: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 20 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\nDisposal \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\nFrom \\nwhom/Wh\\nere \\nrecovered \\nor seized \\n\\n11. Particulars of accused person charge sheeted (Use separate sheet for each accused) 168 \\nSl. No: A-1 169 (i) Name: Mr. Pandurang Pednekar 170 (ii) Father\\'s Name: Vithu Pednekar 171 \\n(iv) Sex: Male. 172 (vi) Passport No.: 173Whether Verified: Yes. 174 (iii) Date/Year of birth: 41 \\nyrs. 175 (v) Nationality: Indian 176Date of issue: 177Place of issue: 178 (vii) Religion: Hindu 179 \\n(viii) Whether SC/ST/OBC: -- (ix) Occupation: -Business 180 (x) Address: Amurlim, Khorlim, \\nMapusa Bardez Goa. 181 (xi) Provisional criminal No. :- A-1 182 (xii) Regular criminal No. (if \\nKnown)...-- 183 (xiv) Date of release on bail : 184 (xiii) Date of arrest: 20.03.2018 185 (xv) \\nDate on which forwarded to court:- 186 (xvi) Under Acts & Sections: U/s 363, 376, 506 IPC, \\n8 of Goa Children\\'s Act and Sec 4, 8, 18712 of POCSO Act. 188 (xvii) Details of \\nbailers/sureties 189Name: 190Occupation 191Identification....... 192Father\\'s name: Address:..... \\n193 (xvii) Previous convictions with case references... 194 (xix) Status of the accused: \\nJUDICIAL CUSTODY. 195Forwarded / Bailed by Police / Bailed by Court / Police Custody / \\nAbsconding / 196JUDICIAL CUSTODY / Proclaimed offender (tick\\'\\' applicable portion) 197<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:58:03 [engine.py:317] Added request chatcmpl-4e5581e05390466bb885557d4b80edce.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_4.txt...vLLM STDOUT: INFO:     127.0.0.1:59074 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:58:18 [logger.py:43] Received request chatcmpl-1f736116ec3a4d3c964bdb54dfacd9e2: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 20 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n193 (xvii) Previous convictions with case references... 194 (xix) Status of the accused: \\nJUDICIAL CUSTODY. 195Forwarded / Bailed by Police / Bailed by Court / Police Custody / \\nAbsconding / 196JUDICIAL CUSTODY / Proclaimed offender (tick\\'\\' applicable portion) 197 \\n\\nPage 10 \\n\\n12. Particulars of accused persons-not charge sheeted (suspect): (Use separate sheet 198for<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:58:18 [engine.py:317] Added request chatcmpl-1f736116ec3a4d3c964bdb54dfacd9e2.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_4.txt...vLLM STDOUT: INFO:     127.0.0.1:59940 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:58:34 [logger.py:43] Received request chatcmpl-3ce413f6398c4feea145c607d90220e3: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 20 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n194 (xix) Status of the accused: \\nJUDICIAL CUSTODY. 195Forwarded / Bailed by Police / Bailed by Court / Police Custody / \\nAbsconding / 196JUDICIAL CUSTODY / Proclaimed offender (tick\\'\\' applicable portion) 197 \\n\\nPage 10 \\n\\n12. Particulars of accused persons-not charge sheeted (suspect): (Use separate sheet 198for \\n\\neach suspect) 199 Sl. No: NIL. 200 (i) Name:--- 201 (ii) Father\\'s/Husband\\'s name: 202 \\n(iv)Sex................. 203 (vi) Passport No: 204 (vii) Religion 205 (ix) Occupation: ---- 206 (x) \\nAddress. 207Date of issue................. 208 (xi) Provisional criminal No. 209 (xii) Suspicion \\nApproved: 210 (xiii) Status of the accused (suspect): 211Whether verified: 212 (iii) Date/Year \\nof birth: 213 (v) Nationality: -- 214Place of issue........... 215 (viii) Whether SC/ST/OBC....... \\n216Whether verified. 217Yes/No. 218Bailed by Police/Bailed by court/Judicial Custody/Not \\narrested 219 (tick\\'\\' applicable portion). 220 (xiv) Under Acts & Sections..... 221 (xv) Any \\nspecial remarks including reasons for not charge sheeting......-- 222to be examined: 223<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_4.txt...vLLM STDOUT: INFO 12-14 04:58:34 [engine.py:317] Added request chatcmpl-3ce413f6398c4feea145c607d90220e3.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_4.txt...vLLM STDOUT: INFO:     127.0.0.1:53696 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:58:49 [logger.py:43] Received request chatcmpl-cdc0a5aaf59e4bfeb34780b1359e9b72: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 20 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n218Bailed by Police/Bailed by court/Judicial Custody/Not \\narrested 219 (tick\\'\\' applicable portion). 220 (xiv) Under Acts & Sections..... 221 (xv) Any \\nspecial remarks including reasons for not charge sheeting......-- 222to be examined: 223 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c13. \\nParticula\\nrs of \\nwitnesse\\ns Sl. No \\n\\nName \\n\\nFather\\'s/ \\nHusband\\n\\'s Name \\n\\nDate/ \\nYear of \\nbirth \\n\\nOccupat\\nion \\n\\nAddress \\n\\nType of \\nEvidence \\nto be \\ntendered<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:58:49 [engine.py:317] Added request chatcmpl-cdc0a5aaf59e4bfeb34780b1359e9b72.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_4.txt...vLLM STDOUT: INFO:     127.0.0.1:60138 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 72 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_4_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_4_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_4.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_4_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:45212 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:45224 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:59:07 [logger.py:43] Received request chatcmpl-0198fe985a4e427e847025d25fc211ce: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n13. \\nParticula\\nrs of \\nwitnesse\\ns Sl. No \\n\\nName \\n\\nFather\\'s/ \\nHusband\\n\\'s Name \\n\\nDate/ \\nYear of \\nbirth \\n\\nOccupat\\nion \\n\\nAddress \\n\\nType of \\nEvidence \\nto be \\ntendered \\n\\n1 \\n\\n2 \\n\\n3 \\n\\n4 \\n\\n5 \\n\\n6 \\n\\nGurudas \\nVinodkar \\nMrs. \\nGauri \\nVirnodkar \\n96377162\\n08 \\n\\nVinod \\nKalangut\\nkar Miss \\nPranita \\nKalangut\\nkar \\n\\nJulius \\nPereira \\nMiss \\nJessica \\nPereira \\n\\nGurudas \\nVirnodkar \\nMiss \\nPoorva \\nVirnodkar \\n\\nMrs. \\nAudrey \\nPinto \\n\\n50 yrs \\n\\nPvt. Work \\n\\nGurudas \\nVirnodkar \\n\\n25 yrs \\n\\nChild line \\nmember \\n\\n27 yrs \\n\\nStudent \\n\\n12 yrs \\n\\nNGO \\n\\nMadhu \\nVirnodkar \\n\\nMajor \\n\\nService \\n\\nAmurlim, \\nKhorlim \\nMapusa \\nBardez \\nGoa \\n\\nComplain\\na nt \\nPanch \\nWitness \\n224 \\n\\nPanch \\nWitness \\n225 \\n\\nWitness \\n226 \\n\\nWitness \\n227 \\n\\nWitness \\n228 \\n\\nH.No. \\n514, \\nCouncilor \\nMerces \\nTiswadi \\nGoa \\n\\nA-2, \\nKamat \\nEnclaves, \\nAldona \\nBardez \\nGoa \\n\\nAmurlim, \\nKhorlim \\nMapusa \\nBardez \\nGoa \\n\\nOne Stop \\nCentre, \\nPanaji \\nGoa \\n\\nJaten \\n\\nShri. \\n\\n47 yrs \\n\\nService \\n\\nH.No. 85,  Witness \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cPopy \\n\\nGurudas \\nVirnodkar \\n\\n21 yrs \\n\\nChild \\nLine \\nTeam \\n\\n7 \\n\\nVishram \\nGadekar \\nMiss. \\nVinita \\nGadekar \\n\\nsumnya 231 \\n\\nPage 11 \\n\\n8 \\n\\n9 \\n\\n10 \\n\\n11 \\n\\nMajor \\n\\nM.O \\n\\nDr. \\nRohan \\nMardolk\\nar \\n\\nG. \\nMardolk\\nar \\n\\nDr. Analni \\nD\\'mello \\n\\nP. \\nKorgaonk\\nar \\n\\nMajor \\n\\nSenior \\nResident \\n\\nDr. Manu \\nDr. \\nSanjay \\nKorgaonk\\nar \\n\\nDr. Sunil \\nChimbolk\\nar \\n\\nMajor \\n\\nM. O. \\n\\nShrikant \\nChimbolk\\nar \\n\\nMajor \\n\\nAssistant \\nLecturer \\n\\n229 \\n\\nWitness \\n230 \\n\\nnear \\nKrishna \\nTemple, \\nAmurlim \\nKhorlim \\nMapusa \\n\\nH.No. \\n36/11, \\nTuvarwad\\no, Colvale \\nBardez \\n\\nGoa \\nMedical \\nCollege, \\nBamboli\\nm Goa \\n\\nGoa \\nMedical \\nCollege, \\nBamboli\\nm Goa \\n\\nGMC \\nBlood \\nBank, \\nBamboli\\nm Goa \\n\\nGMC \\nBamboli\\nm Goa \\n\\nW \\n\\nWitness \\n233 \\n\\nWitness \\n234 \\n\\nWitness \\n235 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c12 \\n\\n13 \\n\\nMs. Reina \\nS. \\nFernande\\ns \\n\\nMajor \\n\\nHon\\'ble \\nJudge \\n\\nShri \\nParesh \\nRamnath\\nkar \\n\\nGunanan\\nd \\nRamnath\\nkar \\n\\n27 yrs \\n\\nPolice \\nSub \\nInspector \\n\\nWitness \\n236 \\n\\nI.O. 237 \\n\\nJudicial \\nMagistrat\\ne First \\nClass, \"F\" \\nCourt, \\nMapusa \\nBardez \\nGoa \\n\\nMapusa \\nPolice \\nStation, \\nMapusa \\nBardez \\nGoa \\n\\n230 238Zay 239œâœÇ 240pwq 24110 242 \\n14. If FIR is false, indicate action taken or proposed to be taken u/s.182/211 I.P.C.:--- 243 \\n15. Result of Laboratory analysis: 244 \\n16. Brief facts of the case (add separate sheet, if necessary). 245PWY Swagle Niyur 246As per \\nAnnexure A 247 \\n17. Refer Notice served: 248Yes/No 249Date: 250 (Acknowledgement to be placed) 251 \\n18. Dispatched On: 252 \\n19. No of enclosures: As per index. 253 \\n20. List of enclosures: As annex<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:59:07 [engine.py:317] Added request chatcmpl-0198fe985a4e427e847025d25fc211ce.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_5.txt...vLLM STDOUT: INFO:     127.0.0.1:45226 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:59:10 [logger.py:43] Received request chatcmpl-6ce693d2a22942368ad62dfdf2d8ec23: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c13. \\nParticula\\nrs of \\nwitnesse\\ns Sl. No \\n\\nName \\n\\nFather\\'s/ \\nHusband\\n\\'s Name \\n\\nDate/ \\nYear of \\nbirth \\n\\nOccupat\\nion \\n\\nAddress \\n\\nType of \\nEvidence \\nto be \\ntendered \\n\\n1 \\n\\n2 \\n\\n3 \\n\\n4 \\n\\n5 \\n\\n6 \\n\\nGurudas \\nVinodkar \\nMrs. \\nGauri \\nVirnodkar \\n96377162\\n08 \\n\\nVinod \\nKalangut\\nkar Miss \\nPranita \\nKalangut\\nkar \\n\\nJulius \\nPereira \\nMiss \\nJessica \\nPereira \\n\\nGurudas \\nVirnodkar \\nMiss \\nPoorva \\nVirnodkar \\n\\nMrs. \\nAudrey \\nPinto \\n\\n50 yrs \\n\\nPvt. Work \\n\\nGurudas \\nVirnodkar \\n\\n25 yrs \\n\\nChild line \\nmember \\n\\n27 yrs \\n\\nStudent \\n\\n12 yrs \\n\\nNGO \\n\\nMadhu \\nVirnodkar \\n\\nMajor \\n\\nService \\n\\nAmurlim, \\nKhorlim \\nMapusa \\nBardez \\nGoa \\n\\nComplain\\na nt \\nPanch \\nWitness \\n224 \\n\\nPanch \\nWitness \\n225 \\n\\nWitness \\n226 \\n\\nWitness \\n227 \\n\\nWitness \\n228 \\n\\nH.No. \\n514, \\nCouncilor \\nMerces \\nTiswadi \\nGoa \\n\\nA-2, \\nKamat \\nEnclaves, \\nAldona \\nBardez \\nGoa \\n\\nAmurlim, \\nKhorlim \\nMapusa \\nBardez \\nGoa \\n\\nOne Stop \\nCentre, \\nPanaji \\nGoa \\n\\nJaten \\n\\nShri. \\n\\n47 yrs \\n\\nService \\n\\nH.No. 85,  Witness \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cPopy \\n\\nGurudas \\nVirnodkar \\n\\n21 yrs \\n\\nChild \\nLine \\nTeam \\n\\n7<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:59:10 [engine.py:317] Added request chatcmpl-6ce693d2a22942368ad62dfdf2d8ec23.\n",
            "\u001b[2KProcessing 3 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_5.txt...vLLM STDOUT: INFO:     127.0.0.1:37390 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:59:25 [logger.py:43] Received request chatcmpl-1813d36c79b544368c68201ae976b1fd: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n514, \\nCouncilor \\nMerces \\nTiswadi \\nGoa \\n\\nA-2, \\nKamat \\nEnclaves, \\nAldona \\nBardez \\nGoa \\n\\nAmurlim, \\nKhorlim \\nMapusa \\nBardez \\nGoa \\n\\nOne Stop \\nCentre, \\nPanaji \\nGoa \\n\\nJaten \\n\\nShri. \\n\\n47 yrs \\n\\nService \\n\\nH.No. 85,  Witness \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cPopy \\n\\nGurudas \\nVirnodkar \\n\\n21 yrs \\n\\nChild \\nLine \\nTeam \\n\\n7 \\n\\nVishram \\nGadekar \\nMiss. \\nVinita \\nGadekar \\n\\nsumnya 231 \\n\\nPage 11 \\n\\n8 \\n\\n9 \\n\\n10 \\n\\n11 \\n\\nMajor \\n\\nM.O \\n\\nDr. \\nRohan \\nMardolk\\nar \\n\\nG. \\nMardolk\\nar \\n\\nDr. Analni \\nD\\'mello \\n\\nP. \\nKorgaonk\\nar \\n\\nMajor \\n\\nSenior \\nResident \\n\\nDr. Manu \\nDr. \\nSanjay \\nKorgaonk\\nar \\n\\nDr. Sunil \\nChimbolk\\nar \\n\\nMajor \\n\\nM. O. \\n\\nShrikant \\nChimbolk\\nar \\n\\nMajor \\n\\nAssistant \\nLecturer \\n\\n229 \\n\\nWitness \\n230 \\n\\nnear \\nKrishna \\nTemple, \\nAmurlim \\nKhorlim \\nMapusa \\n\\nH.No. \\n36/11, \\nTuvarwad\\no, Colvale \\nBardez \\n\\nGoa \\nMedical \\nCollege, \\nBamboli\\nm Goa \\n\\nGoa \\nMedical \\nCollege, \\nBamboli\\nm Goa \\n\\nGMC \\nBlood \\nBank, \\nBamboli\\nm Goa \\n\\nGMC \\nBamboli\\nm Goa \\n\\nW \\n\\nWitness \\n233 \\n\\nWitness \\n234 \\n\\nWitness \\n235 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c12 \\n\\n13 \\n\\nMs. Reina \\nS. \\nFernande\\ns \\n\\nMajor \\n\\nHon\\'ble \\nJudge<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:59:26 [engine.py:317] Added request chatcmpl-1813d36c79b544368c68201ae976b1fd.\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_5.txt...vLLM STDOUT: INFO:     127.0.0.1:49656 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:59:41 [logger.py:43] Received request chatcmpl-ffa2fda98174448aa78e325a53a95434: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n36/11, \\nTuvarwad\\no, Colvale \\nBardez \\n\\nGoa \\nMedical \\nCollege, \\nBamboli\\nm Goa \\n\\nGoa \\nMedical \\nCollege, \\nBamboli\\nm Goa \\n\\nGMC \\nBlood \\nBank, \\nBamboli\\nm Goa \\n\\nGMC \\nBamboli\\nm Goa \\n\\nW \\n\\nWitness \\n233 \\n\\nWitness \\n234 \\n\\nWitness \\n235 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c12 \\n\\n13 \\n\\nMs. Reina \\nS. \\nFernande\\ns \\n\\nMajor \\n\\nHon\\'ble \\nJudge \\n\\nShri \\nParesh \\nRamnath\\nkar \\n\\nGunanan\\nd \\nRamnath\\nkar \\n\\n27 yrs \\n\\nPolice \\nSub \\nInspector \\n\\nWitness \\n236 \\n\\nI.O. 237 \\n\\nJudicial \\nMagistrat\\ne First \\nClass, \"F\" \\nCourt, \\nMapusa \\nBardez \\nGoa \\n\\nMapusa \\nPolice \\nStation, \\nMapusa \\nBardez \\nGoa \\n\\n230 238Zay 239œâœÇ 240pwq 24110 242 \\n14. If FIR is false, indicate action taken or proposed to be taken u/s.182/211 I.P.C.:--- 243 \\n15. Result of Laboratory analysis: 244 \\n16. Brief facts of the case (add separate sheet, if necessary). 245PWY Swagle Niyur 246As per \\nAnnexure A 247 \\n17. Refer Notice served: 248Yes/No 249Date: 250 (Acknowledgement to be placed) 251 \\n18. Dispatched On: 252 \\n19. No of enclosures: As per index. 253 \\n20. List of enclosures: As annex<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_5.txt...vLLM STDOUT: INFO 12-14 04:59:41 [engine.py:317] Added request chatcmpl-ffa2fda98174448aa78e325a53a95434.\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_5.txt...vLLM STDOUT: INFO:     127.0.0.1:57000 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 45 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_5_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_5_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_5.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_5_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:45524 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:45540 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 04:59:59 [logger.py:43] Received request chatcmpl-5bce05a328544fb28df92171d3ca4295: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nure A 247 \\n17. Refer Notice served: 248Yes/No 249Date: 250 (Acknowledgement to be placed) 251 \\n18. Dispatched On: 252 \\n19. No of enclosures: As per index. 253 \\n20. List of enclosures: As annexed 254Forwarded by Officer in charge 255 Name: Shri. Tushar \\nG. Lotliker. 256Rank: Police Inspector. 257Mapusa Police Station 258PSE 259Signature of \\ninvestigating officer 260Submitting Final report/Charge Sheet 261Name: Paresh G. \\nRamnathkar. 262Rank: Police Sub Inspector. 263Mapusa Police Station. 264NOTE: The \\nexamination report in respect of the exhibits preserved during medical examination of victim \\ngirl and accused person will be submitted to Hon'ble Court on receipt of the same from FSL \\nVerna-Goa. 265 \\nPage 12 \\n\\nCommitt. 26610/3123 267ANJUNA POLICE STAT 268ANJUNA 2691017123-APP FLA Adisappoint. \\n270arden compunl 271paml 27224/ By-Seniany 273come 274Police Inspector 275Anjuna Police Station \\n276Outward No:-4239 277Date:- 278FINAL FORM/REPORT 279 (Under Section 173 Cr. P. –°.) \\n28026/06/23 281IN THE COURT OF HON'BL JUDICIAL MAGISTRATE 282FIRST CLASS AT MA PUSA \\nGOA. 283 \\n\\n1.  Dist-North P.S.-Anjuna Year. 2023 FIR No. 82/2023 284 Date. 15/05/2023. 285 \\n\\n \\n \\n \\n \\n\\x0c2.  Charge Sheet No. 6612023 3. Date. 26/06/2023. 286 \\n\\nPage 13 \\n\\n4.  (i) Act: I.P.C. Section:- 448, 376 –Ü–†–°. 287 (ii) Act: 288== 289Section: 290 (iii) Act 291Section: 292 \\n\\n(iv)Other Acts & Sections:. 293 \\n\\n5.  Type of Final / Report: Charge Sheet 294(Not Charge sheeted for want of Evidence /FIR \\n\\n295True, undetected/ FIR True, Untraced/FIR True, 296Offence Abated/FIR Unoccurred. 297 \\n(Tick' applicable portion) 298 \\n\\n6.  If FIR Unoccurred: False /Mistake of Fact/Mistake 299of law/Non Cognizable/Civil in Nature. \\n\\n300 (tick' applicable portion). 301 \\n\\n7.  If Charge sheet: Original / Supplementary. 302(tick 303applicable portion). 304 \\n\\n8.  Name of I.O. Miss. Sneha S. Sawal, LPSI 305attached to Anjuna Police Station (at the time \\n\\nof 306Charge sheet) 307 \\n\\nPage 14 \\n\\n(a) Name of complainant informant: Miss Jaya 308Joshi D/o Bhagwat Prasad, age 49 years, \\nOccp Business, R/o 11.No. 309652-5-A, 2nd Floor, Newtons Villa, Porta Waddo, Siolim, Bardez \\nGoa N/o C/o Alok Joshi, P-04, Tilia, Nahar Amrit Sahakti, Chandivali, Mumbai Maharashtra. 310 \\n(b) Father's/Husband's name: Shri. Bhagwat Prasad. 311 \\n10. Details of properties /Articles/Documents recovered / 312seized during Investigation and \\nrelied upon (separate list can 313be attached, if necessary). 314 \\n\\nSr No () \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\nP.S. \\nProperty \\nReg. No. \\n\\n1. \\n\\nAttached \\nseparate \\nsheet \\n\\nFrom \\nwhom \\n/where \\nrecovered \\nor seized \\n\\nDisposal \\n\\n315 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c! 316 \\n\\nPage 15 \\n\\n10. Details of properties/Articles/Documents Recovered/<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 04:59:59 [engine.py:317] Added request chatcmpl-5bce05a328544fb28df92171d3ca4295.\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_6.txt...vLLM STDOUT: INFO:     127.0.0.1:45552 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:00:05 [logger.py:43] Received request chatcmpl-6f53b5bafbf2452d873a0a858e2aee1f: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nure A 247 \\n17. Refer Notice served: 248Yes/No 249Date: 250 (Acknowledgement to be placed) 251 \\n18. Dispatched On: 252 \\n19. No of enclosures: As per index. 253 \\n20. List of enclosures: As annexed 254Forwarded by Officer in charge 255 Name: Shri. Tushar \\nG. Lotliker. 256Rank: Police Inspector. 257Mapusa Police Station 258PSE 259Signature of \\ninvestigating officer 260Submitting Final report/Charge Sheet 261Name: Paresh G. \\nRamnathkar. 262Rank: Police Sub Inspector. 263Mapusa Police Station. 264NOTE: The \\nexamination report in respect of the exhibits preserved during medical examination of victim \\ngirl and accused person will be submitted to Hon\\'ble Court on receipt of the same from FSL \\nVerna-Goa. 265 \\nPage 12<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:00:05 [engine.py:317] Added request chatcmpl-6f53b5bafbf2452d873a0a858e2aee1f.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_6.txt...vLLM STDOUT: INFO:     127.0.0.1:45566 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:00:20 [logger.py:43] Received request chatcmpl-611b170658954c6cb8a1603bb66f9565: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n263Mapusa Police Station. 264NOTE: The \\nexamination report in respect of the exhibits preserved during medical examination of victim \\ngirl and accused person will be submitted to Hon\\'ble Court on receipt of the same from FSL \\nVerna-Goa. 265 \\nPage 12 \\n\\nCommitt. 26610/3123 267ANJUNA POLICE STAT 268ANJUNA 2691017123-APP FLA Adisappoint. \\n270arden compunl 271paml 27224/ By-Seniany 273come 274Police Inspector 275Anjuna Police Station \\n276Outward No:-4239 277Date:- 278FINAL FORM/REPORT 279 (Under Section 173 Cr. P. –°.) \\n28026/06/23 281IN THE COURT OF HON\\'BL JUDICIAL MAGISTRATE 282FIRST CLASS AT MA PUSA \\nGOA. 283 \\n\\n1.  Dist-North P.S.-Anjuna Year. 2023 FIR No. 82/2023 284 Date. 15/05/2023. 285 \\n\\n \\n \\n \\n \\n\\x0c2.  Charge Sheet No. 6612023 3. Date. 26/06/2023. 286 \\n\\nPage 13 \\n\\n4.  (i) Act: I.P.C. Section:- 448, 376 –Ü–†–°. 287 (ii) Act: 288== 289Section: 290 (iii) Act 291Section: 292 \\n\\n(iv)Other Acts & Sections:. 293 \\n\\n5.  Type of Final / Report: Charge Sheet 294(Not Charge sheeted for want of Evidence /FIR<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_6.txt...vLLM STDOUT: INFO 12-14 05:00:20 [engine.py:317] Added request chatcmpl-611b170658954c6cb8a1603bb66f9565.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_6.txt...vLLM STDOUT: INFO:     127.0.0.1:42422 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:00:36 [logger.py:43] Received request chatcmpl-c4e055416fbe47509b7afc381ee8b747: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n287 (ii) Act: 288== 289Section: 290 (iii) Act 291Section: 292 \\n\\n(iv)Other Acts & Sections:. 293 \\n\\n5.  Type of Final / Report: Charge Sheet 294(Not Charge sheeted for want of Evidence /FIR \\n\\n295True, undetected/ FIR True, Untraced/FIR True, 296Offence Abated/FIR Unoccurred. 297 \\n(Tick\\' applicable portion) 298 \\n\\n6.  If FIR Unoccurred: False /Mistake of Fact/Mistake 299of law/Non Cognizable/Civil in Nature. \\n\\n300 (tick\\' applicable portion). 301 \\n\\n7.  If Charge sheet: Original / Supplementary. 302(tick 303applicable portion). 304 \\n\\n8.  Name of I.O. Miss. Sneha S. Sawal, LPSI 305attached to Anjuna Police Station (at the time \\n\\nof 306Charge sheet) 307 \\n\\nPage 14<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:00:36 [engine.py:317] Added request chatcmpl-c4e055416fbe47509b7afc381ee8b747.\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_6.txt...vLLM STDOUT: INFO:     127.0.0.1:35904 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:00:51 [logger.py:43] Received request chatcmpl-76dfa707a89644e6ae9cc3a05532ca60: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nMiss. Sneha S. Sawal, LPSI 305attached to Anjuna Police Station (at the time \\n\\nof 306Charge sheet) 307 \\n\\nPage 14 \\n\\n(a) Name of complainant informant: Miss Jaya 308Joshi D/o Bhagwat Prasad, age 49 years, \\nOccp Business, R/o 11.No. 309652-5-A, 2nd Floor, Newtons Villa, Porta Waddo, Siolim, Bardez \\nGoa N/o C/o Alok Joshi, P-04, Tilia, Nahar Amrit Sahakti, Chandivali, Mumbai Maharashtra. 310 \\n(b) Father\\'s/Husband\\'s name: Shri. Bhagwat Prasad. 311 \\n10. Details of properties /Articles/Documents recovered / 312seized during Investigation and \\nrelied upon (separate list can 313be attached, if necessary). 314 \\n\\nSr No () \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\nP.S. \\nProperty \\nReg. No. \\n\\n1. \\n\\nAttached \\nseparate \\nsheet \\n\\nFrom \\nwhom \\n/where \\nrecovered \\nor seized \\n\\nDisposal \\n\\n315 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c! 316 \\n\\nPage 15 \\n\\n10. Details of properties/Articles/Documents Recovered/<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:00:51 [engine.py:317] Added request chatcmpl-76dfa707a89644e6ae9cc3a05532ca60.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_6.txt...vLLM STDOUT: INFO:     127.0.0.1:60980 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 58 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_6_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_6_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_6.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_6_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:57914 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:57924 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:01:09 [logger.py:43] Received request chatcmpl-c9ea6e1805d94929a917a2fc15ff0c5b: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n. \\nProperty \\nReg. No. \\n\\n1. \\n\\nAttached \\nseparate \\nsheet \\n\\nFrom \\nwhom \\n/where \\nrecovered \\nor seized \\n\\nDisposal \\n\\n315 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c! 316 \\n\\nPage 15 \\n\\n10. Details of properties/Articles/Documents Recovered/ 317Scized during investigation and \\n\\nRelied upon. 318 \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\n/23 \\n\\nDisposal \\n\\nSent at \\nGSFSL \\nVerna for \\nexaminati \\non and \\nreport 319 \\n\\nFrom \\nwhom/Wh\\nere \\nrecovered \\nor seized \\n\\nAttached \\nunder \\narrest cum \\nattachment \\npanchanam\\na dated \\n15/05/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n82/2023 u/s \\n448. 376 \\n\\nSI. No \\n\\nEstimated \\nValue (Rs.) \\n\\nProperty \\nDescriptio\\nn \\n\\n01 \\n\\n100/- \\n\\nThis \\ngreenish \\ncolor cloth \\nline sealed \\nenvelope \\ncontains in \\nit one long \\nsleeves \\nshirt having \\non it \\ncolourled \\nlight black, \\ngrey, green \\nhorizontal \\nand vertical \\nlines duly \\nattached \\nunder the \\narresi cum \\nattachment \\npanchanam\\na \\n\\nPage 16 \\n\\n| | | panchanama dated 15/05/2023 concerned in Anjuna P.S. Cr. No. 82/2023 u/s 448. 376 IPC \\n\\n \\n \\n \\n\\x0cand marked as \"Exhibit -1\" | IPC | | | 320 | \\n| :--- | :--- | :--- | :--- | :--- | :--- | \\n| 2. | 200/- | This greenish color cloth line sealed envelope contains in it one grey colour long \\njeans pant duly attached under the arrest cum attachment panchanama dated 15/05/2023 \\nconcerned in Anjuna P.S. Cr. No. 82/2023 u/s 448, 376 IPC. | /23 | Attached under the cum \\narrest attachment panchanama dated 15/05/2023 concerned in Anjuna P.S. Cr. No. 82/2023 \\nu/s 448. 376 IPC. | Sent al GSFSL Verna for examinati on and report 321 | \\nPage 17 \\n\\n| | | 376 11 and marked as Exhibit-2 | | | | 322 | \\n| :--- | :--- | :--- | :--- | :--- | :--- | \\n| 03. | 100/- | This greenish colour cloth line sealed envelope contains in it one grey colour \\npanty duly attached under scene of offence panchanama dated 16/05/2023 concerned in \\nAnjuna P.S Cr. No. 82/2023 u/s 448, 376 IPC and marked as \"Exhibit-A\". | /23 | Attached under \\nscene of offence panchanama dated 16/05/2023 concerned in Anjuna P.S Cr. No. 82/2023 u/s \\n448, 376 IPC. | Sent at GSFSL Verna for examina tion and report 323 | \\n| 04. | 200/- | This sealed colour cloth line envelope contains in it one short sleeves t-shirt | \\n/23 | Attached under scene of offence panchanama | Sent at GSFSL Verna for 324 | \\nPage 18 \\n\\nexamina \\ntion and \\nreport. \\n\\ndated \\n16/05/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n82/2023 \\nu/s 448. \\n376 IPC. \\n\\nhaving \\nblack & \\nwhite \\ncolour \\nhorizontal \\nlines on it \\nduly \\nattached \\nunder the \\nscene of \\noffence \\npanchana\\nma dated- \\n16/05/2023 \\nconcern in \\nAnjuna P.S. \\nCr. No. \\n82/2023 \\nu/s 1448. \\n376 IPC \\nand \\nmarked as \\n\\n \\n \\n \\n\\x0c05. \\n\\n250/- \\n\\nSent at \\nGSFSL \\nVerna for \\nexamina \\ntion and \\nreport. 326<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:01:09 [engine.py:317] Added request chatcmpl-c9ea6e1805d94929a917a2fc15ff0c5b.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_7.txt...vLLM STDOUT: INFO:     127.0.0.1:57938 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:01:12 [logger.py:43] Received request chatcmpl-316544109d3045178d75e9a69f33afe3: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n. \\nProperty \\nReg. No. \\n\\n1. \\n\\nAttached \\nseparate \\nsheet \\n\\nFrom \\nwhom \\n/where \\nrecovered \\nor seized \\n\\nDisposal \\n\\n315 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c! 316 \\n\\nPage 15 \\n\\n10. Details of properties/Articles/Documents Recovered/ 317Scized during investigation and \\n\\nRelied upon. 318 \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\n/23 \\n\\nDisposal \\n\\nSent at \\nGSFSL \\nVerna for \\nexaminati \\non and \\nreport 319 \\n\\nFrom \\nwhom/Wh\\nere \\nrecovered \\nor seized \\n\\nAttached \\nunder \\narrest cum \\nattachment \\npanchanam\\na dated \\n15/05/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n82/2023 u/s \\n448. 376 \\n\\nSI. No \\n\\nEstimated \\nValue (Rs.) \\n\\nProperty \\nDescriptio\\nn \\n\\n01 \\n\\n100/- \\n\\nThis \\ngreenish \\ncolor cloth \\nline sealed \\nenvelope \\ncontains in \\nit one long \\nsleeves \\nshirt having \\non it \\ncolourled \\nlight black, \\ngrey, green \\nhorizontal \\nand vertical \\nlines duly \\nattached \\nunder the \\narresi cum \\nattachment \\npanchanam\\na \\n\\nPage 16 \\n\\n| | | panchanama dated 15/05/2023 concerned in Anjuna P.S. Cr. No. 82/2023 u/s 448. 376 IPC<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:01:12 [engine.py:317] Added request chatcmpl-316544109d3045178d75e9a69f33afe3.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_7.txt...vLLM STDOUT: INFO:     127.0.0.1:57944 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:01:28 [logger.py:43] Received request chatcmpl-a5b4720591194fdda714f5c42fddd645: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nNo. 82/2023 u/s 448. 376 IPC \\n\\n \\n \\n \\n\\x0cand marked as \"Exhibit -1\" | IPC | | | 320 | \\n| :--- | :--- | :--- | :--- | :--- | :--- | \\n| 2. | 200/- | This greenish color cloth line sealed envelope contains in it one grey colour long \\njeans pant duly attached under the arrest cum attachment panchanama dated 15/05/2023 \\nconcerned in Anjuna P.S. Cr. No. 82/2023 u/s 448, 376 IPC. | /23 | Attached under the cum \\narrest attachment panchanama dated 15/05/2023 concerned in Anjuna P.S. Cr. No. 82/2023 \\nu/s 448. 376 IPC. | Sent al GSFSL Verna for examinati on and report 321 | \\nPage 17<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:01:28 [engine.py:317] Added request chatcmpl-a5b4720591194fdda714f5c42fddd645.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_7.txt...vLLM STDOUT: INFO:     127.0.0.1:51856 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:01:43 [logger.py:43] Received request chatcmpl-04c212084457427787c7b17f4c347a11: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n82/2023 \\nu/s 448. 376 IPC. | Sent al GSFSL Verna for examinati on and report 321 | \\nPage 17 \\n\\n| | | 376 11 and marked as Exhibit-2 | | | | 322 | \\n| :--- | :--- | :--- | :--- | :--- | :--- | \\n| 03. | 100/- | This greenish colour cloth line sealed envelope contains in it one grey colour \\npanty duly attached under scene of offence panchanama dated 16/05/2023 concerned in \\nAnjuna P.S Cr. No. 82/2023 u/s 448, 376 IPC and marked as \"Exhibit-A\". | /23 | Attached under \\nscene of offence panchanama dated 16/05/2023 concerned in Anjuna P.S Cr. No. 82/2023 u/s \\n448, 376 IPC. | Sent at GSFSL Verna for examina tion and report 323 | \\n| 04. | 200/- | This sealed colour cloth line envelope contains in it one short sleeves t-shirt | \\n/23 | Attached under scene of offence panchanama | Sent at GSFSL Verna for 324 | \\nPage 18 \\n\\nexamina \\ntion and \\nreport. \\n\\ndated \\n16/05/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n82/2023 \\nu/s 448. \\n376 IPC.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:01:43 [engine.py:317] Added request chatcmpl-04c212084457427787c7b17f4c347a11.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_7.txt...vLLM STDOUT: INFO:     127.0.0.1:37074 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:01:59 [logger.py:43] Received request chatcmpl-3be7f747d25c40c4b97fe8097c73e25f: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n82/2023 \\nu/s 448. \\n376 IPC. \\n\\nhaving \\nblack & \\nwhite \\ncolour \\nhorizontal \\nlines on it \\nduly \\nattached \\nunder the \\nscene of \\noffence \\npanchana\\nma dated- \\n16/05/2023 \\nconcern in \\nAnjuna P.S. \\nCr. No. \\n82/2023 \\nu/s 1448. \\n376 IPC \\nand \\nmarked as \\n\\n \\n \\n \\n\\x0c05. \\n\\n250/- \\n\\nSent at \\nGSFSL \\nVerna for \\nexamina \\ntion and \\nreport. 326<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_7.txt...vLLM STDOUT: INFO 12-14 05:01:59 [engine.py:317] Added request chatcmpl-3be7f747d25c40c4b97fe8097c73e25f.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_7.txt...vLLM STDOUT: INFO:     127.0.0.1:54734 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 62 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_7_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_7_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_7.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_7_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:48212 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:48226 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:02:16 [logger.py:43] Received request chatcmpl-1569b0145c204e828a8fd119e9bdee30: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nAnjuna P.S. \\nCr. No. \\n82/2023 \\nu/s 1448. \\n376 IPC \\nand \\nmarked as \\n\\n \\n \\n \\n\\x0c05. \\n\\n250/- \\n\\nSent at \\nGSFSL \\nVerna for \\nexamina \\ntion and \\nreport. 326 \\n\\nAttached \\nunder \\nscene of \\noffence \\npanchanam\\na Viel dated \\n16/05/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n82/2023 u/s \\n448. 376 \\nIPC. \\n\\n/23 \\n\\n\"Exhibit- \\nB\" \\n\\nThis \\ngreenish \\ncolour cloth \\nline sealed \\nenvelope \\ncontains in \\nit one bed \\nsheet \\nhaving blue, \\nwhite & \\ngreen \\ncolour \\ndesign on it \\nduly \\nattached \\nunder the \\nscene of \\noffence \\npanchanam\\na \\n\\nPage 19 \\n\\n| | | seene of offence panchanama dated- 16/05/2023 concern in Anjuna P.S. Cr. No. 82/2023 \\nu/s 448, 376 IPC and marked as \"Marked- C | Cr. No. 82/2023 u/s 448, 376 IPC. | | | 327 | \\n| :--- | :--- | :--- | :--- | :--- | :--- | \\n| 96 | 250/- | This greenish colour cloth line sealed envelope contains in it one red colour bed \\nsheet duly attached under the scene of offence panchanama dated- 16/05/2023 concern in \\nAnjuna P.S. Cr. No. 82/2023 u/s 448. | /23 | Attached under scent of offence panchanama dated \\n16/05/2023 concerned in Anjuna P.S. Cr No 82/2023 u/s 448. 376 | Sent at GSFSL Verna for \\nexamina tion and report 328 | \\nPage 20 \\n\\n| | | 376 IPC and marked as \"Exhibit-D\". | IPC. | | | 329 | \\n| :--- | :--- | :--- | :--- | :--- | :--- | \\n| 07 | 100/- | This greenish colour cloth line sealed! envelope contains in it one cream colour \\npillow cover duly attached under scene of offence panchanama dated- 16/05/2023 concern in \\nAnjuna P.S. Cr. No. 82/2023 u/s 448, 376 IPC and marked \"Exhibit E\". | /23 | Attached under \\nscene of offence panchanama dated 16/05/2023 concerned in Anjuna P.S. Cr. No. 82/2023 u/s \\n\\n \\n\\x0c448. 376 IPC. | Sent at GSFSL Verna for examina tion and report. 330 | \\n| 08. | 50/- | This greenish colour cloth line sealed envelope contains in | 123 | Attached under \\nscene of offence | Sent at GSFSL Verna 331 | \\nPage 21 \\n\\nMelat 332chain 333 \\n\\nfor \\nexamina \\ntion and \\nreport. \\n\\npanchana\\nma dated \\n16/05/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n82/2023 \\nu/s 448, \\n376 IPC. \\n\\nit one \\ndamaged \\nsilver \\nmetal \\ncolour \\nround \\nshape \\nchain and \\none rosary \\nchain \\nhaving \\ntransparen\\nt beads \\nand cross \\nat the \\ncentre \\nduly \\nattached \\nunder the \\nscene of \\noffence \\npanchana\\nma \\ndated-16/0\\n5/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n82/2023 \\nu/s 448, \\n376 IPC \\nand \\nmarked as \\n\"Exhibit - \\n\\n \\n \\n \\n \\n\\x0cF\" \\n\\n(Sncha S. Sawal) 335 LPSI. Anjuna P.S. 336 \\n\\nPage 22 \\n\\n11. Particulars of accused persons Charge-sheeted 337 (ise Separate sheet for each \\n\\naccused). 338Sr. No. A-1 339<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:02:16 [engine.py:317] Added request chatcmpl-1569b0145c204e828a8fd119e9bdee30.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_8.txt...vLLM STDOUT: INFO:     127.0.0.1:48228 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:02:21 [logger.py:43] Received request chatcmpl-bdff8fdfa78a4ae1bbf57e8b2152f7ca: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n \\nAnjuna P.S. \\nCr. No. \\n82/2023 \\nu/s 1448. \\n376 IPC \\nand \\nmarked as \\n\\n \\n \\n \\n\\x0c05. \\n\\n250/- \\n\\nSent at \\nGSFSL \\nVerna for \\nexamina \\ntion and \\nreport. 326 \\n\\nAttached \\nunder \\nscene of \\noffence \\npanchanam\\na Viel dated \\n16/05/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n82/2023 u/s \\n448. 376 \\nIPC. \\n\\n/23 \\n\\n\"Exhibit- \\nB\" \\n\\nThis \\ngreenish \\ncolour cloth \\nline sealed \\nenvelope \\ncontains in \\nit one bed \\nsheet \\nhaving blue, \\nwhite & \\ngreen \\ncolour \\ndesign on it \\nduly \\nattached \\nunder the \\nscene of \\noffence \\npanchanam\\na \\n\\nPage 19<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:02:21 [engine.py:317] Added request chatcmpl-bdff8fdfa78a4ae1bbf57e8b2152f7ca.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_8.txt...vLLM STDOUT: INFO:     127.0.0.1:41478 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:02:36 [logger.py:43] Received request chatcmpl-607e97dca4a54e3e94de43b9d7ae090e: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n82/2023 u/s \\n448. 376 \\nIPC. \\n\\n/23 \\n\\n\"Exhibit- \\nB\" \\n\\nThis \\ngreenish \\ncolour cloth \\nline sealed \\nenvelope \\ncontains in \\nit one bed \\nsheet \\nhaving blue, \\nwhite & \\ngreen \\ncolour \\ndesign on it \\nduly \\nattached \\nunder the \\nscene of \\noffence \\npanchanam\\na \\n\\nPage 19 \\n\\n| | | seene of offence panchanama dated- 16/05/2023 concern in Anjuna P.S. Cr. No. 82/2023 \\nu/s 448, 376 IPC and marked as \"Marked- C | Cr. No. 82/2023 u/s 448, 376 IPC. | | | 327 | \\n| :--- | :--- | :--- | :--- | :--- | :--- | \\n| 96 | 250/- | This greenish colour cloth line sealed envelope contains in it one red colour bed \\nsheet duly attached under the scene of offence panchanama dated- 16/05/2023 concern in \\nAnjuna P.S. Cr. No. 82/2023 u/s 448. | /23 | Attached under scent of offence panchanama dated \\n16/05/2023 concerned in Anjuna P.S. Cr No 82/2023 u/s 448. 376 | Sent at GSFSL Verna for \\nexamina tion and report 328 | \\nPage 20<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:02:36 [engine.py:317] Added request chatcmpl-607e97dca4a54e3e94de43b9d7ae090e.\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_8.txt...vLLM STDOUT: INFO:     127.0.0.1:49578 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:02:52 [logger.py:43] Received request chatcmpl-32bd8fe63c614bcebadcaaa6076dd25e: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n| /23 | Attached under scent of offence panchanama dated \\n16/05/2023 concerned in Anjuna P.S. Cr No 82/2023 u/s 448. 376 | Sent at GSFSL Verna for \\nexamina tion and report 328 | \\nPage 20 \\n\\n| | | 376 IPC and marked as \"Exhibit-D\". | IPC. | | | 329 | \\n| :--- | :--- | :--- | :--- | :--- | :--- | \\n| 07 | 100/- | This greenish colour cloth line sealed! envelope contains in it one cream colour \\npillow cover duly attached under scene of offence panchanama dated- 16/05/2023 concern in \\nAnjuna P.S. Cr. No. 82/2023 u/s 448, 376 IPC and marked \"Exhibit E\". | /23 | Attached under \\nscene of offence panchanama dated 16/05/2023 concerned in Anjuna P.S. Cr. No. 82/2023 u/s \\n\\n \\n\\x0c448. 376 IPC. | Sent at GSFSL Verna for examina tion and report. 330 | \\n| 08. | 50/- | This greenish colour cloth line sealed envelope contains in | 123 | Attached under \\nscene of offence | Sent at GSFSL Verna 331 | \\nPage 21 \\n\\nMelat 332chain 333 \\n\\nfor \\nexamina \\ntion and \\nreport.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:02:52 [engine.py:317] Added request chatcmpl-32bd8fe63c614bcebadcaaa6076dd25e.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_8.txt...vLLM STDOUT: INFO:     127.0.0.1:37886 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:03:07 [logger.py:43] Received request chatcmpl-ea283d09a92343ffb21612807cc47209: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n330 | \\n| 08. | 50/- | This greenish colour cloth line sealed envelope contains in | 123 | Attached under \\nscene of offence | Sent at GSFSL Verna 331 | \\nPage 21 \\n\\nMelat 332chain 333 \\n\\nfor \\nexamina \\ntion and \\nreport. \\n\\npanchana\\nma dated \\n16/05/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n82/2023 \\nu/s 448, \\n376 IPC. \\n\\nit one \\ndamaged \\nsilver \\nmetal \\ncolour \\nround \\nshape \\nchain and \\none rosary \\nchain \\nhaving \\ntransparen\\nt beads \\nand cross \\nat the \\ncentre \\nduly \\nattached \\nunder the \\nscene of \\noffence \\npanchana\\nma \\ndated-16/0\\n5/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n82/2023 \\nu/s 448, \\n376 IPC \\nand \\nmarked as \\n\"Exhibit - \\n\\n \\n \\n \\n \\n\\x0cF\" \\n\\n(Sncha S. Sawal) 335 LPSI. Anjuna P.S. 336 \\n\\nPage 22 \\n\\n11. Particulars of accused persons Charge-sheeted 337 (ise Separate sheet for each \\n\\naccused). 338Sr. No. A-1 339<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:03:07 [engine.py:317] Added request chatcmpl-ea283d09a92343ffb21612807cc47209.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_8.txt...vLLM STDOUT: INFO:     127.0.0.1:37566 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 63 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_8_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_8_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_8.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_8_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:44982 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:44986 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:03:25 [logger.py:43] Received request chatcmpl-aa53df4869ac405193946ec9433d4357: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nF\" \\n\\n(Sncha S. Sawal) 335 LPSI. Anjuna P.S. 336 \\n\\nPage 22 \\n\\n11. Particulars of accused persons Charge-sheeted 337 (ise Separate sheet for each \\n\\naccused). 338Sr. No. A-1 339 (i) Name: Mr. Alfred Fernandes 340verified: Yes. 341Whether 342 \\n(ii) Father\\'s/Husband\\'s name:- Mr. Antonio 343Fernandes 344 (iii) Date/Year of birth: 38 \\nvears. 345 (iv) Sex: Male. 346 (v) Nationality: Indian. 347 (vi) Passport No. === 348 Date of \\nissue. = 349Place of issue. 350 (vii) Religion: Christian. 351 (viii) Whether SC/ST/OBC- 352 (ix) \\nOccupation:------- 353 (x) Address:- R/o Porta wado, Siolim Bardez Goa. 354 Whether \\nverified. Yes 355 (xi) Provisional criminal No: A-1. 356 (xii) Regular criminal No. (if known). 357 \\n(xiii) Date of arrest: Arrested on 15/05/2023 at 35817.00 hrs. 359 \\n\\nPage 23 \\n\\n(NIV) Date of release on bail: -------- 360 (XM) Date on which forwarded to Court.---- 361 \\n(xvi) Under Acts & Sections: U/s 448, 376 IPC. 362 (xvii) Details of Bailers/Sureties: 363 (xviii) \\nPrevious conviction with case reference.------- 364 (xix) Status of the accused: In Judicial \\nCustody. 365Forwarded-/Bailed by Police/Bailed by Court/Pelice 366Custody/Judicial \\nCustody/Absconding /Proclaimed 367 offender. (tick applicable portion). 368 \\n12. Particulars of accused persons not Charge sheeted: 369NIL 370 (Use separate sheet for \\neach suspect). 371 Sl. No: NIL. 372 (i)Name:--- 373Whether verified: 374 (ii)Father\\'s/Husband\\'s \\nname: 375 (iii) Date/Year of birth: 376 (iv) Sex.. 377 (v) Nationality: -- 378 (vi) Passport No.- \\nDate of issue- Place of issue...-- 379wii)Religion 380 \\nPage 24 \\n\\nPici 381 (viii) Whether SC/ST/OBC... 382 (ix) Occupation: 383 (x)Address.......... Whether verified \\n384 (xi) Provisional criminal No. 385 (xii) Suspicion Approved: Yes/No. 386 (xiii) Status of the \\naccused (suspect): 387Forwarded / Bailed by Police / Bailed by court / 388Police 389Custody / \\nAbsconding / Without 390Arrest/ 391Proclaimed offender (tick applicable portion) 392 (xiv) \\nUnder Acts & Sections:- --- 393 (xv) Any special remarks including reasons for not Charge \\n394sheeting......-- 395 \\n13. Particulars of witnesses to be examined: 396 Sl. Name, age, father\\'s/Husband\\'s Occupat \\nType of 397No.name and address. 398ion. 399evidenc 400e to be 401rendere 402 d \\n1.  Ms. Jaya Joshi D/o Bhagwat Busines Compl 403 Prasad, age 49 years. R/o H.No. s \\n\\n404lainant 405Plo, 4069819147870 407 \\n\\n \\n \\n \\n\\x0cPage 25 \\n\\n| | 652-5-A. 2hd loor, Newtons Villa, Porta Waddo. Siolim, Bardez Goa Ne C/o Alok Joshi. P-04. \\nTilia, Nahar Amrit Sahakti, Chandivali. Mumbai Maharashtra | | | | | 408 | \\n| :--- | :--- | :--- | :--- | :--- | :--- | \\n| 2. | Dr. Suk<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:03:25 [engine.py:317] Added request chatcmpl-aa53df4869ac405193946ec9433d4357.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_9.txt...vLLM STDOUT: INFO:     127.0.0.1:44988 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:03:30 [logger.py:43] Received request chatcmpl-c70e129d2f474927884c8166b47377d3: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nF\" \\n\\n(Sncha S. Sawal) 335 LPSI. Anjuna P.S. 336 \\n\\nPage 22 \\n\\n11. Particulars of accused persons Charge-sheeted 337 (ise Separate sheet for each \\n\\naccused). 338Sr. No. A-1 339 (i) Name: Mr. Alfred Fernandes 340verified: Yes. 341Whether 342 \\n(ii) Father\\'s/Husband\\'s name:- Mr. Antonio 343Fernandes 344 (iii) Date/Year of birth: 38 \\nvears. 345 (iv) Sex: Male. 346 (v) Nationality: Indian. 347 (vi) Passport No. === 348 Date of \\nissue. = 349Place of issue. 350 (vii) Religion: Christian. 351 (viii) Whether SC/ST/OBC- 352 (ix) \\nOccupation:------- 353 (x) Address:- R/o Porta wado, Siolim Bardez Goa. 354 Whether \\nverified. Yes 355 (xi) Provisional criminal No: A-1. 356 (xii) Regular criminal No. (if known). 357 \\n(xiii) Date of arrest: Arrested on 15/05/2023 at 35817.00 hrs. 359 \\n\\nPage 23<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:03:30 [engine.py:317] Added request chatcmpl-c70e129d2f474927884c8166b47377d3.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_9.txt...vLLM STDOUT: INFO:     127.0.0.1:45026 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:03:46 [logger.py:43] Received request chatcmpl-0c4173a331094098901b428c4ae269fe: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n(if known). 357 \\n(xiii) Date of arrest: Arrested on 15/05/2023 at 35817.00 hrs. 359 \\n\\nPage 23 \\n\\n(NIV) Date of release on bail: -------- 360 (XM) Date on which forwarded to Court.---- 361 \\n(xvi) Under Acts & Sections: U/s 448, 376 IPC. 362 (xvii) Details of Bailers/Sureties: 363 (xviii) \\nPrevious conviction with case reference.------- 364 (xix) Status of the accused: In Judicial \\nCustody. 365Forwarded-/Bailed by Police/Bailed by Court/Pelice 366Custody/Judicial \\nCustody/Absconding /Proclaimed 367 offender. (tick applicable portion). 368 \\n12. Particulars of accused persons not Charge sheeted: 369NIL 370 (Use separate sheet for \\neach suspect). 371 Sl. No: NIL. 372 (i)Name:--- 373Whether verified: 374 (ii)Father\\'s/Husband\\'s \\nname: 375 (iii) Date/Year of birth: 376 (iv) Sex.. 377 (v) Nationality: -- 378 (vi) Passport No.- \\nDate of issue- Place of issue...-- 379wii)Religion 380 \\nPage 24<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:03:46 [engine.py:317] Added request chatcmpl-0c4173a331094098901b428c4ae269fe.\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_9.txt...vLLM STDOUT: INFO:     127.0.0.1:36232 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:04:01 [logger.py:43] Received request chatcmpl-54965191adec41a6a79da47fae7bafba: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nNo: NIL. 372 (i)Name:--- 373Whether verified: 374 (ii)Father\\'s/Husband\\'s \\nname: 375 (iii) Date/Year of birth: 376 (iv) Sex.. 377 (v) Nationality: -- 378 (vi) Passport No.- \\nDate of issue- Place of issue...-- 379wii)Religion 380 \\nPage 24 \\n\\nPici 381 (viii) Whether SC/ST/OBC... 382 (ix) Occupation: 383 (x)Address.......... Whether verified \\n384 (xi) Provisional criminal No. 385 (xii) Suspicion Approved: Yes/No. 386 (xiii) Status of the \\naccused (suspect): 387Forwarded / Bailed by Police / Bailed by court / 388Police 389Custody / \\nAbsconding / Without 390Arrest/ 391Proclaimed offender (tick applicable portion) 392 (xiv) \\nUnder Acts & Sections:- --- 393 (xv) Any special remarks including reasons for not Charge \\n394sheeting......-- 395 \\n13. Particulars of witnesses to be examined: 396 Sl. Name, age, father\\'s/Husband\\'s Occupat \\nType of 397No.name and address. 398ion. 399evidenc 400e to be 401rendere 402 d \\n1.  Ms. Jaya Joshi D/o Bhagwat Busines Compl 403 Prasad, age 49 years. R/o H.No. s<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:04:01 [engine.py:317] Added request chatcmpl-54965191adec41a6a79da47fae7bafba.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_9.txt...vLLM STDOUT: INFO:     127.0.0.1:53034 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:04:17 [logger.py:43] Received request chatcmpl-809b54c3845142cfadaf93c8cff9e1a0: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nJaya Joshi D/o Bhagwat Busines Compl 403 Prasad, age 49 years. R/o H.No. s \\n\\n404lainant 405Plo, 4069819147870 407 \\n\\n \\n \\n \\n\\x0cPage 25 \\n\\n| | 652-5-A. 2hd loor, Newtons Villa, Porta Waddo. Siolim, Bardez Goa Ne C/o Alok Joshi. P-04. \\nTilia, Nahar Amrit Sahakti, Chandivali. Mumbai Maharashtra | | | | | 408 | \\n| :--- | :--- | :--- | :--- | :--- | :--- | \\n| 2. | Dr. Suk<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:04:17 [engine.py:317] Added request chatcmpl-809b54c3845142cfadaf93c8cff9e1a0.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_9.txt...vLLM STDOUT: INFO:     127.0.0.1:53416 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 65 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_9_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_9_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_9.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_9_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:38660 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:38672 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:04:34 [logger.py:43] Received request chatcmpl-0e268b62f7a947a997321c415f4c8000: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nAlok Joshi. P-04. \\nTilia, Nahar Amrit Sahakti, Chandivali. Mumbai Maharashtra | | | | | 408 | \\n| :--- | :--- | :--- | :--- | :--- | :--- | \\n| 2. | Dr. Sukanya M, Major in age, Medical Officer, PHC, Siolim, Bardez Goa 8208047159. | \\nGovt. Service | Witness 102 | | | 409 | \\n| 3. | Shri. Damodar s/o Kishore Salgaonkar, age-39 years. r/o 11. No. 505, Bhati, Oxel, Siolim, \\nBardez Goa | Private Service | Witness | | | 410 | \\n| 4. | Shri. Manjunath s/o Shivaji Lamani, age- 23 years, r/o c/o Pravin, Near Starco junction, \\nAnjuna, Bardez Goa, n/o Tanda, Patil, Major in Govt. 975243163 Gadak, Karnataka | Business | \\nWitness | | | 411 | \\n| 5. | Dr. Ankush B. Police lage, sturgeon GMC Service Bambolim Goa | Govt. Service | Witness | \\n| | 412 | \\nPage 26 \\n\\n| 6. | Dr. Nisha Naik. Major in age, Medical officer. Department of Gynaecology. GMC, \\nBambolim Kioa | Govt. Service | Witness | | | 413 | \\n| :--- | :--- | :--- | :--- | :--- | :--- | \\n| 7. | Shri. Sriram s/o Manohar Naik, age-67 years, r/o 11. No. 832/B, Portawada, Siolim. Bardez \\nGoa 84110297 96 | Unempl oyed | Panch witness | | | 414 | \\n| 8. | Mrs. Blossom w/o late Kennath, D'souza, age- 66 years, r/o!!. No. 723, Portawado. Siolim. \\nBardez Goa. | Housew ife | Panch witness | | | 415 | \\n| 9. | Mr. Richard S/o Kenneth D'Souza, age 31 years, R/os H.No. 723, Porta Waddo, Siolim \\nBardez Goa. | Busines Prof | Witness 8 hos | | | 416 | \\n| 10. | Miss Sneha S. Sawal. Major in age, LPSI, Anjuna P.S. | Service | I.O. | | | 417 | \\nPage 27 \\n\\n14. If FIR is false. indicate action taken or proposed to 418be taken U/s 182/211 1.P.C- 419 \\n\\n15. Result of Laboratory analysis. :- ------- 420 \\n\\n16. Brief Facts of the case:- 421 (Add separate sheet. if necessary) 422MAY IT PLEASE YOUR \\nHONOUR 423In the limits of your Hon'ble Court and within the 424Jurisdiction of Anjuna \\nPolice Station, that on 15.05.2023 425at about 00.30 hrs at Siolim Bardez Goa accused \\nperson 426mentioned at serial No. 11 at Col. No. A-1 criminally 427trespassed into the house \\nof the complainant and further 428entered into the complainants bedroom and touched \\nhis 429hand on complainant's vagina and other parts of body 430and further tried to insert \\nhis fingers in her vagina 431without her consent, thereby committed the rape of the \\n432complainant. 433Thus the accused lady committed an oflence 434punishable U/s 448, \\n376 IPC. 435HENCE THE CHARGE 436 \\n\\n \\n \\n \\n\\x0c17. Refer Notice served: Yes/No. 437 (Acknowledgement to be placed) 438 Date. 06/2023 439 \\n\\nPage 28 \\n\\n18. Dispatched on: 26/16/2023 440 \\n\\n19. No. of enclosures: As per<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:04:34 [engine.py:317] Added request chatcmpl-0e268b62f7a947a997321c415f4c8000.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_10.txt...vLLM STDOUT: INFO:     127.0.0.1:38680 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:04:39 [logger.py:43] Received request chatcmpl-18ed19bbd6c14bbca518dc8e95a2d787: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n Alok Joshi. P-04. \\nTilia, Nahar Amrit Sahakti, Chandivali. Mumbai Maharashtra | | | | | 408 | \\n| :--- | :--- | :--- | :--- | :--- | :--- | \\n| 2. | Dr. Sukanya M, Major in age, Medical Officer, PHC, Siolim, Bardez Goa 8208047159. | \\nGovt. Service | Witness 102 | | | 409 | \\n| 3. | Shri. Damodar s/o Kishore Salgaonkar, age-39 years. r/o 11. No. 505, Bhati, Oxel, Siolim, \\nBardez Goa | Private Service | Witness | | | 410 | \\n| 4. | Shri. Manjunath s/o Shivaji Lamani, age- 23 years, r/o c/o Pravin, Near Starco junction, \\nAnjuna, Bardez Goa, n/o Tanda, Patil, Major in Govt. 975243163 Gadak, Karnataka | Business | \\nWitness | | | 411 | \\n| 5. | Dr. Ankush B. Police lage, sturgeon GMC Service Bambolim Goa | Govt. Service | Witness | \\n| | 412 | \\nPage 26<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:04:39 [engine.py:317] Added request chatcmpl-18ed19bbd6c14bbca518dc8e95a2d787.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_10.txt...vLLM STDOUT: INFO:     127.0.0.1:39380 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:04:55 [logger.py:43] Received request chatcmpl-5125f3a950e44f23af365f2264620d01: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nAnkush B. Police lage, sturgeon GMC Service Bambolim Goa | Govt. Service | Witness | \\n| | 412 | \\nPage 26 \\n\\n| 6. | Dr. Nisha Naik. Major in age, Medical officer. Department of Gynaecology. GMC, \\nBambolim Kioa | Govt. Service | Witness | | | 413 | \\n| :--- | :--- | :--- | :--- | :--- | :--- | \\n| 7. | Shri. Sriram s/o Manohar Naik, age-67 years, r/o 11. No. 832/B, Portawada, Siolim. Bardez \\nGoa 84110297 96 | Unempl oyed | Panch witness | | | 414 | \\n| 8. | Mrs. Blossom w/o late Kennath, D\\'souza, age- 66 years, r/o!!. No. 723, Portawado. Siolim. \\nBardez Goa. | Housew ife | Panch witness | | | 415 | \\n| 9. | Mr. Richard S/o Kenneth D\\'Souza, age 31 years, R/os H.No. 723, Porta Waddo, Siolim \\nBardez Goa. | Busines Prof | Witness 8 hos | | | 416 | \\n| 10. | Miss Sneha S. Sawal. Major in age, LPSI, Anjuna P.S. | Service | I.O. | | | 417 | \\nPage 27 \\n\\n14. If FIR is false. indicate action taken or proposed to 418be taken U/s 182/211 1.P.C- 419 \\n\\n15. Result of Laboratory analysis. :- ------- 420<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:04:55 [engine.py:317] Added request chatcmpl-5125f3a950e44f23af365f2264620d01.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_10.txt...vLLM STDOUT: INFO:     127.0.0.1:55024 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:05:10 [logger.py:43] Received request chatcmpl-4e3bdf42b44d4e45b88c2a25e2067859: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nindicate action taken or proposed to 418be taken U/s 182/211 1.P.C- 419 \\n\\n15. Result of Laboratory analysis. :- ------- 420 \\n\\n16. Brief Facts of the case:- 421 (Add separate sheet. if necessary) 422MAY IT PLEASE YOUR \\nHONOUR 423In the limits of your Hon\\'ble Court and within the 424Jurisdiction of Anjuna \\nPolice Station, that on 15.05.2023 425at about 00.30 hrs at Siolim Bardez Goa accused \\nperson 426mentioned at serial No. 11 at Col. No. A-1 criminally 427trespassed into the house \\nof the complainant and further 428entered into the complainants bedroom and touched \\nhis 429hand on complainant\\'s vagina and other parts of body 430and further tried to insert \\nhis fingers in her vagina 431without her consent, thereby committed the rape of the \\n432complainant. 433Thus the accused lady committed an oflence 434punishable U/s 448, \\n376 IPC. 435HENCE THE CHARGE 436 \\n\\n \\n \\n \\n\\x0c17. Refer Notice served: Yes/No. 437 (Acknowledgement to be placed) 438 Date. 06/2023 439 \\n\\nPage 28 \\n\\n18. Dispatched on: 26/16/2023 440<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:05:10 [engine.py:317] Added request chatcmpl-4e3bdf42b44d4e45b88c2a25e2067859.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_10.txt...vLLM STDOUT: INFO:     127.0.0.1:52564 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:05:26 [logger.py:43] Received request chatcmpl-a8e5e1825d08401ca59e86c3c188a663: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n437 (Acknowledgement to be placed) 438 Date. 06/2023 439 \\n\\nPage 28 \\n\\n18. Dispatched on: 26/16/2023 440 \\n\\n19. No. of enclosures: As per<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:05:26 [engine.py:317] Added request chatcmpl-a8e5e1825d08401ca59e86c3c188a663.\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_10.txt...vLLM STDOUT: INFO:     127.0.0.1:49934 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 66 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_10_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_10_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/output2/ilovepdf_merged_10.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_10_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:56376 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:56382 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:05:44 [logger.py:43] Received request chatcmpl-9bc8554b28584bb099ba5c9742868db4: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n17. Refer Notice served: Yes/No. 437 (Acknowledgement to be placed) 438 Date. 06/2023 439 \\n\\nPage 28 \\n\\n18. Dispatched on: 26/16/2023 440 \\n\\n19. No. of enclosures: As per Index. 441 \\n\\n20. List of enclosures: As annexed. 442Forwarded by Officer in charge Signature of \\n\\ninvestigating 443Of Police Station. 444Officer 445Submitting Charge sheet 446 Name: -Shri. \\nPrashal P.N. Dessai. Name:- Miss. Sneha 447Sawal. 448sql 449Rank: - Folice Inspector. \\n450Rank: - LPSI, Anjuna PS. 451Note: 452 \\n\\n21. The Original charge sheet along with Criginal case papers is submitted to The Hon'ble \\n\\nJMFC Court Mapusa. 453 \\n\\n22. The duplicate case paper along with duplicate charge sheet is sent to PP, Hon'ble JMFC \\n\\nCourt Mapusa with request to conduct prosecution at the time of trial. 454 \\n\\n23. A copy of charge sheet along with the set of case papers is sent herewith for the \\n\\npurpose of accused. 455 \\n\\n24. Summons to the witnesses for prosecution may be sent through this P.S. 456 \\n\\n25. More evidence will be adduced if necessary, with the permission of the court. 457 \\n\\nPage 29 \\n\\nN.C.R.B. 458I.I.F.- V 459GOA POLICE 460FINAL FORM / REPORT 461 (Under Section 173 Cr.P.C.) \\n462IN THE COURT OF CHILDREN COURT SHRAMA SHAKTI 463BHAVAN PANAJI 464 \\n\\n1.  District 465Case/FIR No. 466 North Goa P.S. Bicholim Police Year 2019 467Station 46876/2019 \\n\\nDate 24-07-2019 469 \\n\\n2.  Charge Sheet No 623/2019 62/5/2019 470 \\n\\n3.  Date 47124-09-2019 472 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cPage 30 \\n\\n4.  Acts and Sections 473 \\n\\nActs \\n\\nSections \\n\\nr/w Section \\n\\nNo Records Available \\n\\n474 \\n\\n5.  Type of Final Form/Report 475Charge Sheet 4766. 477If FR Unoccurred 4787. 479If Charge \\n\\nsheet 480Original 481 \\n\\n6.  Name of I.O 482BHARAT BABLO KHARAT 483Rank 484Sub-Inspector No.: 485 (At the time of \\n\\ncharge sheet) 4869. 487 (a) 488Name of complainant / informant 489Hayath sab \\nKhasimmanavar 490 (b) 491Father's/ Husband's name 492Jamasab 493 (c) Complainant \\nAddress 494c/o Nasir Beig 495Shaikh, Vathadev, Sarvan, Bich olim, North Goa, Goa 496 \\n\\n7.  Details of Properties/Articles/Documents recovered/seized during 497investigation and \\n\\nrelied upon(separate list can be attached, if necessary). 498 \\n\\nS.No \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (in \\nRs.) \\n\\nDisposal \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\nFrom \\nwhom/ \\nwhere \\nrecovered \\nor seized \\n\\nNo Records \\nAvailable \\n\\n499 \\n\\n11. Particulars of accused persons charge-sheeted: (Use separate sheet for each accused) \\n500S.No 501 (i) 502Name 503A1 504Palamurgan Gawander 505Whether verified 506First Alias \\n507Second Alias 508 (ii) 509Father's/Husband's Name 510Late Sokar [Father] 511 (iii) \\n512Date/Year of birth 513 (Age: 32) 514 \\n\\nPage 31 \\n\\n(iv) Sex \\n\\n(v) Nationality \\n\\nMale \\n\\nIndian \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c(vi) Passport No. \\n\\nDate of Issue Place of Issue \\n\\n(vii) Religion \\n\\nMuslim \\n\\n(viii) Whether SC/ST/OBC \\n\\n(ix) Occupation \\n\\nMason<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:05:44 [engine.py:317] Added request chatcmpl-9bc8554b28584bb099ba5c9742868db4.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_11.txt...vLLM STDOUT: INFO:     127.0.0.1:56396 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:05:48 [logger.py:43] Received request chatcmpl-6a028d6577c4461594b6cec4bd4c1aa1: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n \\n \\n \\n\\x0c17. Refer Notice served: Yes/No. 437 (Acknowledgement to be placed) 438 Date. 06/2023 439 \\n\\nPage 28 \\n\\n18. Dispatched on: 26/16/2023 440 \\n\\n19. No. of enclosures: As per Index. 441 \\n\\n20. List of enclosures: As annexed. 442Forwarded by Officer in charge Signature of \\n\\ninvestigating 443Of Police Station. 444Officer 445Submitting Charge sheet 446 Name: -Shri. \\nPrashal P.N. Dessai. Name:- Miss. Sneha 447Sawal. 448sql 449Rank: - Folice Inspector. \\n450Rank: - LPSI, Anjuna PS. 451Note: 452 \\n\\n21. The Original charge sheet along with Criginal case papers is submitted to The Hon\\'ble \\n\\nJMFC Court Mapusa. 453 \\n\\n22. The duplicate case paper along with duplicate charge sheet is sent to PP, Hon\\'ble JMFC \\n\\nCourt Mapusa with request to conduct prosecution at the time of trial. 454 \\n\\n23. A copy of charge sheet along with the set of case papers is sent herewith for the \\n\\npurpose of accused. 455 \\n\\n24. Summons to the witnesses for prosecution may be sent through this P.S. 456<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:05:48 [engine.py:317] Added request chatcmpl-6a028d6577c4461594b6cec4bd4c1aa1.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_11.txt...vLLM STDOUT: INFO:     127.0.0.1:60346 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:06:03 [logger.py:43] Received request chatcmpl-62362187abe242888983d8441c032ed3: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n455 \\n\\n24. Summons to the witnesses for prosecution may be sent through this P.S. 456 \\n\\n25. More evidence will be adduced if necessary, with the permission of the court. 457 \\n\\nPage 29 \\n\\nN.C.R.B. 458I.I.F.- V 459GOA POLICE 460FINAL FORM / REPORT 461 (Under Section 173 Cr.P.C.) \\n462IN THE COURT OF CHILDREN COURT SHRAMA SHAKTI 463BHAVAN PANAJI 464 \\n\\n1.  District 465Case/FIR No. 466 North Goa P.S. Bicholim Police Year 2019 467Station 46876/2019 \\n\\nDate 24-07-2019 469 \\n\\n2.  Charge Sheet No 623/2019 62/5/2019 470 \\n\\n3.  Date 47124-09-2019 472 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cPage 30 \\n\\n4.  Acts and Sections 473 \\n\\nActs \\n\\nSections \\n\\nr/w Section \\n\\nNo Records Available \\n\\n474 \\n\\n5.  Type of Final Form/Report 475Charge Sheet 4766. 477If FR Unoccurred 4787. 479If Charge \\n\\nsheet 480Original 481 \\n\\n6.  Name of I.O 482BHARAT BABLO KHARAT 483Rank 484Sub-Inspector No.: 485 (At the time of<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_11.txt...vLLM STDOUT: INFO 12-14 05:06:03 [engine.py:317] Added request chatcmpl-62362187abe242888983d8441c032ed3.\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/output2/ilovepdf_merged_11.txt...vLLM STDOUT: INFO:     127.0.0.1:44950 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:06:19 [logger.py:43] Received request chatcmpl-483b6688e6e0466eacac70a35a892b0d: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n477If FR Unoccurred 4787. 479If Charge \\n\\nsheet 480Original 481 \\n\\n6.  Name of I.O 482BHARAT BABLO KHARAT 483Rank 484Sub-Inspector No.: 485 (At the time of \\n\\ncharge sheet) 4869. 487 (a) 488Name of complainant / informant 489Hayath sab \\nKhasimmanavar 490 (b) 491Father\\'s/ Husband\\'s name 492Jamasab 493 (c) Complainant \\nAddress 494c/o Nasir Beig 495Shaikh, Vathadev, Sarvan, Bich olim, North Goa, Goa 496 \\n\\n7.  Details of Properties/Articles/Documents recovered/seized during 497investigation and \\n\\nrelied upon(separate list can be attached, if necessary). 498 \\n\\nS.No \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (in \\nRs.) \\n\\nDisposal \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\nFrom \\nwhom/ \\nwhere \\nrecovered \\nor seized \\n\\nNo Records \\nAvailable \\n\\n499<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:06:19 [engine.py:317] Added request chatcmpl-483b6688e6e0466eacac70a35a892b0d.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_11.txt...vLLM STDOUT: INFO:     127.0.0.1:42302 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:06:34 [logger.py:43] Received request chatcmpl-5031bbf065e447a0a8d4139a651b16d6: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n498 \\n\\nS.No \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (in \\nRs.) \\n\\nDisposal \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\nFrom \\nwhom/ \\nwhere \\nrecovered \\nor seized \\n\\nNo Records \\nAvailable \\n\\n499 \\n\\n11. Particulars of accused persons charge-sheeted: (Use separate sheet for each accused) \\n500S.No 501 (i) 502Name 503A1 504Palamurgan Gawander 505Whether verified 506First Alias \\n507Second Alias 508 (ii) 509Father\\'s/Husband\\'s Name 510Late Sokar [Father] 511 (iii) \\n512Date/Year of birth 513 (Age: 32) 514 \\n\\nPage 31 \\n\\n(iv) Sex \\n\\n(v) Nationality \\n\\nMale \\n\\nIndian \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c(vi) Passport No. \\n\\nDate of Issue Place of Issue \\n\\n(vii) Religion \\n\\nMuslim \\n\\n(viii) Whether SC/ST/OBC \\n\\n(ix) Occupation \\n\\nMason<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_11.txt...vLLM STDOUT: INFO 12-14 05:06:34 [engine.py:317] Added request chatcmpl-5031bbf065e447a0a8d4139a651b16d6.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_11.txt...vLLM STDOUT: INFO:     127.0.0.1:59020 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 66 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_11_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_11_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_11.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_11_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:55900 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:55916 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:06:52 [logger.py:43] Received request chatcmpl-a77b9ef8c53943dcadba0e0fb1621c3a: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n) 514 \\n\\nPage 31 \\n\\n(iv) Sex \\n\\n(v) Nationality \\n\\nMale \\n\\nIndian \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c(vi) Passport No. \\n\\nDate of Issue Place of Issue \\n\\n(vii) Religion \\n\\nMuslim \\n\\n(viii) Whether SC/ST/OBC \\n\\n(ix) Occupation \\n\\nMason \\n\\n(x) Address Type Address Address Present \\nPermanent Whether verified S.No 1 \\nAddress 2 \\n\\nAddress c/o Shahida Nasir Shaikh, \\nVathadev, Near Neha Collection, Sarvan, \\nBicholim, Nort h Goa, Goa Katkanpatti \\nVatalgundu, Dindigul, Tamilnadu Yes \\n\\n(xi) Provisional criminal No \\n\\n(xii) Regular criminal No. (if known ) \\n\\n(xiii) Date of arrest \\n\\n11-09-2019 19:11:00 \\n\\n(xiv) Date of release on bail \\n\\n(xv) Date on which forwarded to court \\n\\n11-09-2019 19:11:00 \\n\\n(xvi) Under Acts & Sections \\n\\nPage 32 \\n\\nAct \\n\\nSections \\n\\nr/w Section \\n\\nThe Protection of Children \\nfrom Sexual Offences Act, \\n2012 (POCSO) \\n\\n12,4,8,11(i) \\n\\nIndian Penal Code (IPC) \\n\\n363,376 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cThe Goa Children'S Act \\n2003 \\n\\n$8(2)$ \\n\\n(xvii) Details of bailers / sureties 515No Records Available 516 (xviii) Previous convictions with \\ncase 517references 518 (xix) 519Status of the accused 520Arrested 521 \\n12. Particulars of accused persons - not charge sheeted (suspect) 522 \\n13. Particulars of witnesses to be examined 523 \\n\\nS.N 0 \\n\\nName \\n\\n1 \\n\\nHayath \\nsab \\nKhasimm\\nan avar \\n\\nFather's/\\nHusband\\n's Name \\n\\nJamasab \\n[Father] \\n\\nType of \\nevidence \\nto be \\ntendered \\n\\nComplain \\nant 524 \\n\\nDate/Yea\\nr of Birth \\n\\nOccupat\\nion \\n\\nAddress \\n\\n40 \\n\\nLabourer \\n\\nPresent \\nAddress: \\nc/o Nasir \\nBeig \\nShaikh, \\nVath \\nadev, \\nSarvan \\n,Bicholim, \\nN orth \\nGoa, Goa \\nPermane\\nnt \\nAddress: \\nYalawada\\nha lli, \\nHirekeru r \\nHaveri, \\nKar \\nnataka \\n\\nPage 33 \\n\\n2 \\n\\nMoham\\nmed Rafi \\nMakand\\n\\nMadarsa\\nb \\n[Father] \\n\\n32 \\n\\nWelder \\n\\nPresent \\nAddress: \\nCare of \\n\\nPanch \\nWitness \\nMediator \\n\\n \\n \\n\\x0cer \\n\\n3 \\n\\nSubhash \\nKarennva\\nr \\n\\nNingappa \\n[Father] \\n\\n38 \\n\\nMason \\n\\nReports \\n\\nPanch \\nWitness/ \\nMediator \\nReports \\n526 \\n\\nShahida \\nNazir \\nShaikh, \\nVath \\nadev, \\nNear \\nNeha \\nCollectio\\nn, B \\nicholim, \\nNor th \\nGoa, \\nGoa \\nPermane\\nnt \\nAddress: \\nAdur \\nKokkal \\nYelgudg\\na, U \\nnknown \\nDistrict, \\nKar \\nnataka \\n\\nPresent \\nAddress: \\nPiddigaru\\nd a, \\nMuslim \\nwada, \\nBichol im, \\nNorth \\nGoa, Goa \\nPermane\\nnt \\nAddress: \\n962,Sopp\\ndal \\nSaudatti, \\nBe \\nIgaum, \\n\\n \\n\\x0c4 \\n\\nReshma \\nKhasimm\\nan av \\n\\nHayath \\n[Husband \\n\\n35 \\n\\nHousewif \\ne \\n\\n/ 528 \\n\\nPage 34 \\n\\n5 \\n\\n17 \\n\\nStudent \\n\\nShahida \\nKhasim\\nman \\navar \\n\\nHayath \\nSab \\n[Father] \\n\\nWitness \\n527 \\n\\nVictim \\n\\nKarn \\nataka \\n\\nPresent \\nAddress: \\nCare of \\nNasir \\nBeig \\nShaikh, \\nVath \\nadev, \\nSarvan \\n,Bicholim, \\nN orth \\nGoa, Goa \\nPermane\\nnt \\nAddress: \\nYalawada\\nha \\nlliHireker<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:06:52 [engine.py:317] Added request chatcmpl-a77b9ef8c53943dcadba0e0fb1621c3a.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_12.txt...vLLM STDOUT: INFO:     127.0.0.1:55918 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:06:55 [logger.py:43] Received request chatcmpl-203215d4862c4b5c86e7db75609f9f51: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n) 514 \\n\\nPage 31 \\n\\n(iv) Sex \\n\\n(v) Nationality \\n\\nMale \\n\\nIndian \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c(vi) Passport No. \\n\\nDate of Issue Place of Issue \\n\\n(vii) Religion \\n\\nMuslim \\n\\n(viii) Whether SC/ST/OBC \\n\\n(ix) Occupation \\n\\nMason \\n\\n(x) Address Type Address Address Present \\nPermanent Whether verified S.No 1 \\nAddress 2 \\n\\nAddress c/o Shahida Nasir Shaikh, \\nVathadev, Near Neha Collection, Sarvan, \\nBicholim, Nort h Goa, Goa Katkanpatti \\nVatalgundu, Dindigul, Tamilnadu Yes \\n\\n(xi) Provisional criminal No \\n\\n(xii) Regular criminal No. (if known ) \\n\\n(xiii) Date of arrest \\n\\n11-09-2019 19:11:00 \\n\\n(xiv) Date of release on bail \\n\\n(xv) Date on which forwarded to court \\n\\n11-09-2019 19:11:00 \\n\\n(xvi) Under Acts & Sections \\n\\nPage 32 \\n\\nAct \\n\\nSections \\n\\nr/w Section \\n\\nThe Protection of Children \\nfrom Sexual Offences Act, \\n2012 (POCSO) \\n\\n12,4,8,11(i) \\n\\nIndian Penal Code (IPC) \\n\\n363,376 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cThe Goa Children\\'S Act \\n2003 \\n\\n$8(2)$<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2KProcessing 3 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_12.txt...vLLM STDOUT: INFO 12-14 05:06:55 [engine.py:317] Added request chatcmpl-203215d4862c4b5c86e7db75609f9f51.\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_12.txt...vLLM STDOUT: INFO:     127.0.0.1:55924 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:07:11 [logger.py:43] Received request chatcmpl-4ba57f08c6fe488f98b6aa6f0c8911b0: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n(xvii) Details of bailers / sureties 515No Records Available 516 (xviii) Previous convictions with \\ncase 517references 518 (xix) 519Status of the accused 520Arrested 521 \\n12. Particulars of accused persons - not charge sheeted (suspect) 522 \\n13. Particulars of witnesses to be examined 523 \\n\\nS.N 0 \\n\\nName \\n\\n1 \\n\\nHayath \\nsab \\nKhasimm\\nan avar \\n\\nFather\\'s/\\nHusband\\n\\'s Name \\n\\nJamasab \\n[Father] \\n\\nType of \\nevidence \\nto be \\ntendered \\n\\nComplain \\nant 524 \\n\\nDate/Yea\\nr of Birth \\n\\nOccupat\\nion \\n\\nAddress \\n\\n40 \\n\\nLabourer \\n\\nPresent \\nAddress: \\nc/o Nasir \\nBeig \\nShaikh, \\nVath \\nadev, \\nSarvan \\n,Bicholim, \\nN orth \\nGoa, Goa \\nPermane\\nnt \\nAddress: \\nYalawada\\nha lli, \\nHirekeru r \\nHaveri, \\nKar \\nnataka \\n\\nPage 33 \\n\\n2 \\n\\nMoham\\nmed Rafi \\nMakand\\n\\nMadarsa\\nb \\n[Father] \\n\\n32 \\n\\nWelder \\n\\nPresent \\nAddress: \\nCare of \\n\\nPanch \\nWitness \\nMediator \\n\\n \\n \\n\\x0cer \\n\\n3 \\n\\nSubhash \\nKarennva\\nr \\n\\nNingappa \\n[Father] \\n\\n38 \\n\\nMason \\n\\nReports \\n\\nPanch \\nWitness/ \\nMediator \\nReports \\n526<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:07:11 [engine.py:317] Added request chatcmpl-4ba57f08c6fe488f98b6aa6f0c8911b0.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_12.txt...vLLM STDOUT: INFO:     127.0.0.1:43954 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:07:26 [logger.py:43] Received request chatcmpl-48fe588fe2334e0abd0db82485110341: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nShahida \\nNazir \\nShaikh, \\nVath \\nadev, \\nNear \\nNeha \\nCollectio\\nn, B \\nicholim, \\nNor th \\nGoa, \\nGoa \\nPermane\\nnt \\nAddress: \\nAdur \\nKokkal \\nYelgudg\\na, U \\nnknown \\nDistrict, \\nKar \\nnataka \\n\\nPresent \\nAddress: \\nPiddigaru\\nd a, \\nMuslim \\nwada, \\nBichol im, \\nNorth \\nGoa, Goa \\nPermane\\nnt \\nAddress: \\n962,Sopp\\ndal \\nSaudatti, \\nBe \\nIgaum, \\n\\n \\n\\x0c4 \\n\\nReshma \\nKhasimm\\nan av \\n\\nHayath \\n[Husband \\n\\n35 \\n\\nHousewif \\ne \\n\\n/ 528 \\n\\nPage 34 \\n\\n5 \\n\\n17 \\n\\nStudent \\n\\nShahida \\nKhasim\\nman \\navar \\n\\nHayath \\nSab \\n[Father] \\n\\nWitness \\n527 \\n\\nVictim \\n\\nKarn \\nataka \\n\\nPresent \\nAddress: \\nCare of \\nNasir \\nBeig \\nShaikh, \\nVath \\nadev, \\nSarvan \\n,Bicholim, \\nN orth \\nGoa, Goa \\nPermane\\nnt \\nAddress: \\nYalawada\\nha \\nlliHireker<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:07:26 [engine.py:317] Added request chatcmpl-48fe588fe2334e0abd0db82485110341.\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_12.txt...vLLM STDOUT: INFO:     127.0.0.1:51324 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 40 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_12_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_12_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_12.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_12_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:36778 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:36780 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:07:44 [logger.py:43] Received request chatcmpl-04d2ab9d71ba4578b2687a7b4cb7f25d: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nAddress: \\nCare of \\nNasir \\nBeig \\nShaikh, \\nVath \\nadev, \\nSarvan \\n,Bicholim, \\nN orth \\nGoa, Goa \\nPermane\\nnt \\nAddress: \\nYalawada\\nha \\nlliHireker\\nu, r \\n,Haveri, \\nKar \\nnataka \\n\\nPresent \\nAddress: \\nCare of \\nNasir \\nBeig \\nShaikh, \\nVath \\nadev, \\nSarvan \\n,Bicholi\\n\\n \\n \\n\\x0cm, N \\north \\nGoa, \\nGoa \\nPermane\\nnt \\nAddress: \\nYalawad\\naha lli, \\nHirekeru \\nr,Haveri \\nnataka \\n\\nPresent \\nAddress: \\nCare of \\nNasir \\nBeig \\nShaikh, \\nVath \\nadev, \\nSarvan \\n,Bicholim, \\nN orth \\nGoa, Goa \\nPermane\\nnt \\nAddress: \\nYalawada\\nha lli, \\nHirekeru r \\n,Haveri, \\nKar \\nnataka \\n\\nPresent \\nAddress: \\nBamboli\\nm, \\nTiswadi, \\nNor th \\n\\nPanch \\nWitness/ \\nMediator \\nReports \\n530 \\n\\nPanch \\nWitness / \\nDoctor \\nMediator \\nReports \\n531 \\n\\n6 \\n\\nSubhanal\\nla h \\nKhasimm\\nan avar \\n\\nHayath \\nSab \\n[Father] \\n\\n13 \\n\\nStudent \\n\\n7 \\n\\nAnkita \\nBorkar \\n\\n \\n \\n \\n \\n\\x0cGoa, Goa \\nPermane\\nnt \\nAddress: \\nSame As \\nAbove. \\n\\nPage 35 \\n\\n| 8 | Ankush Patil | | | | Present Address: Bambolim, Tiswadi, Nor th Goa, Goa Permanent \\nAddress: Same As Above. | Panch Witness / Mediator Reports 532 | \\n| :--- | :--- | :--- | :--- | :--- | :--- | \\n14. If FR is false, indicate action taken or proposed to be taken u/s 182/211 533I.P.C 534 \\n\\n15. Result of Laboratory analysis 535 D.N.A. Profiling in respect to minor victim and accused is \\nyet 536to be conducted and report of the same will be submitted to 537the Honourable \\ncourt during Trail. 538 \\n\\n16. Brief Facts of the Case (Add separate sheet, if necessary) 539In the limits of your Hon'ble \\nCourt and within the 540jurisdiction of Bicholim Police Station, that on 24.07.2019 at \\n54122.13 hrs Mr. Hayath Sab Khasimmanavar s/o Jamasab, 542aged 40 yrs, Occ- Labourer, \\n$r/o$ $c/o$ Nasir Beig Shaikh, 543Vathadev, Bicholim, Goa lodged his complaint to the \\neffect 544that 23.07.2019 at prior to 12.00 hrs at Vathadev, Bicholim, 545Goa, accused \\nperson Mr. Pulmurga s/o Sokar Gawander, 546age 32 yrs, Occ- Mason, $r/o$ H.No. \\n547$71/B$, Bandarwada, 548Bicholim, Goa, presently residing at $c/o$ ShahidaNazir \\n549Shaikh, near Neha Collection, Vathadev, Bicholim, Goa had 550kidnapped minor \\ndaughter of the complainant, age 17 yrs 551from the lawful guardianship and her present \\nwhereabouts 552are not known. 553Upon receipt of the above complaint PSI Bharat Kharat \\n554registered an offence vide Bicholim Police Station Crime No. 55576/2019 U/s 363 IPC, \\nSec 8 of Goa Children's Act 2003 556against above named accused person. 557 \\n\\nPage 36 \\n\\nDuring course of investigation, obtained presence of mother 558of the minor victim girl namely \\nMrs. Reshma w/o Hayath 559Sab Khasimmanavar, age: - 35 yrs., Occ: - Housewife, $r/o$, \\n560$c/o$ Nasir Beig<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:07:44 [engine.py:317] Added request chatcmpl-04d2ab9d71ba4578b2687a7b4cb7f25d.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_13.txt...vLLM STDOUT: INFO:     127.0.0.1:36794 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:07:49 [logger.py:43] Received request chatcmpl-32ce7f573f134c538df7abb7aa742aca: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n \\nAddress: \\nCare of \\nNasir \\nBeig \\nShaikh, \\nVath \\nadev, \\nSarvan \\n,Bicholim, \\nN orth \\nGoa, Goa \\nPermane\\nnt \\nAddress: \\nYalawada\\nha \\nlliHireker\\nu, r \\n,Haveri, \\nKar \\nnataka \\n\\nPresent \\nAddress: \\nCare of \\nNasir \\nBeig \\nShaikh, \\nVath \\nadev, \\nSarvan \\n,Bicholi\\n\\n \\n \\n\\x0cm, N \\north \\nGoa, \\nGoa \\nPermane\\nnt \\nAddress: \\nYalawad\\naha lli, \\nHirekeru \\nr,Haveri \\nnataka \\n\\nPresent \\nAddress: \\nCare of \\nNasir \\nBeig \\nShaikh, \\nVath \\nadev, \\nSarvan \\n,Bicholim, \\nN orth \\nGoa, Goa \\nPermane\\nnt \\nAddress: \\nYalawada\\nha lli, \\nHirekeru r \\n,Haveri, \\nKar \\nnataka \\n\\nPresent \\nAddress: \\nBamboli\\nm, \\nTiswadi, \\nNor th \\n\\nPanch \\nWitness/ \\nMediator \\nReports \\n530 \\n\\nPanch \\nWitness / \\nDoctor \\nMediator \\nReports \\n531 \\n\\n6 \\n\\nSubhanal\\nla h \\nKhasimm\\nan avar \\n\\nHayath \\nSab \\n[Father] \\n\\n13 \\n\\nStudent \\n\\n7 \\n\\nAnkita \\nBorkar \\n\\n \\n \\n \\n \\n\\x0cGoa, Goa \\nPermane\\nnt \\nAddress: \\nSame As \\nAbove. \\n\\nPage 35<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_13.txt...vLLM STDOUT: INFO 12-14 05:07:49 [engine.py:317] Added request chatcmpl-32ce7f573f134c538df7abb7aa742aca.\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_13.txt...vLLM STDOUT: INFO:     127.0.0.1:45266 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:08:05 [logger.py:43] Received request chatcmpl-2a64af89cc1348f682e8fadd59853fb7: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n| 8 | Ankush Patil | | | | Present Address: Bambolim, Tiswadi, Nor th Goa, Goa Permanent \\nAddress: Same As Above. | Panch Witness / Mediator Reports 532 | \\n| :--- | :--- | :--- | :--- | :--- | :--- | \\n14. If FR is false, indicate action taken or proposed to be taken u/s 182/211 533I.P.C 534 \\n\\n15. Result of Laboratory analysis 535 D.N.A. Profiling in respect to minor victim and accused is \\nyet 536to be conducted and report of the same will be submitted to 537the Honourable \\ncourt during Trail. 538<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_13.txt...vLLM STDOUT: INFO 12-14 05:08:05 [engine.py:317] Added request chatcmpl-2a64af89cc1348f682e8fadd59853fb7.\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/output2/ilovepdf_merged_13.txt...vLLM STDOUT: INFO:     127.0.0.1:53690 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:08:20 [logger.py:43] Received request chatcmpl-6ebc63c729aa42e4afc53aca1a8355b3: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nResult of Laboratory analysis 535 D.N.A. Profiling in respect to minor victim and accused is \\nyet 536to be conducted and report of the same will be submitted to 537the Honourable \\ncourt during Trail. 538 \\n\\n16. Brief Facts of the Case (Add separate sheet, if necessary) 539In the limits of your Hon\\'ble \\nCourt and within the 540jurisdiction of Bicholim Police Station, that on 24.07.2019 at \\n54122.13 hrs Mr. Hayath Sab Khasimmanavar s/o Jamasab, 542aged 40 yrs, Occ- Labourer, \\n$r/o$ $c/o$ Nasir Beig Shaikh, 543Vathadev, Bicholim, Goa lodged his complaint to the \\neffect 544that 23.07.2019 at prior to 12.00 hrs at Vathadev, Bicholim, 545Goa, accused \\nperson Mr. Pulmurga s/o Sokar Gawander, 546age 32 yrs, Occ- Mason, $r/o$ H.No. \\n547$71/B$, Bandarwada, 548Bicholim, Goa, presently residing at $c/o$ ShahidaNazir \\n549Shaikh, near Neha Collection, Vathadev, Bicholim, Goa had 550kidnapped minor \\ndaughter of the complainant, age 17 yrs 551from the lawful guardianship and her present \\nwhereabouts 552are not known. 553Upon receipt of the above complaint PSI Bharat Kharat \\n554registered an offence vide Bicholim Police Station Crime No. 55576/2019 U/s 363 IPC, \\nSec 8 of Goa Children\\'s Act 2003 556against above named accused person. 557<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:08:20 [engine.py:317] Added request chatcmpl-6ebc63c729aa42e4afc53aca1a8355b3.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_13.txt...vLLM STDOUT: INFO:     127.0.0.1:58112 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:08:36 [logger.py:43] Received request chatcmpl-13f432ace5be47fdb23c4439afd1fcb6: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n553Upon receipt of the above complaint PSI Bharat Kharat \\n554registered an offence vide Bicholim Police Station Crime No. 55576/2019 U/s 363 IPC, \\nSec 8 of Goa Children\\'s Act 2003 556against above named accused person. 557 \\n\\nPage 36 \\n\\nDuring course of investigation, obtained presence of mother 558of the minor victim girl namely \\nMrs. Reshma w/o Hayath 559Sab Khasimmanavar, age: - 35 yrs., Occ: - Housewife, $r/o$, \\n560$c/o$ Nasir Beig<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_13.txt...vLLM STDOUT: INFO 12-14 05:08:36 [engine.py:317] Added request chatcmpl-13f432ace5be47fdb23c4439afd1fcb6.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_13.txt...vLLM STDOUT: INFO:     127.0.0.1:55252 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 54 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_13_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_13_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_13.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_13_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:51648 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:51664 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:08:54 [logger.py:43] Received request chatcmpl-e60c7b94d68f4899a38ce1c61eb8f725: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n36 \\n\\nDuring course of investigation, obtained presence of mother 558of the minor victim girl namely \\nMrs. Reshma w/o Hayath 559Sab Khasimmanavar, age: - 35 yrs., Occ: - Housewife, $r/o$, \\n560$c/o$ Nasir Beig Shaikh, Vathadev, Bicholim, Goa and 561brother of victim girl namely Mast. \\n562Subhanallah $s/o$ Hayath 563Sab Khasimmanavar, age 13 yrs., $r/o$, $c/o$ Nasir Beig \\n564Shaikh, Vathadev, Bicholim, Goawherein they both stated 565that accused person \\nmentioned at Col. No. 11 at Sl. 566No. Al 567was always seen visiting their rented room and was \\n\\n \\n \\n \\n \\n\\x0c568interacting with the victim girl. 569The accused person was also 570offering chocolates to the \\nvictim and used to call victim to his 571rented room. 572The brother of the victim in his \\nstatement 573disclosed that the accused person was showing them nude 574videos on his \\nmobile phone and he had threatened victim 575and her brother to not to disclose it to any one \\nin their 576family. 577The detail statements of above persons have been 578appended to case \\nfile. 579During further course of investigation, the minor victim girl 580was traced at her native \\nplace and was brought to Goa at 581residential place at Vathadev, Bicholim, Goa and thereafter \\n582was brought at Bicholim Police Station and her detail 583statement was recorded in \\npresence of Mr. AudaViegas, NGO 584BailanchoEkvot wherein she stated that accused person \\nwho 585is her neighbour, became friendly with her and he used to 586visit their rented room and \\nlater he convinced the her saying 587that he likes her and wants to get married to her as soon \\nas 588possible. 589The accused person in absence of his wife used to 590call the victim girl in his \\nrented room, used to give her 591chocolates and was also used to take her photographs. \\n592After 593many visits of the victim girl to the rented room of the 594accused person, accused \\nperson started showing nude 595photographs of men and woman to the victim girl and also \\n596started having forceful sexual intercourse with the victim. 597Further accused person took \\naway the victim to Tamil Nadu 598from lawful custody of her parents and thereafter dropped \\n599her to her grandfather place i.e. Yelladavahalli village at 600 \\n\\nPage 37 \\n\\nHaveri Karnataka. The detail statement of victim girl is 601appended to the case file. 602Further \\nas stated by the minor victim girl that the above 603noted accused person had sexual \\nintercourse with her, Sec 604376 IPC and Sec 4, 11 (iii) & 12 of POCSO Act 2012 was 605adduced \\nto the case and the intimation of the same was 606given to Hon'ble Court. 607During course of \\nfurther investigation, the minor victim girl 608was referred for medical examination at GMC \\nBambolim, 609wherein Dr. AnkitaBorkar, Lecturer, Dept. of 610Obstetrics&Gynaecology, GMC \\nBambolim conducted medical 611examination, wherein she preserved fetus for DNA profiling. \\n612During further course of investigation, obtained presence of 613two panch witnesses and \\nminor victim girl and conducted 614detail Scene of Offence Panchanama. 615Furtheraccused \\nperson Mr. Pulmurga $s/o$ Sokar Gawander, 616age 32 yrs, Occ- Mason, $r/o$ H.No. 617$71/B$ \\nBandarwada, 618Bicholim, Goa, presently residing at $c/o$ ShahidaNazir 619Shaikh, near Neha \\nCollection, Vathadev, Bicholim, Goa was 620traced and was placed under arrest in the said<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:08:54 [engine.py:317] Added request chatcmpl-e60c7b94d68f4899a38ce1c61eb8f725.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_14.txt...vLLM STDOUT: INFO:     127.0.0.1:51678 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:08:59 [logger.py:43] Received request chatcmpl-5182b8a1d5bc402d99ca60eae7b0b4a5: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n 36 \\n\\nDuring course of investigation, obtained presence of mother 558of the minor victim girl namely \\nMrs. Reshma w/o Hayath 559Sab Khasimmanavar, age: - 35 yrs., Occ: - Housewife, $r/o$, \\n560$c/o$ Nasir Beig Shaikh, Vathadev, Bicholim, Goa and 561brother of victim girl namely Mast. \\n562Subhanallah $s/o$ Hayath 563Sab Khasimmanavar, age 13 yrs., $r/o$, $c/o$ Nasir Beig \\n564Shaikh, Vathadev, Bicholim, Goawherein they both stated 565that accused person \\nmentioned at Col. No. 11 at Sl. 566No. Al 567was always seen visiting their rented room and was<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:08:59 [engine.py:317] Added request chatcmpl-5182b8a1d5bc402d99ca60eae7b0b4a5.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_14.txt...vLLM STDOUT: INFO:     127.0.0.1:56892 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:09:15 [logger.py:43] Received request chatcmpl-da553e52617f4d709f07debd1290b7a6: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n11 at Sl. 566No. Al 567was always seen visiting their rented room and was \\n\\n \\n \\n \\n \\n\\x0c568interacting with the victim girl. 569The accused person was also 570offering chocolates to the \\nvictim and used to call victim to his 571rented room. 572The brother of the victim in his \\nstatement 573disclosed that the accused person was showing them nude 574videos on his \\nmobile phone and he had threatened victim 575and her brother to not to disclose it to any one \\nin their 576family. 577The detail statements of above persons have been 578appended to case \\nfile. 579During further course of investigation, the minor victim girl 580was traced at her native \\nplace and was brought to Goa at 581residential place at Vathadev, Bicholim, Goa and thereafter \\n582was brought at Bicholim Police Station and her detail 583statement was recorded in \\npresence of Mr. AudaViegas, NGO 584BailanchoEkvot wherein she stated that accused person \\nwho 585is her neighbour, became friendly with her and he used to 586visit their rented room and \\nlater he convinced the her saying 587that he likes her and wants to get married to her as soon \\nas 588possible. 589The accused person in absence of his wife used to 590call the victim girl in his \\nrented room, used to give her 591chocolates and was also used to take her photographs. \\n592After 593many visits of the victim girl to the rented room of the 594accused person, accused \\nperson started showing nude 595photographs of men and woman to the victim girl and also \\n596started having forceful sexual intercourse with the victim. 597Further accused person took \\naway the victim to Tamil Nadu 598from lawful custody of her parents and thereafter dropped \\n599her to her grandfather place i.e. Yelladavahalli village at 600<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:09:15 [engine.py:317] Added request chatcmpl-da553e52617f4d709f07debd1290b7a6.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_14.txt...vLLM STDOUT: INFO:     127.0.0.1:43498 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:09:30 [logger.py:43] Received request chatcmpl-cc95746a6be64292bff5ba0798d9fa3e: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n592After 593many visits of the victim girl to the rented room of the 594accused person, accused \\nperson started showing nude 595photographs of men and woman to the victim girl and also \\n596started having forceful sexual intercourse with the victim. 597Further accused person took \\naway the victim to Tamil Nadu 598from lawful custody of her parents and thereafter dropped \\n599her to her grandfather place i.e. Yelladavahalli village at 600 \\n\\nPage 37<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:09:30 [engine.py:317] Added request chatcmpl-cc95746a6be64292bff5ba0798d9fa3e.\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/output2/ilovepdf_merged_14.txt...vLLM STDOUT: INFO:     127.0.0.1:49092 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:09:46 [logger.py:43] Received request chatcmpl-29f134c4a02444a1aa2a30800c810b0a: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nHaveri Karnataka. The detail statement of victim girl is 601appended to the case file. 602Further \\nas stated by the minor victim girl that the above 603noted accused person had sexual \\nintercourse with her, Sec 604376 IPC and Sec 4, 11 (iii) & 12 of POCSO Act 2012 was 605adduced \\nto the case and the intimation of the same was 606given to Hon\\'ble Court. 607During course of \\nfurther investigation, the minor victim girl 608was referred for medical examination at GMC \\nBambolim, 609wherein Dr. AnkitaBorkar, Lecturer, Dept. of 610Obstetrics&Gynaecology, GMC \\nBambolim conducted medical 611examination, wherein she preserved fetus for DNA profiling. \\n612During further course of investigation, obtained presence of 613two panch witnesses and \\nminor victim girl and conducted 614detail Scene of Offence Panchanama. 615Furtheraccused \\nperson Mr. Pulmurga $s/o$ Sokar Gawander, 616age 32 yrs, Occ- Mason, $r/o$ H.No. 617$71/B$ \\nBandarwada, 618Bicholim, Goa, presently residing at $c/o$ ShahidaNazir 619Shaikh, near Neha \\nCollection, Vathadev, Bicholim, Goa was 620traced and was placed under arrest in the said<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_14.txt...vLLM STDOUT: INFO 12-14 05:09:46 [engine.py:317] Added request chatcmpl-29f134c4a02444a1aa2a30800c810b0a.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_14.txt...vLLM STDOUT: INFO:     127.0.0.1:55678 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 57 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_14_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_14_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_14.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_14_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:33620 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:33628 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:10:03 [logger.py:43] Received request chatcmpl-a5ffbe4d974647f0b5b6d10b19771f2e: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n71/B$ \\nBandarwada, 618Bicholim, Goa, presently residing at $c/o$ ShahidaNazir 619Shaikh, near Neha \\nCollection, Vathadev, Bicholim, Goa was 620traced and was placed under arrest in the said \\ncrime after 621observing all SC guidelines and thereafter he was medically 622examined by the \\nMedical Officer, PHC Bicholim, who opined 623that accused person is fit to lodged in lock up. \\n624 The accused personMr. Pulmurga $s/o$ Sokar Gawander was 625referred for medical \\nexamination at Dept. of Forensic, 626Medicine and Toxicology, GMC Bambolim wherein Police \\n627Surgeon Dr. Ankush B. Patil, Lecturer, Dept. of Forensic, 628Medicine and Toxicology, GMC \\n\\n \\n\\x0cBambolim, Goa conducted 629medical examination of accused person and opined that \"On 630 \\n\\nPage 38 \\n\\nphysical and genital examination, there is nothing no 631posture evidence suggestive of \\ncommission of sexual 632intercourse, however the same cannot be ruled out and there 633is \\nnothing to suggest that he is incapable of performing 634sexual intercourse\". 635Further that on \\n12.09.2019, the accused person was 636produced before the Hon\\'ble Judicial Magistrate First \\nClass 637\\'C\\' Court at Bicholim and obtained 05 days Police Custody. 638During course of further \\ninvestigation, the statement of 639minor victim girl was recorded before the Hon\\'ble Judicial \\n640Magistrate First Class at Bicholim as per provisions of Sec. 641164 Cr.P.C. 642The certificate \\nstating birth date of victim girl was procured 643from the Headmaster, Govt. 644Higher Primary \\nSchool, 645Yalavadahalli, Hirekerur, Haveri District and same is taken 646on record and \\nappended to case file. 647Further on 16.09.2019 accused person Mr. Pulmurga $s/o$ 648Sokar \\nGawander, age 32 yrs, Occ- Mason, $r/o$ H.No. 649$71/B$, 650Bandarwada, Bicholim, Goa, \\npresently residing at $c/o$ 651ShahidaNazir Shaikh, near Neha Collection, Vathadev, \\n652Bicholim, Goa was produced before the President, Children\\'s 653Court in Goa at Panaji, \\nwherein accused person was 654remanded 07 days Police custody. 655During course of further \\ninvestigation, as Demand Draft 656required for DNA examination at the CDFD Hyderabad is yet \\n657to be issued by the Office of the Superintendent of Police 658 (North), Porvorim, the fetus \\nhas been preserved at Cold 659Storage, GSFSL, Verna. 660Arrangements are kept to forward \\n661fetus and blood samples of both victim and accused person 662 \\n\\nPage 39 \\n\\nto the Director CDFD, Hyderabad for DNA Profiling. The 663report of DNA profiling will be \\nsubmitted to Hon\\'ble Court as 664soon as same is received after examination. 665The overall \\ninvestigation in to the above crime, from the 666statement of minor victim girl it is transpired \\nthat accused 667person Mr. Pulmurga $s/o$ Sokar Gawander, age 32 yrs, Occ- 668Mason, \\n$r/o$ H.No. 669$71/B$ Bandarwada, Bicholim, Goa, 670presently residing at $c/o$ \\nShahidaNazir Shaikh, near Neha 671Collection, Vathadev, Bicholim, Goa showed objectionable \\n672content i.e. nude photos on his mobile phone to victim girl 673and his minor brother and \\nfurther had forcible sexual 674intercourse with minor victim girl of the complainant, age:- \\n67517 yrs. 676on three different occasions, thereby accused person 677committed rape of \\nminor victim girl. 678Thus<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:10:03 [engine.py:317] Added request chatcmpl-a5ffbe4d974647f0b5b6d10b19771f2e.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_15.txt...vLLM STDOUT: INFO:     127.0.0.1:33634 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:10:09 [logger.py:43] Received request chatcmpl-40389e283c5b4946932086124db066f2: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n71/B$ \\nBandarwada, 618Bicholim, Goa, presently residing at $c/o$ ShahidaNazir 619Shaikh, near Neha \\nCollection, Vathadev, Bicholim, Goa was 620traced and was placed under arrest in the said \\ncrime after 621observing all SC guidelines and thereafter he was medically 622examined by the \\nMedical Officer, PHC Bicholim, who opined 623that accused person is fit to lodged in lock up. \\n624 The accused personMr. Pulmurga $s/o$ Sokar Gawander was 625referred for medical \\nexamination at Dept. of Forensic, 626Medicine and Toxicology, GMC Bambolim wherein Police \\n627Surgeon Dr. Ankush B. Patil, Lecturer, Dept. of Forensic, 628Medicine and Toxicology, GMC \\n\\n \\n\\x0cBambolim, Goa conducted 629medical examination of accused person and opined that \"On 630 \\n\\nPage 38<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:10:09 [engine.py:317] Added request chatcmpl-40389e283c5b4946932086124db066f2.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_15.txt...vLLM STDOUT: INFO:     127.0.0.1:35636 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:10:25 [logger.py:43] Received request chatcmpl-ce3f8e0e3596478996678559b0a46647: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nAnkush B. Patil, Lecturer, Dept. of Forensic, 628Medicine and Toxicology, GMC \\n\\n \\n\\x0cBambolim, Goa conducted 629medical examination of accused person and opined that \"On 630 \\n\\nPage 38 \\n\\nphysical and genital examination, there is nothing no 631posture evidence suggestive of \\ncommission of sexual 632intercourse, however the same cannot be ruled out and there 633is \\nnothing to suggest that he is incapable of performing 634sexual intercourse\". 635Further that on \\n12.09.2019, the accused person was 636produced before the Hon\\'ble Judicial Magistrate First \\nClass 637\\'C\\' Court at Bicholim and obtained 05 days Police Custody. 638During course of further \\ninvestigation, the statement of 639minor victim girl was recorded before the Hon\\'ble Judicial \\n640Magistrate First Class at Bicholim as per provisions of Sec. 641164 Cr.P.C. 642The certificate \\nstating birth date of victim girl was procured 643from the Headmaster, Govt. 644Higher Primary \\nSchool, 645Yalavadahalli, Hirekerur, Haveri District and same is taken 646on record and \\nappended to case file. 647Further on 16.09.2019 accused person Mr. Pulmurga $s/o$ 648Sokar \\nGawander, age 32 yrs, Occ- Mason, $r/o$ H.No. 649$71/B$, 650Bandarwada, Bicholim, Goa, \\npresently residing at $c/o$ 651ShahidaNazir Shaikh, near Neha Collection, Vathadev, \\n652Bicholim, Goa was produced before the President, Children\\'s 653Court in Goa at Panaji, \\nwherein accused person was 654remanded 07 days Police custody. 655During course of further \\ninvestigation, as Demand Draft 656required for DNA examination at the CDFD Hyderabad is yet \\n657to be issued by the Office of the Superintendent of Police 658 (North), Porvorim, the fetus \\nhas been preserved at Cold 659Storage, GSFSL, Verna. 660Arrangements are kept to forward \\n661fetus and blood samples of both victim and accused person 662<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:10:25 [engine.py:317] Added request chatcmpl-ce3f8e0e3596478996678559b0a46647.\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_15.txt...vLLM STDOUT: INFO:     127.0.0.1:48436 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:10:40 [logger.py:43] Received request chatcmpl-4da4479c7b604800ac98c6fab7ecd6dd: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n649$71/B$, 650Bandarwada, Bicholim, Goa, \\npresently residing at $c/o$ 651ShahidaNazir Shaikh, near Neha Collection, Vathadev, \\n652Bicholim, Goa was produced before the President, Children\\'s 653Court in Goa at Panaji, \\nwherein accused person was 654remanded 07 days Police custody. 655During course of further \\ninvestigation, as Demand Draft 656required for DNA examination at the CDFD Hyderabad is yet \\n657to be issued by the Office of the Superintendent of Police 658 (North), Porvorim, the fetus \\nhas been preserved at Cold 659Storage, GSFSL, Verna. 660Arrangements are kept to forward \\n661fetus and blood samples of both victim and accused person 662 \\n\\nPage 39<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:10:40 [engine.py:317] Added request chatcmpl-4da4479c7b604800ac98c6fab7ecd6dd.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_15.txt...vLLM STDOUT: INFO:     127.0.0.1:33414 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:10:56 [logger.py:43] Received request chatcmpl-a2a3148fbc734c04adc0159fadd90b19: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nto the Director CDFD, Hyderabad for DNA Profiling. The 663report of DNA profiling will be \\nsubmitted to Hon\\'ble Court as 664soon as same is received after examination. 665The overall \\ninvestigation in to the above crime, from the 666statement of minor victim girl it is transpired \\nthat accused 667person Mr. Pulmurga $s/o$ Sokar Gawander, age 32 yrs, Occ- 668Mason, \\n$r/o$ H.No. 669$71/B$ Bandarwada, Bicholim, Goa, 670presently residing at $c/o$ \\nShahidaNazir Shaikh, near Neha 671Collection, Vathadev, Bicholim, Goa showed objectionable \\n672content i.e. nude photos on his mobile phone to victim girl 673and his minor brother and \\nfurther had forcible sexual 674intercourse with minor victim girl of the complainant, age:- \\n67517 yrs. 676on three different occasions, thereby accused person 677committed rape of \\nminor victim girl. 678Thus<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:10:56 [engine.py:317] Added request chatcmpl-a2a3148fbc734c04adc0159fadd90b19.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_15.txt...vLLM STDOUT: INFO:     127.0.0.1:39478 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 57 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_15_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_15_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_15.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_15_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:38898 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:38908 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:11:13 [logger.py:43] Received request chatcmpl-aa45e66a447d4bcfb15afb1c7cc55fcb: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\non his mobile phone to victim girl 673and his minor brother and \\nfurther had forcible sexual 674intercourse with minor victim girl of the complainant, age:- \\n67517 yrs. 676on three different occasions, thereby accused person 677committed rape of \\nminor victim girl. 678Thus accused person Mr. Pulmurga $s/o$ Sokar Gawander, 679age 32 yrs \\ncommitted an offence punishable under 680section 376 IPC, Sec. 6814, 6 &12 of POCSO Act. \\n682Hence the charge. 683 \\n17. Refer Notice served 684Date 685 (Acknowledgement to be placed) 686 \\n18. Despatched on 687 \\n19. No. of enclosures 688 \\n\\n \\n \\n\\x0c20. List of enclosures 689Yes 69024-09-2019 691 \\n\\nForwarded by Officer in charge \\n\\nSignature of Investigating officer \\n\\nName FILOMENO LUIS COSTA \\n\\nsubmitting Final report/Charge sheet Name \\nBHARAT BABLO KHARAT \\n\\nRank Inspector \\n\\nRank Sub-Inspector \\n\\nNo \\n\\nNo \\n\\nPage 40 \\n\\nPOLICE STATION 692Pora 693 AW. IN 694ENJUNA POLICE STATION 6951330 69614/02/2020 697DATE \\n698FINAL FORM/REPORT 699 (Under section 173Cr.P.C.) 700In the court of Hon'ble JMFC Court, \\nMapusa. 701 \\n\\n1.  Dist. North, 702P.S: Anjuna 703Year 2019 FIR No.134/19, Date 18/12/2019. 704 \\n\\n2.  Chargesheet No. 7057/2020. 706 3. Date 14/02/2020. 707 \\n\\n3.  (i) Act: IPC 708Section: 342,506(ii),376,307 IPC. 709 (ii) Act 710Section ===== 711 (iii) Act \\n\\n712Section====== 713 (iv) Other Acts & Section: ====, 714 \\n\\n4.  Type of Final Report: Charge sheet/Untraced/-Unoccurred/Not-Charge-sheet for want of \\n\\nevidence: Charge sheet. 715 \\n\\n5.  If F.R. Unoccurred: false/mistake of fact/mistake of Law/non-cognizable/civil Nature: \\n\\nCognizable. 716 \\n\\n6.  If Supplementary or Original: Original. 717 \\n\\n8 Name of the L.O. Amir Y.Taral. Rank: PSI, Anjuna P.S. No: ====== 718 \\n(a) Name of complainant/Informant: Mrs Everilda D'Mello.- 982005266 719 \\n(b)Father's/Husband's-Name: W/o Ivor Phillip D'Mello. 720 \\n\\n7.  Detail of properties/Articles/Documents recovered/Seized during investigation and relied \\n\\nupon (separate list can be attached, if necessary) 721 \\n\\nSr No \\n\\nProperty \\nDescriptio\\n\\nEstimated \\nValue (in \\n\\nP.S. \\nProperty \\n\\nFrom \\nwhom \\n\\nDisposal \\n\\n \\n \\n \\n \\n \\n \\n \\n\\x0cn \\n\\n2 \\n\\nSeparate \\nsheet \\nattached. \\n\\n1 \\n\\n01 \\n\\nRs.) \\n\\nRegister \\nNo. \\n\\nwhere \\nRecovered \\nor Seized \\n\\n3 \\n\\n4 \\n\\n5 \\n\\n6 \\n\\n722 \\n\\n83-21 723770 7242.37 725argh heard on 726der 727bai? 728& args befcharya 729 \\n\\nPage 41 \\n\\nAPOLICE STATION 730Pora 731ENJUNA POLICE RATION 7321330 73314/02/2020 734DATE 735FINAL \\nFORM/REPORT 736 (Under section 173Cr.P.C.) 737In the court of Hon'ble JMFC Court, Mapusa. \\n738 \\n\\n1.  Dist. North, 739P.S: Anjuna 740Year 2019 FIR No.134/19, Date 18/12/2019. 741 \\n\\n2.  Chargesheet No. 7427/2020. 743 3. Date 14/02/2020. 744 \\n\\n3.  (i) Act: IPC 745<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:11:13 [engine.py:317] Added request chatcmpl-aa45e66a447d4bcfb15afb1c7cc55fcb.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_16.txt...vLLM STDOUT: INFO:     127.0.0.1:38916 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:11:20 [logger.py:43] Received request chatcmpl-743e44b5b00046b2b5cdd98bbe8a7502: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n on his mobile phone to victim girl 673and his minor brother and \\nfurther had forcible sexual 674intercourse with minor victim girl of the complainant, age:- \\n67517 yrs. 676on three different occasions, thereby accused person 677committed rape of \\nminor victim girl. 678Thus accused person Mr. Pulmurga $s/o$ Sokar Gawander, 679age 32 yrs \\ncommitted an offence punishable under 680section 376 IPC, Sec. 6814, 6 &12 of POCSO Act. \\n682Hence the charge. 683 \\n17. Refer Notice served 684Date 685 (Acknowledgement to be placed) 686 \\n18. Despatched on 687 \\n19. No. of enclosures 688 \\n\\n \\n \\n\\x0c20. List of enclosures 689Yes 69024-09-2019 691 \\n\\nForwarded by Officer in charge \\n\\nSignature of Investigating officer \\n\\nName FILOMENO LUIS COSTA \\n\\nsubmitting Final report/Charge sheet Name \\nBHARAT BABLO KHARAT \\n\\nRank Inspector \\n\\nRank Sub-Inspector \\n\\nNo \\n\\nNo \\n\\nPage 40<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:11:20 [engine.py:317] Added request chatcmpl-743e44b5b00046b2b5cdd98bbe8a7502.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_16.txt...vLLM STDOUT: INFO:     127.0.0.1:52204 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:11:35 [logger.py:43] Received request chatcmpl-49880323528c45539e3cf512ddfa06ed: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nNo. of enclosures 688 \\n\\n \\n \\n\\x0c20. List of enclosures 689Yes 69024-09-2019 691 \\n\\nForwarded by Officer in charge \\n\\nSignature of Investigating officer \\n\\nName FILOMENO LUIS COSTA \\n\\nsubmitting Final report/Charge sheet Name \\nBHARAT BABLO KHARAT \\n\\nRank Inspector \\n\\nRank Sub-Inspector \\n\\nNo \\n\\nNo \\n\\nPage 40 \\n\\nPOLICE STATION 692Pora 693 AW. IN 694ENJUNA POLICE STATION 6951330 69614/02/2020 697DATE \\n698FINAL FORM/REPORT 699 (Under section 173Cr.P.C.) 700In the court of Hon\\'ble JMFC Court, \\nMapusa. 701 \\n\\n1.  Dist. North, 702P.S: Anjuna 703Year 2019 FIR No.134/19, Date 18/12/2019. 704 \\n\\n2.  Chargesheet No. 7057/2020. 706 3. Date 14/02/2020. 707 \\n\\n3.  (i) Act: IPC 708Section: 342,506(ii),376,307 IPC. 709 (ii) Act 710Section ===== 711 (iii) Act \\n\\n712Section====== 713 (iv) Other Acts & Section: ====, 714 \\n\\n4.  Type of Final Report: Charge sheet/Untraced/-Unoccurred/Not-Charge-sheet for want of \\n\\nevidence: Charge sheet. 715 \\n\\n5.  If F.R. Unoccurred: false/mistake of fact/mistake of Law/non-cognizable/civil Nature:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_16.txt...vLLM STDOUT: INFO 12-14 05:11:35 [engine.py:317] Added request chatcmpl-49880323528c45539e3cf512ddfa06ed.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_16.txt...vLLM STDOUT: INFO:     127.0.0.1:52510 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:11:51 [logger.py:43] Received request chatcmpl-f29f5a03e8604d72bc873cb1e0cb5224: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n715 \\n\\n5.  If F.R. Unoccurred: false/mistake of fact/mistake of Law/non-cognizable/civil Nature: \\n\\nCognizable. 716 \\n\\n6.  If Supplementary or Original: Original. 717 \\n\\n8 Name of the L.O. Amir Y.Taral. Rank: PSI, Anjuna P.S. No: ====== 718 \\n(a) Name of complainant/Informant: Mrs Everilda D\\'Mello.- 982005266 719 \\n(b)Father\\'s/Husband\\'s-Name: W/o Ivor Phillip D\\'Mello. 720 \\n\\n7.  Detail of properties/Articles/Documents recovered/Seized during investigation and relied \\n\\nupon (separate list can be attached, if necessary) 721 \\n\\nSr No \\n\\nProperty \\nDescriptio\\n\\nEstimated \\nValue (in \\n\\nP.S. \\nProperty \\n\\nFrom \\nwhom \\n\\nDisposal \\n\\n \\n \\n \\n \\n \\n \\n \\n\\x0cn \\n\\n2 \\n\\nSeparate \\nsheet \\nattached. \\n\\n1 \\n\\n01 \\n\\nRs.) \\n\\nRegister \\nNo. \\n\\nwhere \\nRecovered \\nor Seized \\n\\n3 \\n\\n4 \\n\\n5 \\n\\n6 \\n\\n722 \\n\\n83-21 723770 7242.37 725argh heard on 726der 727bai? 728& args befcharya 729 \\n\\nPage 41<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:11:51 [engine.py:317] Added request chatcmpl-f29f5a03e8604d72bc873cb1e0cb5224.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_16.txt...vLLM STDOUT: INFO:     127.0.0.1:50070 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:12:07 [logger.py:43] Received request chatcmpl-e88a3416ccc342c497492adffacc03c1: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\nProperty \\n\\nFrom \\nwhom \\n\\nDisposal \\n\\n \\n \\n \\n \\n \\n \\n \\n\\x0cn \\n\\n2 \\n\\nSeparate \\nsheet \\nattached. \\n\\n1 \\n\\n01 \\n\\nRs.) \\n\\nRegister \\nNo. \\n\\nwhere \\nRecovered \\nor Seized \\n\\n3 \\n\\n4 \\n\\n5 \\n\\n6 \\n\\n722 \\n\\n83-21 723770 7242.37 725argh heard on 726der 727bai? 728& args befcharya 729 \\n\\nPage 41 \\n\\nAPOLICE STATION 730Pora 731ENJUNA POLICE RATION 7321330 73314/02/2020 734DATE 735FINAL \\nFORM/REPORT 736 (Under section 173Cr.P.C.) 737In the court of Hon\\'ble JMFC Court, Mapusa. \\n738 \\n\\n1.  Dist. North, 739P.S: Anjuna 740Year 2019 FIR No.134/19, Date 18/12/2019. 741 \\n\\n2.  Chargesheet No. 7427/2020. 743 3. Date 14/02/2020. 744 \\n\\n3.  (i) Act: IPC 745<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:12:07 [engine.py:317] Added request chatcmpl-e88a3416ccc342c497492adffacc03c1.\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_16.txt...vLLM STDOUT: INFO:     127.0.0.1:35082 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 68 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_16_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_16_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/output2/ilovepdf_merged_16.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_16_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:42404 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:42416 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:12:24 [logger.py:43] Received request chatcmpl-53b0c2796a7149cca1499d38b89dd465: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n2019 FIR No.134/19, Date 18/12/2019. 741 \\n\\n2.  Chargesheet No. 7427/2020. 743 3. Date 14/02/2020. 744 \\n\\n3.  (i) Act: IPC 745Section: 342,506 (ii),376,307 IPC. 746 (ii) Act 747Section ===== 748 (iii) Act \\n\\n749Section====== 750 (iv) Other Acts & Section: ===== 751 \\n\\n4.  Type of Final Report: Charge sheet/Untraced/-Unoccurred/Not-Charge sheet for want of \\n\\nevidence: Charge sheet. 752 \\n\\n5.  If F.R. Unoccurred: false/mistake of fact/mistake of Law/non-cognizable/civil Nature: \\n\\nCognizable. 753 \\n\\n6.  Supplementary or Original: Original. 754 \\n\\n7.  Name of the I.O. Amir Y.Taral, Rank: PSI, Anjuna P.S. No: ====== 755 \\n\\n(a) Name of complainant/Informant: Mrs Everilda D\\'Mello. - 982005266 756 \\n(b)Father\\'s/Husband\\'s-Name: W/o Ivor Phillip D\\'Mello. 757 \\n\\n8.  Detail of properties/Articles/Documents recovered/Seized during investigation and relied \\n\\nupon (separate list can be attached, if necessary) 758 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cProperty \\nDescription \\nNo 1 \\n\\nEstimated \\nValue (in Rs.) \\n3 \\n\\nP.S. Property \\nRegister No. 4 \\n\\nSeparate sheet \\nattached. 01 \\n\\nDisposal 6 \\n\\nFrom whom \\nwhere \\nRecovered or \\nSeized 5 \\n\\n759 \\n\\n83-21 76023-21 7612-32 762argh heard on 763der 764bai? 765& argh befcharya 766 \\n\\nEstimated \\nValue (in Rs.) \\n3 \\n\\nP.S. Property \\nRegister No. 4 \\n\\nHaving \\nevidential \\nvalue \\n\\n771()/19 \\n\\nDisposal 6 \\n\\nSent to CDFD \\nHyderabad \\nvide letter no. \\nSP/North/Read\\ner/174/2020, dt \\n13/02/2020 \\n\\nFrom whom/ \\nwhere \\nRecovered or \\nSeized 5 \\n\\nPSI Amir Y. \\nTaral. Found at \\nCrime scene \\nand attached \\nunder scene of \\noffence \\npanchanama \\ndated \\n19/12/2019 by \\n\\nPage 42 \\n\\nProperty \\nDescription \\n\\nOne greenish \\ncolour sealed \\nenvelope \\ncontains one \\nwhitish paper \\nwrapped in it \\nblack and grey \\ncolour hairs of \\nhuman, \\nattached \\nunder scene of \\noffence \\npanchanama \\ndated \\n19/12/2019 \\nconcerned in \\nAnjuna PS Cr. \\nNo. 134/19 U/s \\n342, 506(ii), \\n376, 307 IPC \\nand marked as \\n\"Ex-A\" \\n\\n \\n \\n \\n \\n\\x0cRs 50/-apprx \\n\\n77(2)/19 \\n\\n-do- \\n\\nSent to CDFD \\nHyderabad \\nvide letter no. \\nSP/North/Read\\ner/174/2020, dt \\n13/02/2020 \\n\\nRs 200/- \\napprx. \\n\\n77(3)/19 \\n\\n-do- \\n\\nSent to CDFD \\nHyderabad \\nvide letter no. \\nSP/North/Read\\ner/174/2020, dt \\n13/02/2020 \\n\\nOne greenish \\ncolour sealed \\nenvelope \\ncontains in it \\none whitish \\ncolour pillow \\ncover, having \\nreddish stains \\nover it, having \\nlength of 68 \\ncmsx 42 cms, \\nattached \\nunder scene of \\noffence \\npanchanama \\ndated \\n19/12/2019 \\nconcerned in \\nAnjuna PS Cr. \\nNo. 134/19 U/s \\n342, 506(ii), \\n376, 307 IPC \\nand marked as \\n\"Ex-B\" \\n\\nOne greenish \\ncolour sealed \\nenvelope \\ncontains in it \\nWhitish colour \\nsealed parcel \\ncontaining in it \\nwhite colour \\npillow having \\ntag of \\n\\'SNOOZEEE\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:12:24 [engine.py:317] Added request chatcmpl-53b0c2796a7149cca1499d38b89dd465.\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_17.txt...vLLM STDOUT: INFO:     127.0.0.1:42432 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:12:30 [logger.py:43] Received request chatcmpl-27e3ee55108143b6ad1a218bba9a7bd4: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n 2019 FIR No.134/19, Date 18/12/2019. 741 \\n\\n2.  Chargesheet No. 7427/2020. 743 3. Date 14/02/2020. 744 \\n\\n3.  (i) Act: IPC 745Section: 342,506 (ii),376,307 IPC. 746 (ii) Act 747Section ===== 748 (iii) Act \\n\\n749Section====== 750 (iv) Other Acts & Section: ===== 751 \\n\\n4.  Type of Final Report: Charge sheet/Untraced/-Unoccurred/Not-Charge sheet for want of \\n\\nevidence: Charge sheet. 752 \\n\\n5.  If F.R. Unoccurred: false/mistake of fact/mistake of Law/non-cognizable/civil Nature: \\n\\nCognizable. 753 \\n\\n6.  Supplementary or Original: Original. 754 \\n\\n7.  Name of the I.O. Amir Y.Taral, Rank: PSI, Anjuna P.S. No: ====== 755 \\n\\n(a) Name of complainant/Informant: Mrs Everilda D\\'Mello. - 982005266 756 \\n(b)Father\\'s/Husband\\'s-Name: W/o Ivor Phillip D\\'Mello. 757 \\n\\n8.  Detail of properties/Articles/Documents recovered/Seized during investigation and relied \\n\\nupon (separate list can be attached, if necessary) 758 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cProperty \\nDescription \\nNo 1 \\n\\nEstimated \\nValue (in Rs.) \\n3 \\n\\nP.S. Property \\nRegister No. 4<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:12:30 [engine.py:317] Added request chatcmpl-27e3ee55108143b6ad1a218bba9a7bd4.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_17.txt...vLLM STDOUT: INFO:     127.0.0.1:45514 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:12:42 [logger.py:43] Received request chatcmpl-d7a1b479bd5b4f60ada0f26553e665ea: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n Detail of properties/Articles/Documents recovered/Seized during investigation and relied \\n\\nupon (separate list can be attached, if necessary) 758 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cProperty \\nDescription \\nNo 1 \\n\\nEstimated \\nValue (in Rs.) \\n3 \\n\\nP.S. Property \\nRegister No. 4 \\n\\nSeparate sheet \\nattached. 01 \\n\\nDisposal 6 \\n\\nFrom whom \\nwhere \\nRecovered or \\nSeized 5 \\n\\n759 \\n\\n83-21 76023-21 7612-32 762argh heard on 763der 764bai? 765& argh befcharya 766 \\n\\nEstimated \\nValue (in Rs.) \\n3 \\n\\nP.S. Property \\nRegister No. 4 \\n\\nHaving \\nevidential \\nvalue \\n\\n771()/19 \\n\\nDisposal 6 \\n\\nSent to CDFD \\nHyderabad \\nvide letter no. \\nSP/North/Read\\ner/174/2020, dt \\n13/02/2020 \\n\\nFrom whom/ \\nwhere \\nRecovered or \\nSeized 5 \\n\\nPSI Amir Y. \\nTaral. Found at \\nCrime scene \\nand attached \\nunder scene of \\noffence \\npanchanama \\ndated \\n19/12/2019 by \\n\\nPage 42 \\n\\nProperty \\nDescription<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_17.txt...vLLM STDOUT: INFO 12-14 05:12:42 [engine.py:317] Added request chatcmpl-d7a1b479bd5b4f60ada0f26553e665ea.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_17.txt...vLLM STDOUT: INFO:     127.0.0.1:46626 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:12:58 [logger.py:43] Received request chatcmpl-97e7678a92414d8ca88da8bd266c9b27: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\nSP/North/Read\\ner/174/2020, dt \\n13/02/2020 \\n\\nFrom whom/ \\nwhere \\nRecovered or \\nSeized 5 \\n\\nPSI Amir Y. \\nTaral. Found at \\nCrime scene \\nand attached \\nunder scene of \\noffence \\npanchanama \\ndated \\n19/12/2019 by \\n\\nPage 42 \\n\\nProperty \\nDescription \\n\\nOne greenish \\ncolour sealed \\nenvelope \\ncontains one \\nwhitish paper \\nwrapped in it \\nblack and grey \\ncolour hairs of \\nhuman, \\nattached \\nunder scene of \\noffence \\npanchanama \\ndated \\n19/12/2019 \\nconcerned in \\nAnjuna PS Cr. \\nNo. 134/19 U/s \\n342, 506(ii), \\n376, 307 IPC \\nand marked as \\n\"Ex-A\" \\n\\n \\n \\n \\n \\n\\x0cRs 50/-apprx \\n\\n77(2)/19 \\n\\n-do- \\n\\nSent to CDFD \\nHyderabad \\nvide letter no. \\nSP/North/Read\\ner/174/2020, dt \\n13/02/2020 \\n\\nRs 200/- \\napprx. \\n\\n77(3)/19 \\n\\n-do- \\n\\nSent to CDFD \\nHyderabad \\nvide letter no. \\nSP/North/Read\\ner/174/2020, dt \\n13/02/2020<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:12:58 [engine.py:317] Added request chatcmpl-97e7678a92414d8ca88da8bd266c9b27.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_17.txt...vLLM STDOUT: INFO:     127.0.0.1:35144 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_17.txt...vLLM STDOUT: INFO 12-14 05:13:14 [logger.py:43] Received request chatcmpl-e2cc4fcddaa74becab42a83b72a74575: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\nSP/North/Read\\ner/174/2020, dt \\n13/02/2020 \\n\\nRs 200/- \\napprx. \\n\\n77(3)/19 \\n\\n-do- \\n\\nSent to CDFD \\nHyderabad \\nvide letter no. \\nSP/North/Read\\ner/174/2020, dt \\n13/02/2020 \\n\\nOne greenish \\ncolour sealed \\nenvelope \\ncontains in it \\none whitish \\ncolour pillow \\ncover, having \\nreddish stains \\nover it, having \\nlength of 68 \\ncmsx 42 cms, \\nattached \\nunder scene of \\noffence \\npanchanama \\ndated \\n19/12/2019 \\nconcerned in \\nAnjuna PS Cr. \\nNo. 134/19 U/s \\n342, 506(ii), \\n376, 307 IPC \\nand marked as \\n\"Ex-B\" \\n\\nOne greenish \\ncolour sealed \\nenvelope \\ncontains in it \\nWhitish colour \\nsealed parcel \\ncontaining in it \\nwhite colour \\npillow having \\ntag of \\n\\'SNOOZEEE\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:13:14 [engine.py:317] Added request chatcmpl-e2cc4fcddaa74becab42a83b72a74575.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_17.txt...vLLM STDOUT: INFO:     127.0.0.1:37404 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 59 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_17_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_17_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_17.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_17_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:36118 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:36126 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:13:31 [logger.py:43] Received request chatcmpl-8db30baf08a6421ca1df26ce22e2a4aa: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n506(ii), \\n376, 307 IPC \\nand marked as \\n\"Ex-B\" \\n\\nOne greenish \\ncolour sealed \\nenvelope \\ncontains in it \\nWhitish colour \\nsealed parcel \\ncontaining in it \\nwhite colour \\npillow having \\ntag of \\n\\'SNOOZEEE\" \\nhaving reddish \\ncolour stains. \\nhaving length \\nof 60 cms x40 \\ncms, attached \\nunder scene of \\n\\n\\x0coffence \\npanchanama \\ndated \\n19/12/2019 \\nconcerned in \\nAnjuna PS Cr. \\nNo. 134/19 U/s \\n342, 506(ii), \\n376, 307 IPC \\nand marked as \\n\"Ex-C\" \\n\\n04 One \\ngreenish \\ncolour sealed \\nenvelope \\nsealed \\nenvelope \\nstains having \\nlength of 2.25 \\nmetres x2.20 \\nmetres, \\nattached \\ncontains one \\nwhitish colour \\nbed sheet with \\nreddish colour \\n\\nRs 500/- \\napprx. \\n\\n77(4)/19 \\n\\n-do- \\n\\n2 767Articles/Documents recovered/Seized during investigation and relied upon (separate list \\ncan be attached, if necessary) 7681 76901 77002 77103 772 \\n\\nPage 43 \\n\\n3 77305 774 \\n\\nunder scene \\nof offence \\npanchanama \\ndated \\n\\ndt 13/02/2020 \\n\\n \\n \\n \\n \\n \\n \\n\\x0cRs 50/- apprx. \\n\\n77(5)/19 \\n\\n--do-- \\n\\nSent herewith \\nchargesheet \\n776 \\n\\n19/12/2019 \\nconcerned in \\nAnjuna PS Cr. \\nNo. 134/19 U/s \\n342, 506(ii), \\n376, 307 IPC \\nand marked \\nas \"Ex-D\" \\n\\nOne greenish \\ncolour sealed \\nenvelope \\ncontains in it \\none stainless \\nsteel scissor \\nhaving pinkish \\ncolour handle \\ngrip having \\nwords \\nengraved on it \\nas \\'Flower \\nRose\\' attached \\nunder scene of \\noffence \\npanchanama \\ndated \\n19/12/2019 \\nconcerned in \\nAnjuna PS Cr. \\nNo. 134/19 U/s \\n342, 506(ii), \\n376, 307 IPC \\nand marked as \\n\"Ex-E\" \\n\\nPage 44 \\n\\n11. Particulars of accused persons charge sheeted: 777 (Use separate sheet for each \\n\\naccused) 778 SI. No A-1 (i) Name: Mr. Lalrinnunga Lalfakzuala. whether verified: Yes 779 (ii) \\nFather\\'s/Husband\\'s name: ====. 780 (iii) Date/Year of Birth: 22 yrs. 781 (iv) Sex: Male 782 (v) \\nNationality: Indian 783 (vi) Passport No: ====. Date of issue : ====== 784Place of issue: \\n\\n \\n\\x0c===== 785 (vii) Religion: Catholic. 786Whether SC/ST 787 (ix) Occupation: ====. 788 (x) \\nAddress: R/o:C-111/4(A), Section III, Chawlhhmun, Aizwal Municipal 789Council, Vaivakawn, \\nAizwaal, Mizoram. 790Whether verified: Yes 791 (xi) Provisional Criminal No. A-1. 792 (xii) \\nRegional Criminal No. 79328,112025 79418/12/2015 795if known) 796 (xiii) Date of Arrest: On \\n18/12/2019 at 08.01 hrs. 797 (xiv) Date of release on bail: In Judicial custody (produced \\nherewith). 798 (xv) Date on which forwarded to court -==== 799 (xvi) Under Acts & \\nSections: U/s: 342, 506(ii), 376, 307 IPC 800 (xvii) Name(s) and Address (es) of sureties: \\n====. 801 (xviii) Previous convictions with case reference 802 (xix) Status of accused: In \\nJudicial custody, produced herewith. 803Forwarded/Bailed by Police/Under Police Custody \\n/ Bailed by Court/In Judicial Cust<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:13:31 [engine.py:317] Added request chatcmpl-8db30baf08a6421ca1df26ce22e2a4aa.\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/output2/ilovepdf_merged_18.txt...vLLM STDOUT: INFO:     127.0.0.1:36130 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_18.txt...vLLM STDOUT: INFO 12-14 05:13:37 [logger.py:43] Received request chatcmpl-4eb68483f74a40bbb77eb5e5212670cc: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n 506(ii), \\n376, 307 IPC \\nand marked as \\n\"Ex-B\" \\n\\nOne greenish \\ncolour sealed \\nenvelope \\ncontains in it \\nWhitish colour \\nsealed parcel \\ncontaining in it \\nwhite colour \\npillow having \\ntag of \\n\\'SNOOZEEE\" \\nhaving reddish \\ncolour stains. \\nhaving length \\nof 60 cms x40 \\ncms, attached \\nunder scene of \\n\\n\\x0coffence \\npanchanama \\ndated \\n19/12/2019 \\nconcerned in \\nAnjuna PS Cr. \\nNo. 134/19 U/s \\n342, 506(ii), \\n376, 307 IPC \\nand marked as \\n\"Ex-C\" \\n\\n04 One \\ngreenish \\ncolour sealed \\nenvelope \\nsealed \\nenvelope \\nstains having \\nlength of 2.25 \\nmetres x2.20 \\nmetres, \\nattached \\ncontains one \\nwhitish colour \\nbed sheet with \\nreddish colour \\n\\nRs 500/- \\napprx. \\n\\n77(4)/19 \\n\\n-do- \\n\\n2 767Articles/Documents recovered/Seized during investigation and relied upon (separate list \\ncan be attached, if necessary) 7681 76901 77002 77103 772 \\n\\nPage 43 \\n\\n3 77305 774 \\n\\nunder scene \\nof offence \\npanchanama \\ndated \\n\\ndt 13/02/2020 \\n\\n \\n \\n \\n \\n \\n \\n\\x0cRs 50/- apprx. \\n\\n77(5)/19 \\n\\n--do-- \\n\\nSent herewith \\nchargesheet \\n776<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:13:37 [engine.py:317] Added request chatcmpl-4eb68483f74a40bbb77eb5e5212670cc.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_18.txt...vLLM STDOUT: INFO:     127.0.0.1:36146 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:13:52 [logger.py:43] Received request chatcmpl-9d5d160a56db43b4b345e4f047938b54: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n134/19 U/s \\n342, 506(ii), \\n376, 307 IPC \\nand marked as \\n\"Ex-C\" \\n\\n04 One \\ngreenish \\ncolour sealed \\nenvelope \\nsealed \\nenvelope \\nstains having \\nlength of 2.25 \\nmetres x2.20 \\nmetres, \\nattached \\ncontains one \\nwhitish colour \\nbed sheet with \\nreddish colour \\n\\nRs 500/- \\napprx. \\n\\n77(4)/19 \\n\\n-do- \\n\\n2 767Articles/Documents recovered/Seized during investigation and relied upon (separate list \\ncan be attached, if necessary) 7681 76901 77002 77103 772 \\n\\nPage 43 \\n\\n3 77305 774 \\n\\nunder scene \\nof offence \\npanchanama \\ndated \\n\\ndt 13/02/2020 \\n\\n \\n \\n \\n \\n \\n \\n\\x0cRs 50/- apprx. \\n\\n77(5)/19 \\n\\n--do-- \\n\\nSent herewith \\nchargesheet \\n776 \\n\\n19/12/2019 \\nconcerned in \\nAnjuna PS Cr. \\nNo. 134/19 U/s \\n342, 506(ii), \\n376, 307 IPC \\nand marked \\nas \"Ex-D\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:13:52 [engine.py:317] Added request chatcmpl-9d5d160a56db43b4b345e4f047938b54.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_18.txt...vLLM STDOUT: INFO:     127.0.0.1:48184 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:14:08 [logger.py:43] Received request chatcmpl-62362f09e9ec46b49f08c04eca1d6e68: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n\\n77(5)/19 \\n\\n--do-- \\n\\nSent herewith \\nchargesheet \\n776 \\n\\n19/12/2019 \\nconcerned in \\nAnjuna PS Cr. \\nNo. 134/19 U/s \\n342, 506(ii), \\n376, 307 IPC \\nand marked \\nas \"Ex-D\" \\n\\nOne greenish \\ncolour sealed \\nenvelope \\ncontains in it \\none stainless \\nsteel scissor \\nhaving pinkish \\ncolour handle \\ngrip having \\nwords \\nengraved on it \\nas \\'Flower \\nRose\\' attached \\nunder scene of \\noffence \\npanchanama \\ndated \\n19/12/2019 \\nconcerned in \\nAnjuna PS Cr. \\nNo. 134/19 U/s \\n342, 506(ii), \\n376, 307 IPC \\nand marked as \\n\"Ex-E\" \\n\\nPage 44 \\n\\n11. Particulars of accused persons charge sheeted: 777 (Use separate sheet for each \\n\\naccused) 778 SI. No A-1 (i) Name: Mr. Lalrinnunga Lalfakzuala. whether verified: Yes 779 (ii) \\nFather\\'s/Husband\\'s name: ====. 780 (iii) Date/Year of Birth: 22 yrs. 781 (iv) Sex: Male 782 (v) \\nNationality: Indian 783 (vi) Passport No: ====. Date of issue : ====== 784Place of issue:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:14:08 [engine.py:317] Added request chatcmpl-62362f09e9ec46b49f08c04eca1d6e68.\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_18.txt...vLLM STDOUT: INFO:     127.0.0.1:55924 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:14:23 [logger.py:43] Received request chatcmpl-f47b7d29992a439fa8f4ea264eabe0fb: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n780 (iii) Date/Year of Birth: 22 yrs. 781 (iv) Sex: Male 782 (v) \\nNationality: Indian 783 (vi) Passport No: ====. Date of issue : ====== 784Place of issue: \\n\\n \\n\\x0c===== 785 (vii) Religion: Catholic. 786Whether SC/ST 787 (ix) Occupation: ====. 788 (x) \\nAddress: R/o:C-111/4(A), Section III, Chawlhhmun, Aizwal Municipal 789Council, Vaivakawn, \\nAizwaal, Mizoram. 790Whether verified: Yes 791 (xi) Provisional Criminal No. A-1. 792 (xii) \\nRegional Criminal No. 79328,112025 79418/12/2015 795if known) 796 (xiii) Date of Arrest: On \\n18/12/2019 at 08.01 hrs. 797 (xiv) Date of release on bail: In Judicial custody (produced \\nherewith). 798 (xv) Date on which forwarded to court -==== 799 (xvi) Under Acts & \\nSections: U/s: 342, 506(ii), 376, 307 IPC 800 (xvii) Name(s) and Address (es) of sureties: \\n====. 801 (xviii) Previous convictions with case reference 802 (xix) Status of accused: In \\nJudicial custody, produced herewith. 803Forwarded/Bailed by Police/Under Police Custody \\n/ Bailed by Court/In Judicial Cust<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:14:23 [engine.py:317] Added request chatcmpl-f47b7d29992a439fa8f4ea264eabe0fb.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_18.txt...vLLM STDOUT: INFO:     127.0.0.1:35390 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 59 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_18_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_18_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_18.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_18_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:54002 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:54014 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:14:41 [logger.py:43] Received request chatcmpl-821a087e52ef497d99ff5b60ee39d545: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nes) of sureties: \\n====. 801 (xviii) Previous convictions with case reference 802 (xix) Status of accused: In \\nJudicial custody, produced herewith. 803Forwarded/Bailed by Police/Under Police Custody \\n/ Bailed by Court/In Judicial Custody/Absconding/Proclaimed offender. 80404 805 \\n\\nPage 45 \\n\\n5 806 \\n12. Particulars of accused persons not charge sheeted: NIL 807 (Use separate sheet for each \\naccused) 808 SI. No A-1 (i) Name: ===, whether verified: = 809 (ii) Father's/Husband's name: \\n====, 810 (iii) Date/Year of Birth: ==. 811 (iv) Sex: == 812 (v) Nationality: == 813 (vi) Passport \\nNo: ===. Date of issue : ====== 814Place of issue: ===== 815 (vii) Religion: ==. 816Whether \\nSC/ST 817 (ix) Occupation: ====. 818 (x) Address: ==== 819Whether verified: == 820 (xi) \\nProvisional Criminal No. 821 (xii) Regional Criminal No. 822if known) 823 (xiii) Date of Arrest: \\n====. 824 (xiv) Date of release on bail: ==== 825 (xv) Date on which forwarded to court -==== \\n826 (xvi) Under Acts & Sections: ==== 827 (xvii) Name(s) and Address (es) of sureties: \\nReleased on bail by Court. 828 (xviii) Previous convictions with case reference 829 (xix) Status \\nof accused: ==== 830Forwarded/Bailed by Police/Under Police Custody/Bailed by Court/In \\nJudicial Custody/Absconding/Proclaimed offender. 831 \\nPage 46 \\n\\nl'articulars of Witnesses to be examined: 8326 833 \\n\\nNo 1 \\n\\nName 2 \\n\\n1 \\n\\nMrs \\nEverilda \\nD'Mello \\n\\nFather's/\\nHusband\\n's Name \\n3 \\n\\nIvor Philip \\nD'Mello \\n\\nDate/ \\nYear of \\nBirth. 4 \\n\\nOccupat\\nion 5 \\n\\nAddress \\n6 \\n\\n63 yrs \\n\\nBusiness \\n\\nMello \\nRosa \\nHotel, \\nMainath \\nBhati, \\nArpora, \\n\\nType —Å \\nEviden \\nrendere \\n7 \\n\\nCompl \\n834834834834\\n\\n834834834834\\n\\n834834834834\\n\\n834834834834 \\n\\n \\n \\n\\x0c2 \\n\\n3 \\n\\n4 \\n\\nMs Lizia \\nD'Souza \\n\\nJƒÅseph \\nD'Souza \\n\\n30 yrs \\n\\nPvt \\nservice \\n\\nMr \\nJitender \\nSingh \\n\\nRavindra \\nSingh \\n\\n34 yrs \\n\\nPvt \\nservice \\n\\nMr. \\nBalkrishn\\na Pandey \\n\\nS/o \\nShivkuma\\nr Pandey \\n\\n40 yrs \\n\\nPvt. \\nService \\n\\nBardez \\nGoa, N/o \\nAvinash \\nBuilding, \\nPlot 349, \\n33 Road, \\nBandra \\nWest, \\nMumbai \\n\\nHNo. \\n157/C, \\nGaurawa\\ndo, \\nCalangut\\ne, Goa \\n\\nC/o Mrs \\nSharmila \\nPednekar, \\nbehind \\nCasa \\nSeverina, \\nNr. \\nNewton \\nSuper \\nmarket, \\nCalangut\\ne, Goa. \\n\\nRoom no. \\nA1-002, \\nresort \\nMello \\nRosa, \\nMainathb\\nhati, \\nArpora, \\nBardez, \\nGoa n/o \\nGram: \\n\\nPanch V \\n835835835835 \\n\\n--dc \\n836836836836 \\n\\nWitn 837 \\n\\n \\n \\n \\n \\n\\x0c5 \\n\\n6 \\n\\nMr. \\nSachin \\nNaik \\n\\nThippesu\\namy Naik \\n\\n28 yrs \\n\\nPvt.Servi\\nce \\n\\nSunil \\nKumar \\nPanday \\n\\nBhaiya \\nRam \\nPanday \\n\\n25 yrs \\n\\nPvt. \\nService \\n\\nWitne 838 \\n\\nWitnes \\n839839839839 \\n\\nPaderi, \\nTehsil-Thi\\nthore, \\nZilla-Riwa\\n,<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:14:41 [engine.py:317] Added request chatcmpl-821a087e52ef497d99ff5b60ee39d545.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_19.txt...vLLM STDOUT: INFO:     127.0.0.1:54024 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:14:45 [logger.py:43] Received request chatcmpl-5c6d93c25a6c43a192350f051335e087: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nes) of sureties: \\n====. 801 (xviii) Previous convictions with case reference 802 (xix) Status of accused: In \\nJudicial custody, produced herewith. 803Forwarded/Bailed by Police/Under Police Custody \\n/ Bailed by Court/In Judicial Custody/Absconding/Proclaimed offender. 80404 805 \\n\\nPage 45<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:14:45 [engine.py:317] Added request chatcmpl-5c6d93c25a6c43a192350f051335e087.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_19.txt...vLLM STDOUT: INFO:     127.0.0.1:54034 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:15:00 [logger.py:43] Received request chatcmpl-ec27522379954d9d958412ad3d209507: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n801 (xviii) Previous convictions with case reference 802 (xix) Status of accused: In \\nJudicial custody, produced herewith. 803Forwarded/Bailed by Police/Under Police Custody \\n/ Bailed by Court/In Judicial Custody/Absconding/Proclaimed offender. 80404 805 \\n\\nPage 45 \\n\\n5 806 \\n12. Particulars of accused persons not charge sheeted: NIL 807 (Use separate sheet for each \\naccused) 808 SI. No A-1 (i) Name: ===, whether verified: = 809 (ii) Father\\'s/Husband\\'s name: \\n====, 810 (iii) Date/Year of Birth: ==. 811 (iv) Sex: == 812 (v) Nationality: == 813 (vi) Passport \\nNo: ===. Date of issue : ====== 814Place of issue: ===== 815 (vii) Religion: ==. 816Whether \\nSC/ST 817 (ix) Occupation: ====. 818 (x) Address: ==== 819Whether verified: == 820 (xi) \\nProvisional Criminal No. 821 (xii) Regional Criminal No. 822if known) 823 (xiii) Date of Arrest: \\n====. 824 (xiv) Date of release on bail: ==== 825 (xv) Date on which forwarded to court -==== \\n826 (xvi) Under Acts & Sections: ==== 827 (xvii) Name(s) and Address (es) of sureties: \\nReleased on bail by Court. 828 (xviii) Previous convictions with case reference 829 (xix) Status \\nof accused: ==== 830Forwarded/Bailed by Police/Under Police Custody/Bailed by Court/In \\nJudicial Custody/Absconding/Proclaimed offender. 831 \\nPage 46<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_19.txt...vLLM STDOUT: INFO 12-14 05:15:00 [engine.py:317] Added request chatcmpl-ec27522379954d9d958412ad3d209507.\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_19.txt...vLLM STDOUT: INFO:     127.0.0.1:52362 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:15:16 [logger.py:43] Received request chatcmpl-0ab6717b9a6a40aa804f6d57c54a1299: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n824 (xiv) Date of release on bail: ==== 825 (xv) Date on which forwarded to court -==== \\n826 (xvi) Under Acts & Sections: ==== 827 (xvii) Name(s) and Address (es) of sureties: \\nReleased on bail by Court. 828 (xviii) Previous convictions with case reference 829 (xix) Status \\nof accused: ==== 830Forwarded/Bailed by Police/Under Police Custody/Bailed by Court/In \\nJudicial Custody/Absconding/Proclaimed offender. 831 \\nPage 46 \\n\\nl\\'articulars of Witnesses to be examined: 8326 833 \\n\\nNo 1 \\n\\nName 2 \\n\\n1 \\n\\nMrs \\nEverilda \\nD\\'Mello \\n\\nFather\\'s/\\nHusband\\n\\'s Name \\n3 \\n\\nIvor Philip \\nD\\'Mello \\n\\nDate/ \\nYear of \\nBirth. 4 \\n\\nOccupat\\nion 5 \\n\\nAddress \\n6 \\n\\n63 yrs \\n\\nBusiness \\n\\nMello \\nRosa \\nHotel, \\nMainath \\nBhati, \\nArpora, \\n\\nType —Å \\nEviden \\nrendere \\n7 \\n\\nCompl \\n834834834834\\n\\n834834834834\\n\\n834834834834\\n\\n834834834834 \\n\\n \\n \\n\\x0c2 \\n\\n3 \\n\\n4 \\n\\nMs Lizia \\nD\\'Souza \\n\\nJƒÅseph \\nD\\'Souza \\n\\n30 yrs \\n\\nPvt \\nservice \\n\\nMr \\nJitender \\nSingh \\n\\nRavindra \\nSingh \\n\\n34 yrs \\n\\nPvt \\nservice \\n\\nMr. \\nBalkrishn\\na Pandey \\n\\nS/o \\nShivkuma\\nr Pandey \\n\\n40 yrs \\n\\nPvt. \\nService<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:15:16 [engine.py:317] Added request chatcmpl-0ab6717b9a6a40aa804f6d57c54a1299.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_19.txt...vLLM STDOUT: INFO:     127.0.0.1:51210 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:15:31 [logger.py:43] Received request chatcmpl-3943d0b55b2441c7ac7a61aad708c369: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n4 \\n\\nOccupat\\nion 5 \\n\\nAddress \\n6 \\n\\n63 yrs \\n\\nBusiness \\n\\nMello \\nRosa \\nHotel, \\nMainath \\nBhati, \\nArpora, \\n\\nType —Å \\nEviden \\nrendere \\n7 \\n\\nCompl \\n834834834834\\n\\n834834834834\\n\\n834834834834\\n\\n834834834834 \\n\\n \\n \\n\\x0c2 \\n\\n3 \\n\\n4 \\n\\nMs Lizia \\nD\\'Souza \\n\\nJƒÅseph \\nD\\'Souza \\n\\n30 yrs \\n\\nPvt \\nservice \\n\\nMr \\nJitender \\nSingh \\n\\nRavindra \\nSingh \\n\\n34 yrs \\n\\nPvt \\nservice \\n\\nMr. \\nBalkrishn\\na Pandey \\n\\nS/o \\nShivkuma\\nr Pandey \\n\\n40 yrs \\n\\nPvt. \\nService \\n\\nBardez \\nGoa, N/o \\nAvinash \\nBuilding, \\nPlot 349, \\n33 Road, \\nBandra \\nWest, \\nMumbai \\n\\nHNo. \\n157/C, \\nGaurawa\\ndo, \\nCalangut\\ne, Goa \\n\\nC/o Mrs \\nSharmila \\nPednekar, \\nbehind \\nCasa \\nSeverina, \\nNr. \\nNewton \\nSuper \\nmarket, \\nCalangut\\ne, Goa. \\n\\nRoom no. \\nA1-002, \\nresort \\nMello \\nRosa, \\nMainathb\\nhati, \\nArpora, \\nBardez, \\nGoa n/o \\nGram: \\n\\nPanch V \\n835835835835 \\n\\n--dc \\n836836836836 \\n\\nWitn 837 \\n\\n \\n \\n \\n \\n\\x0c5 \\n\\n6 \\n\\nMr. \\nSachin \\nNaik \\n\\nThippesu\\namy Naik \\n\\n28 yrs \\n\\nPvt.Servi\\nce \\n\\nSunil \\nKumar \\nPanday \\n\\nBhaiya \\nRam \\nPanday \\n\\n25 yrs \\n\\nPvt. \\nService \\n\\nWitne 838 \\n\\nWitnes \\n839839839839 \\n\\nPaderi, \\nTehsil-Thi\\nthore, \\nZilla-Riwa\\n,<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:15:31 [engine.py:317] Added request chatcmpl-3943d0b55b2441c7ac7a61aad708c369.\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_19.txt...vLLM STDOUT: INFO:     127.0.0.1:48708 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 64 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_19_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_19_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_19.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_19_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:44920 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:44926 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:15:49 [logger.py:43] Received request chatcmpl-ee7d1690857d42a98e4fcb19ea26aef0: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nKumar \\nPanday \\n\\nBhaiya \\nRam \\nPanday \\n\\n25 yrs \\n\\nPvt. \\nService \\n\\nWitne 838 \\n\\nWitnes \\n839839839839 \\n\\nPaderi, \\nTehsil-Thi\\nthore, \\nZilla-Riwa\\n, Madhya \\nPradesh \\n\\nResort \\nMello \\nRosa, \\nB4-203, \\nMainathb\\nhati, \\nArpora, \\nGoa, n/o \\n12/349, \\nSidhavira\\nppa, \\nBadavan\\ne, 7th \\nCross, \\nDavangar\\ni, \\nKarnatak\\na. \\n\\nRoom no. \\nA1-103, \\nFirst \\nfloor, \\nresort \\nMello \\nRosa, \\nArpora, \\nGoa. n/o \\nStreet no. \\n6, \\nAmbedka\\nr nagar, \\nGiaspura, \\nLohora, \\n\\n \\n \\n\\x0c7 \\n\\n8 \\n\\n9 \\n\\n23 yrs \\n\\nPvt.Servi\\nce \\n\\nManish \\nSharma \\n@Sharma \\n\\nKumaima \\nSingh \\nYudhveer \\nKumain@\\nSingh \\n\\n= \\n\\nMajor \\n\\nDoctor \\n\\nDr \\nAkshata \\nAmonkar \\n\\nDr Sheryl \\nSuares \\n\\nMajor \\n\\nDoctor \\n\\nWitnes \\n84084084084\\n\\n0 \\n\\nWitnes \\n841841841841 \\n\\nWitnes \\n842842842842 \\n\\nLudhiana, \\nPunjab. \\n\\nRoom no. \\nA1-103, \\nFirst \\nfloor, \\nresort \\nMello \\nRosa, \\nArpora, \\nGoa, n'o \\nSaroth, \\nKhanda \\nsarot, \\nTehri, \\nGhatwal, \\nUttarakha\\nnd. \\n\\nC/o Dept \\nof \\nObstetric\\ns & \\nGynecolo\\ngy, GMC, \\nBamboli\\nm, Goa \\n\\nC/o Det \\nof \\nForensic \\nMedicine \\n& \\nToxicolog\\ny Dept \\nGMC, \\nGoa. \\n\\n10 \\n\\nNilesh \\n\\nD.Naik \\n\\nMajor \\n\\nPC \\n\\nC/o Goa \\nPolice \\n\\nWitnes \\n843 \\n\\n \\n \\n \\n \\n\\x0cNaik \\n\\nBNo.5841 \\n\\n11 \\n\\nUmanatƒ± \\nNuk \\n\\nL.Naik \\n\\nMajor \\n\\nService \\n\\nPage 47 \\n\\n7 845 \\n\\n12. \\n\\n13. \\n\\nMrs \\nMary \\nJoao \\n93251319\\n10 \\n\\nMajor \\n\\n(Draftsm\\nan) \\nService \\n\\nMr Ivor \\nPhilip \\nD'Mello \\n\\nDamien \\nFrank \\nD'Mello \\n\\n70 yrs \\n\\nBusiness \\n\\nWitnes \\n844 \\n\\nWitnes \\n\\nWitnes 847 \\n\\nPhotogra\\nphy Unit, \\nCrime \\nbranch. \\nPHQ \\nPanaji. \\n\\nC/o \\nFinger \\nprint \\nbureau, \\nVerna, \\nGoa. \\n\\nC/o \\nPWID, \\n305, \\nGovt. \\nComplex \\nbuilding, \\nMorod, \\nMapusa, \\nGoa. \\n\\nResort \\nMello \\nRosa, \\nMainath \\nBhati, \\nArpora, \\nBardez \\nGoa. N/o \\nAvinash \\nBuilding, \\nPlot 349, \\n\\n \\n \\n \\n \\n \\n\\x0c14. \\n\\nAmir \\nTaral \\n\\nYesulo \\nTaral \\n\\nMajor \\n\\nPSI \\n\\n33 Road, \\nBandra \\nWest, \\nMumbai \\n400050 \\n\\nC/o \\nAnjuna \\nPolice \\nStation. \\n\\nI.O. 848 \\n\\n14. If F.R is False, indicate action taken or proposed to be taken u/s 182/211 I.P.C.: 849 \\n\\n15. Result of Laboratory Analysis: 850D.S. Ne 851Negi 852INA Examiner-. 85309. 854Mapari. \\n\\n855EASL Verna 856PW1O 857 \\n\\nPage 48 \\n\\n16. Brief fact of the case (Add separate sheet, if necessary): 858MAY IT PLEASE YOUR \\n\\nHONOUR 859In the limits of Your Hon'ble Court and within the Jurisdiction of Anjuna \\n860Police Station, that on 18/12/2019 at around 02.00 hrs at Room No. B2-104 at<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:15:49 [engine.py:317] Added request chatcmpl-ee7d1690857d42a98e4fcb19ea26aef0.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_20.txt...vLLM STDOUT: INFO:     127.0.0.1:44930 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:15:55 [logger.py:43] Received request chatcmpl-8bc3854ab1c84404a510bbde10ff72e7: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n \\nKumar \\nPanday \\n\\nBhaiya \\nRam \\nPanday \\n\\n25 yrs \\n\\nPvt. \\nService \\n\\nWitne 838 \\n\\nWitnes \\n839839839839 \\n\\nPaderi, \\nTehsil-Thi\\nthore, \\nZilla-Riwa\\n, Madhya \\nPradesh \\n\\nResort \\nMello \\nRosa, \\nB4-203, \\nMainathb\\nhati, \\nArpora, \\nGoa, n/o \\n12/349, \\nSidhavira\\nppa, \\nBadavan\\ne, 7th \\nCross, \\nDavangar\\ni, \\nKarnatak\\na. \\n\\nRoom no. \\nA1-103, \\nFirst \\nfloor, \\nresort \\nMello \\nRosa, \\nArpora, \\nGoa. n/o \\nStreet no. \\n6, \\nAmbedka\\nr nagar, \\nGiaspura, \\nLohora, \\n\\n \\n \\n\\x0c7 \\n\\n8 \\n\\n9 \\n\\n23 yrs \\n\\nPvt.Servi\\nce \\n\\nManish \\nSharma \\n@Sharma \\n\\nKumaima \\nSingh \\nYudhveer \\nKumain@\\nSingh \\n\\n= \\n\\nMajor \\n\\nDoctor \\n\\nDr \\nAkshata \\nAmonkar \\n\\nDr Sheryl \\nSuares \\n\\nMajor \\n\\nDoctor \\n\\nWitnes \\n84084084084\\n\\n0 \\n\\nWitnes \\n841841841841 \\n\\nWitnes \\n842842842842 \\n\\nLudhiana, \\nPunjab. \\n\\nRoom no. \\nA1-103, \\nFirst \\nfloor, \\nresort \\nMello \\nRosa, \\nArpora, \\nGoa, n\\'o \\nSaroth, \\nKhanda \\nsarot, \\nTehri, \\nGhatwal, \\nUttarakha\\nnd. \\n\\nC/o Dept \\nof \\nObstetric\\ns & \\nGynecolo\\ngy, GMC, \\nBamboli\\nm, Goa \\n\\nC/o Det \\nof \\nForensic \\nMedicine \\n& \\nToxicolog\\ny Dept \\nGMC, \\nGoa. \\n\\n10 \\n\\nNilesh \\n\\nD.Naik \\n\\nMajor \\n\\nPC<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:15:55 [engine.py:317] Added request chatcmpl-8bc3854ab1c84404a510bbde10ff72e7.\n",
            "\u001b[2KProcessing 3 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_20.txt...vLLM STDOUT: INFO:     127.0.0.1:44934 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:16:11 [logger.py:43] Received request chatcmpl-1857f80909db4e96ae01f342390f8864: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\nA1-103, \\nFirst \\nfloor, \\nresort \\nMello \\nRosa, \\nArpora, \\nGoa, n\\'o \\nSaroth, \\nKhanda \\nsarot, \\nTehri, \\nGhatwal, \\nUttarakha\\nnd. \\n\\nC/o Dept \\nof \\nObstetric\\ns & \\nGynecolo\\ngy, GMC, \\nBamboli\\nm, Goa \\n\\nC/o Det \\nof \\nForensic \\nMedicine \\n& \\nToxicolog\\ny Dept \\nGMC, \\nGoa. \\n\\n10 \\n\\nNilesh \\n\\nD.Naik \\n\\nMajor \\n\\nPC \\n\\nC/o Goa \\nPolice \\n\\nWitnes \\n843 \\n\\n \\n \\n \\n \\n\\x0cNaik \\n\\nBNo.5841 \\n\\n11 \\n\\nUmanatƒ± \\nNuk \\n\\nL.Naik \\n\\nMajor \\n\\nService \\n\\nPage 47 \\n\\n7 845 \\n\\n12. \\n\\n13. \\n\\nMrs \\nMary \\nJoao \\n93251319\\n10 \\n\\nMajor \\n\\n(Draftsm\\nan) \\nService \\n\\nMr Ivor \\nPhilip \\nD\\'Mello \\n\\nDamien \\nFrank \\nD\\'Mello \\n\\n70 yrs \\n\\nBusiness \\n\\nWitnes \\n844 \\n\\nWitnes \\n\\nWitnes 847 \\n\\nPhotogra\\nphy Unit, \\nCrime \\nbranch. \\nPHQ \\nPanaji. \\n\\nC/o \\nFinger \\nprint \\nbureau, \\nVerna, \\nGoa. \\n\\nC/o \\nPWID, \\n305, \\nGovt. \\nComplex \\nbuilding, \\nMorod, \\nMapusa, \\nGoa. \\n\\nResort \\nMello \\nRosa, \\nMainath \\nBhati, \\nArpora, \\nBardez \\nGoa. N/o \\nAvinash \\nBuilding, \\nPlot 349, \\n\\n \\n \\n \\n \\n \\n\\x0c14. \\n\\nAmir \\nTaral \\n\\nYesulo \\nTaral \\n\\nMajor \\n\\nPSI \\n\\n33 Road, \\nBandra \\nWest, \\nMumbai \\n400050 \\n\\nC/o \\nAnjuna \\nPolice \\nStation. \\n\\nI.O. 848<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:16:11 [engine.py:317] Added request chatcmpl-1857f80909db4e96ae01f342390f8864.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_20.txt...vLLM STDOUT: INFO:     127.0.0.1:32880 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:16:26 [logger.py:43] Received request chatcmpl-3741280202eb410384585767c0058869: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n\\nAmir \\nTaral \\n\\nYesulo \\nTaral \\n\\nMajor \\n\\nPSI \\n\\n33 Road, \\nBandra \\nWest, \\nMumbai \\n400050 \\n\\nC/o \\nAnjuna \\nPolice \\nStation. \\n\\nI.O. 848 \\n\\n14. If F.R is False, indicate action taken or proposed to be taken u/s 182/211 I.P.C.: 849 \\n\\n15. Result of Laboratory Analysis: 850D.S. Ne 851Negi 852INA Examiner-. 85309. 854Mapari. \\n\\n855EASL Verna 856PW1O 857 \\n\\nPage 48 \\n\\n16. Brief fact of the case (Add separate sheet, if necessary): 858MAY IT PLEASE YOUR \\n\\nHONOUR 859In the limits of Your Hon\\'ble Court and within the Jurisdiction of Anjuna \\n860Police Station, that on 18/12/2019 at around 02.00 hrs at Room No. B2-104 at<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/output2/ilovepdf_merged_20.txt...vLLM STDOUT: INFO 12-14 05:16:26 [engine.py:317] Added request chatcmpl-3741280202eb410384585767c0058869.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_20.txt...vLLM STDOUT: INFO:     127.0.0.1:53128 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 42 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_20_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_20_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_20.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_20_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:52590 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:52596 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:16:44 [logger.py:43] Received request chatcmpl-fac2950a04ee44879c169b6232c03132: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nif necessary): 858MAY IT PLEASE YOUR \\n\\nHONOUR 859In the limits of Your Hon'ble Court and within the Jurisdiction of Anjuna \\n860Police Station, that on 18/12/2019 at around 02.00 hrs at Room No. B2-104 at 861Mello \\nRosa Hotel, Mainathbhati, Arpora, Bardez Goa, accused person mentioned 862in Column \\nno.11 at Sr. No.A-1 who is the employee of the complainant, 863wrongfully confined her in \\nthe room, threatened her with dire consequences to 864kill and had sexual intercourse \\nwith her without her consent and attempted to 865kill her by pressing pillow over her face. \\n866Thus the accused person committed an offence punishable U/s 342, 506(ii), 867376, 307 \\nIPC. 868Hence the charge. 869 \\n\\n17. Refer Notice served 870Yes/No 871Date: /02/2020. 872 (Acknowledgement to be placed) 873 \\n\\n18. Dispatched on: 874/02/2020. 875Forwarded by station house 876Officer/officer in-charge \\n\\n877Name: Suraj H.Gawas. 878Rank: P.I.Anjuna P.S. 879No.==== 880Signature of the \\nInvestigating 881Officer submitting the final 882Report/Charge sheet 883Name: Amir Y. Taral. \\n884 Rank: PSI Anjuna P.S. No. ==== 885Note: 886NOTE: 887 \\n\\n19. The Original charge sheet along with Original case papers is submitted to the Hon'ble \\n\\nJMFC Court, Mapusa, Goa. 888 \\n\\n20. The duplicate case paper along with duplicate charge sheet is sent to APP Mapusa with \\n\\nrequest to conduct prosecution at the time of trial. 889 \\n\\n \\n \\n \\n \\n \\n \\n \\n\\x0c21. A copy of charge sheet along with the set of case paper is sent herewith for the purpose \\n\\nof accused. 890 \\n\\n22. Summons for the prosecution with here may be sent through this P.S. 891 \\n\\n23. More evidence will be adduced if necessary with the permission of the court. 892The \\n\\nexhibits attached under Scene panchanama and the exhibits collected by the medical \\nofficers of both the accused and victim are sent for CDFD, Hyderabad and CFSL, \\nHyderabad for examination and reports are awaited. 893 \\n\\n \\n \\n \\n \\n\\x0cBased on the provided document, here is the extracted text: \\n\\n--- PAGE 1 --- \\n\\n[Stamp of Anjuna Police Station, Anjuna Goa] \\n292 1 CONO. 23/3/23/A 2costory 3maim 4ANJUN 5POLICE STAT 6N 7ANJUNA GOA 8Police \\nInspector Anjuna Police Station 9Outward No:-6243 10Date: 25/09/23 11FINAL FORM/REPORT \\n12 (Under Section 173 Cr. P. –°.) 13IN THE COURT OF HON'BL JUDICIAL MAGISTRATE 14FIRST \\nCLASS AT MAPUSA GOA. 15 1 Dist-North P.S.-Anjuna Year. 2023 FIR No. 119/2023 16 Date. \\n01/08/2023. 172 Charge Sheet No. $1=3/2023$ 3.Date 109/2023 18A 19 Scanned with OKEN \\nScanner \\n--- PAGE 2 --- \\n\\n4.  (i) Act: I.P.C. Section:-376 IPC. 20 (ii) Act: 21Section: 22 (!!!) Act 23Section: 24 (iv)Other Acts & \\nSections: ----- 25 5. Type of Final/Report: Charge Sheet 26(Not Charge sheeted for want \\nof Evidence /FIR 27True, undetected/ FIR True, Untraced/FIR True, 28Offence Abated/FIR \\nUnoccurred. 29 (Tick' applicable portion) 30 6. If FIR Unoccurred: False /Mistake of \\nFact/Mistake 31of law/Non Cognizable/C<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:16:44 [engine.py:317] Added request chatcmpl-fac2950a04ee44879c169b6232c03132.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_21.txt...vLLM STDOUT: INFO:     127.0.0.1:52602 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:16:49 [logger.py:43] Received request chatcmpl-6566d335e600481283725ab47636e811: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n if necessary): 858MAY IT PLEASE YOUR \\n\\nHONOUR 859In the limits of Your Hon\\'ble Court and within the Jurisdiction of Anjuna \\n860Police Station, that on 18/12/2019 at around 02.00 hrs at Room No. B2-104 at 861Mello \\nRosa Hotel, Mainathbhati, Arpora, Bardez Goa, accused person mentioned 862in Column \\nno.11 at Sr. No.A-1 who is the employee of the complainant, 863wrongfully confined her in \\nthe room, threatened her with dire consequences to 864kill and had sexual intercourse \\nwith her without her consent and attempted to 865kill her by pressing pillow over her face. \\n866Thus the accused person committed an offence punishable U/s 342, 506(ii), 867376, 307 \\nIPC. 868Hence the charge. 869 \\n\\n17. Refer Notice served 870Yes/No 871Date: /02/2020. 872 (Acknowledgement to be placed) 873 \\n\\n18. Dispatched on: 874/02/2020. 875Forwarded by station house 876Officer/officer in-charge<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:16:49 [engine.py:317] Added request chatcmpl-6566d335e600481283725ab47636e811.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_21.txt...vLLM STDOUT: INFO:     127.0.0.1:40990 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:17:05 [logger.py:43] Received request chatcmpl-44b97bd2da91447fa7bbb89299357c93: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n872 (Acknowledgement to be placed) 873 \\n\\n18. Dispatched on: 874/02/2020. 875Forwarded by station house 876Officer/officer in-charge \\n\\n877Name: Suraj H.Gawas. 878Rank: P.I.Anjuna P.S. 879No.==== 880Signature of the \\nInvestigating 881Officer submitting the final 882Report/Charge sheet 883Name: Amir Y. Taral. \\n884 Rank: PSI Anjuna P.S. No. ==== 885Note: 886NOTE: 887 \\n\\n19. The Original charge sheet along with Original case papers is submitted to the Hon\\'ble \\n\\nJMFC Court, Mapusa, Goa. 888 \\n\\n20. The duplicate case paper along with duplicate charge sheet is sent to APP Mapusa with \\n\\nrequest to conduct prosecution at the time of trial. 889 \\n\\n \\n \\n \\n \\n \\n \\n \\n\\x0c21. A copy of charge sheet along with the set of case paper is sent herewith for the purpose \\n\\nof accused. 890 \\n\\n22. Summons for the prosecution with here may be sent through this P.S. 891 \\n\\n23. More evidence will be adduced if necessary with the permission of the court. 892The<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:17:05 [engine.py:317] Added request chatcmpl-44b97bd2da91447fa7bbb89299357c93.\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_21.txt...vLLM STDOUT: INFO:     127.0.0.1:59988 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:17:20 [logger.py:43] Received request chatcmpl-8ec95674e78c4fc8bcf15af37905e98c: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n891 \\n\\n23. More evidence will be adduced if necessary with the permission of the court. 892The \\n\\nexhibits attached under Scene panchanama and the exhibits collected by the medical \\nofficers of both the accused and victim are sent for CDFD, Hyderabad and CFSL, \\nHyderabad for examination and reports are awaited. 893 \\n\\n \\n \\n \\n \\n\\x0cBased on the provided document, here is the extracted text: \\n\\n--- PAGE 1 --- \\n\\n[Stamp of Anjuna Police Station, Anjuna Goa] \\n292 1 CONO. 23/3/23/A 2costory 3maim 4ANJUN 5POLICE STAT 6N 7ANJUNA GOA 8Police \\nInspector Anjuna Police Station 9Outward No:-6243 10Date: 25/09/23 11FINAL FORM/REPORT \\n12 (Under Section 173 Cr. P. –°.) 13IN THE COURT OF HON\\'BL JUDICIAL MAGISTRATE 14FIRST \\nCLASS AT MAPUSA GOA. 15 1 Dist-North P.S.-Anjuna Year. 2023 FIR No. 119/2023 16 Date. \\n01/08/2023. 172 Charge Sheet No. $1=3/2023$ 3.Date 109/2023 18A 19 Scanned with OKEN \\nScanner \\n--- PAGE 2 ---<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:17:20 [engine.py:317] Added request chatcmpl-8ec95674e78c4fc8bcf15af37905e98c.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_21.txt...vLLM STDOUT: INFO:     127.0.0.1:48272 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:17:36 [logger.py:43] Received request chatcmpl-a6a2aa4d96bf443593bb6e999e957c9b: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n01/08/2023. 172 Charge Sheet No. $1=3/2023$ 3.Date 109/2023 18A 19 Scanned with OKEN \\nScanner \\n--- PAGE 2 --- \\n\\n4.  (i) Act: I.P.C. Section:-376 IPC. 20 (ii) Act: 21Section: 22 (!!!) Act 23Section: 24 (iv)Other Acts & \\nSections: ----- 25 5. Type of Final/Report: Charge Sheet 26(Not Charge sheeted for want \\nof Evidence /FIR 27True, undetected/ FIR True, Untraced/FIR True, 28Offence Abated/FIR \\nUnoccurred. 29 (Tick\\' applicable portion) 30 6. If FIR Unoccurred: False /Mistake of \\nFact/Mistake 31of law/Non Cognizable/C<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:17:36 [engine.py:317] Added request chatcmpl-a6a2aa4d96bf443593bb6e999e957c9b.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_21.txt...vLLM STDOUT: INFO:     127.0.0.1:38754 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 57 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_21_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_21_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_21.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_21_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:58148 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:58160 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:17:54 [logger.py:43] Received request chatcmpl-9cee0e64c5a8410e91da16934dcfe031: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n/ FIR True, Untraced/FIR True, 28Offence Abated/FIR \\nUnoccurred. 29 (Tick\\' applicable portion) 30 6. If FIR Unoccurred: False /Mistake of \\nFact/Mistake 31of law/Non Cognizable/Civil in Nature. 32 (tick\\' applicable portion). 33 7. If \\nCharge sheet: Original / Supplementary. 34 (tick\\' applicable portion). 35 8. Name of 1.O. \\nMiss. Sneha S. Sawai, LPSI 36attached to Anjuna Police Station (at the time of 37 (\\'harge \\nsheet) 38Scanned with OKEN Scanner 39 \\n\\n--- PAGE 3 --- \\n\\n(a) Name of complainant/informant: Miss Marv 40Fernandes, age 18 years, Occ-employed r/o \\nH. No 309, Nerul, Bhati Waddo, Bardez, Goa. 41 (b) Father\\'s Husband\\'s name: Shri. Benito \\nFernandes. 42 10. Details of properties /Articles/Documents recovered / seized during \\nInvestigation and relied upon (separate list can 43be attached, if necessary). 44 \\n\\nSr. N o \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\nP.S. \\nProperty \\nReg. No. \\n\\nDisposal \\n\\nFrom \\nwhom \\n/where \\nrecovered \\nor seized \\n\\n1 \\n\\n1. \\n\\n2 \\n\\n3 \\n\\n4 \\n\\n5 \\n\\n6 \\n\\nAttached \\n\\nseparate \\nsheet \\n\\n \\n \\n \\n \\n \\n\\x0cScanned with OKEN Scanner 45 \\n\\n--- PAGE 4 --- \\n\\n10. Details of properties/Articles/Documents Recovered/ 46Seized during investigation and \\n\\nRelied upon. 47 \\n\\nFrom \\nwhom/ \\nWhere \\nrecovered \\nor seized \\n\\nAttached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\n/23 of \\nscene \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\nby LPSI \\nSneha S. \\nSawal. \\n\\nDisposal \\n\\nBeing sent \\nat Central \\nForensic \\nScience \\nLaboratory \\nKharadi \\nPune, \\nMaharashtr\\na for \\nexaminatio\\nn and \\nreport. \\n\\nSI. No. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\n01 \\n\\n300/- \\n\\nThis \\ngreenish \\ncolour cloth \\nline sealed \\nenvelope \\ncontains in \\nit one \\nmulticolor \\nbed sheet \\nof blue, \\nwhite \\nmaroon \\ncolour & \\nduly \\nattached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\nconcerned \\nin Anjuna \\nPS Cr No. \\n119/2023 \\nu/s 376 IPC \\nand marked \\n\\n \\n \\n\\x0cas \\n\"Exhibit-1\". \\n\\nScanned with OKEN Scanner 48 \\n\\n--- PAGE 5 --- \\n\\nSI. No. \\n\\n2. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\n400/- \\n\\nThis \\ngreenish \\ncolour cloth \\nline sealed \\nenvelope \\ncontains in \\nit one red \\ncolour \\nshort \\nsleeves \\nt-shirt duly \\nattached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n119/2023 \\nu/s 376 IPC \\nand marked \\nas \\n\"Exhibit-2\". \\n\\nFrom \\nwhom/ \\nWhere \\nrecovered \\nor seized \\n\\nAttached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\n/23 under \\nthe scene \\nof offence \\npanchanam\\na dated- \\n01/08/2023 \\nby LPSI \\nSneha S. \\nSawal. \\n\\nDisposal \\n\\nBeing sent \\nat Central \\nForensic \\nScience \\nLaboratory \\nKharadi \\nPune, \\nMaharashtr<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:17:54 [engine.py:317] Added request chatcmpl-9cee0e64c5a8410e91da16934dcfe031.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_22.txt...vLLM STDOUT: INFO:     127.0.0.1:58168 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:17:58 [logger.py:43] Received request chatcmpl-b3544ee7838d414f8add1a23de13d5e0: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n/ FIR True, Untraced/FIR True, 28Offence Abated/FIR \\nUnoccurred. 29 (Tick\\' applicable portion) 30 6. If FIR Unoccurred: False /Mistake of \\nFact/Mistake 31of law/Non Cognizable/Civil in Nature. 32 (tick\\' applicable portion). 33 7. If \\nCharge sheet: Original / Supplementary. 34 (tick\\' applicable portion). 35 8. Name of 1.O. \\nMiss. Sneha S. Sawai, LPSI 36attached to Anjuna Police Station (at the time of 37 (\\'harge \\nsheet) 38Scanned with OKEN Scanner 39 \\n\\n--- PAGE 3 --- \\n\\n(a) Name of complainant/informant: Miss Marv 40Fernandes, age 18 years, Occ-employed r/o \\nH. No 309, Nerul, Bhati Waddo, Bardez, Goa. 41 (b) Father\\'s Husband\\'s name: Shri. Benito \\nFernandes. 42 10. Details of properties /Articles/Documents recovered / seized during \\nInvestigation and relied upon (separate list can 43be attached, if necessary). 44 \\n\\nSr. N o \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\nP.S. \\nProperty \\nReg. No. \\n\\nDisposal \\n\\nFrom \\nwhom \\n/where \\nrecovered \\nor seized \\n\\n1 \\n\\n1. \\n\\n2 \\n\\n3 \\n\\n4 \\n\\n5 \\n\\n6 \\n\\nAttached \\n\\nseparate \\nsheet<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:17:58 [engine.py:317] Added request chatcmpl-b3544ee7838d414f8add1a23de13d5e0.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_22.txt...vLLM STDOUT: INFO:     127.0.0.1:34922 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:18:13 [logger.py:43] Received request chatcmpl-e6fc9ea7262848388f2046732213304f: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nNo. \\n\\nDisposal \\n\\nFrom \\nwhom \\n/where \\nrecovered \\nor seized \\n\\n1 \\n\\n1. \\n\\n2 \\n\\n3 \\n\\n4 \\n\\n5 \\n\\n6 \\n\\nAttached \\n\\nseparate \\nsheet \\n\\n \\n \\n \\n \\n \\n\\x0cScanned with OKEN Scanner 45 \\n\\n--- PAGE 4 --- \\n\\n10. Details of properties/Articles/Documents Recovered/ 46Seized during investigation and \\n\\nRelied upon. 47 \\n\\nFrom \\nwhom/ \\nWhere \\nrecovered \\nor seized \\n\\nAttached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\n/23 of \\nscene \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\nby LPSI \\nSneha S. \\nSawal. \\n\\nDisposal \\n\\nBeing sent \\nat Central \\nForensic \\nScience \\nLaboratory \\nKharadi \\nPune, \\nMaharashtr\\na for \\nexaminatio\\nn and \\nreport. \\n\\nSI. No. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\n01 \\n\\n300/- \\n\\nThis \\ngreenish \\ncolour cloth \\nline sealed \\nenvelope \\ncontains in \\nit one \\nmulticolor \\nbed sheet \\nof blue, \\nwhite \\nmaroon \\ncolour & \\nduly \\nattached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\nconcerned \\nin Anjuna \\nPS Cr No. \\n119/2023 \\nu/s 376 IPC \\nand marked \\n\\n \\n \\n\\x0cas \\n\"Exhibit-1\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_22.txt...vLLM STDOUT: INFO 12-14 05:18:13 [engine.py:317] Added request chatcmpl-e6fc9ea7262848388f2046732213304f.\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/output2/ilovepdf_merged_22.txt...vLLM STDOUT: INFO:     127.0.0.1:56932 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:18:29 [logger.py:43] Received request chatcmpl-322c940e48ae4b098c41ef64e49573c0: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\n01 \\n\\n300/- \\n\\nThis \\ngreenish \\ncolour cloth \\nline sealed \\nenvelope \\ncontains in \\nit one \\nmulticolor \\nbed sheet \\nof blue, \\nwhite \\nmaroon \\ncolour & \\nduly \\nattached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\nconcerned \\nin Anjuna \\nPS Cr No. \\n119/2023 \\nu/s 376 IPC \\nand marked \\n\\n \\n \\n\\x0cas \\n\"Exhibit-1\". \\n\\nScanned with OKEN Scanner 48 \\n\\n--- PAGE 5 --- \\n\\nSI. No. \\n\\n2. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\n400/- \\n\\nThis \\ngreenish \\ncolour cloth \\nline sealed \\nenvelope \\ncontains in \\nit one red \\ncolour \\nshort \\nsleeves \\nt-shirt duly \\nattached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n119/2023 \\nu/s 376 IPC \\nand marked \\nas \\n\"Exhibit-2\". \\n\\nFrom \\nwhom/ \\nWhere \\nrecovered \\nor seized \\n\\nAttached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\n/23 under \\nthe scene \\nof offence \\npanchanam\\na dated- \\n01/08/2023 \\nby LPSI \\nSneha S. \\nSawal. \\n\\nDisposal<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:18:29 [engine.py:317] Added request chatcmpl-322c940e48ae4b098c41ef64e49573c0.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_22.txt...vLLM STDOUT: INFO:     127.0.0.1:52326 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:18:44 [logger.py:43] Received request chatcmpl-6929b86b6c6a42aa9742a4518992d25f: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n\\n/23 under \\nthe scene \\nof offence \\npanchanam\\na dated- \\n01/08/2023 \\nby LPSI \\nSneha S. \\nSawal. \\n\\nDisposal \\n\\nBeing sent \\nat Central \\nForensic \\nScience \\nLaboratory \\nKharadi \\nPune, \\nMaharashtr<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:18:44 [engine.py:317] Added request chatcmpl-6929b86b6c6a42aa9742a4518992d25f.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_22.txt...vLLM STDOUT: INFO:     127.0.0.1:59034 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 64 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_22_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_22_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_22.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_22_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:53314 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:53324 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:19:02 [logger.py:43] Received request chatcmpl-02eee3c8ac2c4565a12d7bb54ef7146a: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nof offence \\npanchanam\\na dated- \\n01/08/2023 \\nby LPSI \\nSneha S. \\nSawal. \\n\\nDisposal \\n\\nBeing sent \\nat Central \\nForensic \\nScience \\nLaboratory \\nKharadi \\nPune, \\nMaharashtr\\na for \\nexaminatio\\nn and \\nreport. \\n\\n \\n\\x0c500/- \\n\\nAttached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\n\\n/23 under \\nthe scene \\nof offence \\npanchanam\\na dated- \\n01/08/2023 \\nby LPSI \\nSneha S. \\nSawal. \\n\\nBeing sent \\nat Central \\nForensic \\nScience \\nLaboratory \\nKharadi \\nPune, \\nMaharashtr\\na for \\nexaminatio\\nn and \\nreport. \\n\\n03. \\n\\nThis \\ngreenish \\ncolour cloth \\nline sealed \\nenvelope \\ncontains in \\nit one blue \\ncolour long \\njeans pant \\nhaving \\nholes at \\nnear thigh \\nand knee \\nregion duly \\nattached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n119/2023 \\nu/s 376 IPC \\nand marked \\nas \\n\"Exhibit-3\". \\n\\ne k i t Scanned with OKEN Scanner 49 \\n\\n--- PAGE 6 --- \\n\\n1 50 \\n\\nSI. No. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\nP.S. \\nProperty \\nRegister \\n\\nFrom \\nwhom/ \\nWhere \\n\\nDisposal \\n\\n \\n \\n\\x0c300/- \\n\\nrecovered \\nor seized \\n\\nAttached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\n\\nNo. \\n\\n/23 under \\nthe scene \\nof offence \\npanchanam\\na dated- \\n01/08/2023 \\nby LPSI \\nSneha S. \\nSawal. \\n\\nBeing sent \\nat Central \\nForensic \\nScience \\nLaboratory \\nKharadi \\nPune, \\nMaharashtr\\na for \\nexaminatio\\nn and \\nreport. \\n\\n04. \\n\\nThis \\ngreenish \\ncolour cloth \\nline sealed \\nenvelope \\ncontains in \\nit one grey \\ncolour bra \\nof make \\n\"Peans \\nLingerie \\nduly \\nattached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n119/2023 \\nu/s 376 IPC \\nand marked \\nas \\n\"Exhibit-4\". \\n\\nScanned with OKEN Scanner 51 \\n\\n--- PAGE 7 --- \\n\\nSI. No. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\nFrom \\nwhom/ \\nWhere \\nrecovered \\n\\nDisposal \\n\\n \\n\\x0c200/- \\n\\nor seized \\n\\nAttached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\n\\n/23 under \\nthe scene \\nof offence \\npanchanam\\na dated- \\n01/08/2023 \\nby LPSI \\nSneha S. \\nSawal. \\n\\nBeing sent \\nat Central \\nForensic \\nScience \\nLaboratory \\nKharadi \\nPune, \\nMaharashtr\\na for \\nexaminatio\\nn and \\nreport. \\n\\n05. \\n\\nThis \\ngreenish \\ncolour cloth \\nline sealed \\nenvelope \\ncontains in \\nit one blue \\ncolour \\npenty/unde\\nrwear \\ndark/brown \\nhaving \\nstains on it \\nduly \\nattached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n119/2023 \\nu/s 376 IPC \\nand marked \\nas \\n\"Exhibit-5\". \\n\\ne k i. 52 t 1 531 54Scanned with OKEN Scanner 55 \\n\\n--- PAGE 8 --- \\n\\nSI. No<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:19:02 [engine.py:317] Added request chatcmpl-02eee3c8ac2c4565a12d7bb54ef7146a.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_23.txt...vLLM STDOUT: INFO:     127.0.0.1:53336 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:19:07 [logger.py:43] Received request chatcmpl-9ce238ca94d54c45a323aaf82c365f09: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n \\nof offence \\npanchanam\\na dated- \\n01/08/2023 \\nby LPSI \\nSneha S. \\nSawal. \\n\\nDisposal \\n\\nBeing sent \\nat Central \\nForensic \\nScience \\nLaboratory \\nKharadi \\nPune, \\nMaharashtr\\na for \\nexaminatio\\nn and \\nreport. \\n\\n \\n\\x0c500/- \\n\\nAttached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\n\\n/23 under \\nthe scene \\nof offence \\npanchanam\\na dated- \\n01/08/2023 \\nby LPSI \\nSneha S. \\nSawal. \\n\\nBeing sent \\nat Central \\nForensic \\nScience \\nLaboratory \\nKharadi \\nPune, \\nMaharashtr\\na for \\nexaminatio\\nn and \\nreport. \\n\\n03. \\n\\nThis \\ngreenish \\ncolour cloth \\nline sealed \\nenvelope \\ncontains in \\nit one blue \\ncolour long \\njeans pant \\nhaving \\nholes at \\nnear thigh \\nand knee \\nregion duly \\nattached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n119/2023 \\nu/s 376 IPC \\nand marked \\nas \\n\"Exhibit-3\". \\n\\ne k i t Scanned with OKEN Scanner 49 \\n\\n--- PAGE 6 --- \\n\\n1 50 \\n\\nSI. No. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\nP.S. \\nProperty \\nRegister \\n\\nFrom \\nwhom/ \\nWhere \\n\\nDisposal \\n\\n \\n \\n\\x0c300/-<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:19:07 [engine.py:317] Added request chatcmpl-9ce238ca94d54c45a323aaf82c365f09.\n",
            "\u001b[2KProcessing 3 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_23.txt...vLLM STDOUT: INFO:     127.0.0.1:35260 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:19:23 [logger.py:43] Received request chatcmpl-5125586e9c964993bc7a57504263ac97: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nNo. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\nP.S. \\nProperty \\nRegister \\n\\nFrom \\nwhom/ \\nWhere \\n\\nDisposal \\n\\n \\n \\n\\x0c300/- \\n\\nrecovered \\nor seized \\n\\nAttached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\n\\nNo. \\n\\n/23 under \\nthe scene \\nof offence \\npanchanam\\na dated- \\n01/08/2023 \\nby LPSI \\nSneha S. \\nSawal. \\n\\nBeing sent \\nat Central \\nForensic \\nScience \\nLaboratory \\nKharadi \\nPune, \\nMaharashtr\\na for \\nexaminatio\\nn and \\nreport. \\n\\n04. \\n\\nThis \\ngreenish \\ncolour cloth \\nline sealed \\nenvelope \\ncontains in \\nit one grey \\ncolour bra \\nof make \\n\"Peans \\nLingerie \\nduly \\nattached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n119/2023 \\nu/s 376 IPC \\nand marked \\nas \\n\"Exhibit-4\". \\n\\nScanned with OKEN Scanner 51 \\n\\n--- PAGE 7 --- \\n\\nSI. No. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\nFrom \\nwhom/ \\nWhere \\nrecovered \\n\\nDisposal \\n\\n \\n\\x0c200/- \\n\\nor seized \\n\\nAttached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:19:23 [engine.py:317] Added request chatcmpl-5125586e9c964993bc7a57504263ac97.\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_23.txt...vLLM STDOUT: INFO:     127.0.0.1:43404 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:19:38 [logger.py:43] Received request chatcmpl-99455c37b14e43289b8d84daf4d1ef96: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\nFrom \\nwhom/ \\nWhere \\nrecovered \\n\\nDisposal \\n\\n \\n\\x0c200/- \\n\\nor seized \\n\\nAttached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\n\\n/23 under \\nthe scene \\nof offence \\npanchanam\\na dated- \\n01/08/2023 \\nby LPSI \\nSneha S. \\nSawal. \\n\\nBeing sent \\nat Central \\nForensic \\nScience \\nLaboratory \\nKharadi \\nPune, \\nMaharashtr\\na for \\nexaminatio\\nn and \\nreport. \\n\\n05. \\n\\nThis \\ngreenish \\ncolour cloth \\nline sealed \\nenvelope \\ncontains in \\nit one blue \\ncolour \\npenty/unde\\nrwear \\ndark/brown \\nhaving \\nstains on it \\nduly \\nattached \\nunder the \\nscene of \\noffence \\npanchanam\\na dated- \\n01/08/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n119/2023 \\nu/s 376 IPC \\nand marked \\nas \\n\"Exhibit-5\". \\n\\ne k i. 52 t 1 531 54Scanned with OKEN Scanner 55 \\n\\n--- PAGE 8 --- \\n\\nSI. No<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:19:38 [engine.py:317] Added request chatcmpl-99455c37b14e43289b8d84daf4d1ef96.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_23.txt...vLLM STDOUT: INFO:     127.0.0.1:59972 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 49 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_23_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_23_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_23.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_23_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:35764 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:35780 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:19:56 [logger.py:43] Received request chatcmpl-251cf43853b34682993a832bbdf583b3: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nuna \\nP.S. Cr. No. \\n119/2023 \\nu/s 376 IPC \\nand marked \\nas \\n\"Exhibit-5\". \\n\\ne k i. 52 t 1 531 54Scanned with OKEN Scanner 55 \\n\\n--- PAGE 8 --- \\n\\nSI. No. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\nP.S. \\nProperty \\nRegister \\n\\nDisposal \\n\\nFrom \\nwhom/ \\nWhere \\nrecovered \\n\\n \\n\\x0cNo. \\n\\n/23 \\n\\n250/- \\n\\nor seized \\n\\nAttached \\nunder \\nvehicle \\nattachment \\npanchanam\\na dated \\n04/08/2023 \\nby LPSI \\nSneha S. \\nSawal of \\nAnjuna P.S. \\n\\nReleased \\nby JMFC \\n\"D\" court \\nMapusa \\nvide order \\nNo. \\nJMFC/M \\nAP/Rel/20 \\n23/8373 \\ndated \\n29/08/2023. \\n\\n06 \\n\\nThis \\nOrange \\ncolour TVS \\nJupitor \\nscooter \\nhaving \\nregistration \\nnumber \\nplates as \\nGA-03-AS-\\n3035 \\nattached \\nunder \\nvehicle \\nattachment \\npanchanam\\na dated \\n04/08/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n119/2023 \\nu/s 376 IPC \\nand marked \\nas \\n\"Exhibit-A\". \\n\\nScanned with OKEN Scanner 56 \\n\\n--- PAGE 9 --- \\n\\n11. Particulars of accused persons Charge-sheeted 57Use Separate sheet for each accused). \\n\\n58St No A-1 59( Name: Mr. Afzal Khan @ Albaz Khan 60Whether verified: Yes. 61 (11) \\nFather\\'s/Husband\\'s name: Mr. Noor Ahmed 62Khan 63 (iii) Date/Year of birth: 21 vears. 64 \\n(iv) Sex: Male. 65 (v) Nationality: Indian. 66he 67 (vi) Passport No. 68, Date of issue. 69ck 705. \\n71Place of issue. 72 (vii) Religion: Muslim. 73 (viii) Whether SC/ST/OBC- 74 (ix) Occupation:- \\nDriver 75 (x) Address:- At present Camurlim, Bardez Goa 76r/o C-10-38-1, Salmo wado, \\nNear Church, 77Saligao, Bardez Goa, n/o Haveri, Karnataka. 78 Whether verified. Yes 79 ( ) \\n\\n \\n\\x0cProvisional criminal No: A-1. 80 (Nit) Regular criminal No. (if known). -- 81 (xiii) Date of \\narrest: Arrested on 01.08.2023 at 82Scanned with OKEN Scanner 83 \\n\\n--- PAGE 10 --- \\n\\n14.21 hrs. 84 (Nix) Date of release on bail: -------- 85 (NV) Date on which forwarded to \\nCourt.---.. 86 (xvi) Under Acts & Sections: U/s 376 IPC. 87 (xvii) Details of Bailers/Sureties: -- 88 \\n(xviii) Previous c 89onviction with case reference.- 90 (xix) Status of the accused: In Judicial \\nCustody. 91Forwarded Beiled by Police/Bailed by Court/Police 92Custody/Judicial \\nCustody/Absconding /Proclaimed 93 offender. (tick \\'\\' applicable portion). 94 12. Particulars of \\naccused persons not Charge sheeted: 95NIL 96 (Use separate sheet for each suspect). 97 Sl. \\nNo: NIL. 98 (i)Name:--- 99Whether verified: 100Father\\'s/lusband\\'s name: 101 (in) Date/Year of \\nbirth: 102TIN) Sex 103Scanned with OKEN Scanner 104 \\n\\n--- PAGE 11 --- \\n\\n(v) Nationality: -- 105 (vi) Passport No:- Date of issue-... Place of 106issue...-- 107 (vii)Religion 108 \\n(viii) Whether SC/ST/OBC......- 109 (<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:19:56 [engine.py:317] Added request chatcmpl-251cf43853b34682993a832bbdf583b3.\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_24.txt...vLLM STDOUT: INFO:     127.0.0.1:35790 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:20:00 [logger.py:43] Received request chatcmpl-0c61dc3636cd4a2e90c8944d85bc0687: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nuna \\nP.S. Cr. No. \\n119/2023 \\nu/s 376 IPC \\nand marked \\nas \\n\"Exhibit-5\". \\n\\ne k i. 52 t 1 531 54Scanned with OKEN Scanner 55 \\n\\n--- PAGE 8 --- \\n\\nSI. No. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\nP.S. \\nProperty \\nRegister \\n\\nDisposal \\n\\nFrom \\nwhom/ \\nWhere \\nrecovered \\n\\n \\n\\x0cNo. \\n\\n/23 \\n\\n250/- \\n\\nor seized \\n\\nAttached \\nunder \\nvehicle \\nattachment \\npanchanam\\na dated \\n04/08/2023 \\nby LPSI \\nSneha S. \\nSawal of \\nAnjuna P.S. \\n\\nReleased \\nby JMFC \\n\"D\" court \\nMapusa \\nvide order \\nNo. \\nJMFC/M \\nAP/Rel/20 \\n23/8373 \\ndated \\n29/08/2023. \\n\\n06 \\n\\nThis \\nOrange \\ncolour TVS \\nJupitor \\nscooter \\nhaving \\nregistration \\nnumber \\nplates as \\nGA-03-AS-\\n3035 \\nattached \\nunder \\nvehicle \\nattachment \\npanchanam\\na dated \\n04/08/2023 \\nconcerned \\nin Anjuna \\nP.S. Cr. No. \\n119/2023 \\nu/s 376 IPC \\nand marked \\nas \\n\"Exhibit-A\". \\n\\nScanned with OKEN Scanner 56 \\n\\n--- PAGE 9 --- \\n\\n11. Particulars of accused persons Charge-sheeted 57Use Separate sheet for each accused).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:20:00 [engine.py:317] Added request chatcmpl-0c61dc3636cd4a2e90c8944d85bc0687.\n",
            "\u001b[2KProcessing 3 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_24.txt...vLLM STDOUT: INFO:     127.0.0.1:39970 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:20:16 [logger.py:43] Received request chatcmpl-3200a88578834712ae5f80bb66f8b44c: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n\\nScanned with OKEN Scanner 56 \\n\\n--- PAGE 9 --- \\n\\n11. Particulars of accused persons Charge-sheeted 57Use Separate sheet for each accused). \\n\\n58St No A-1 59( Name: Mr. Afzal Khan @ Albaz Khan 60Whether verified: Yes. 61 (11) \\nFather\\'s/Husband\\'s name: Mr. Noor Ahmed 62Khan 63 (iii) Date/Year of birth: 21 vears. 64 \\n(iv) Sex: Male. 65 (v) Nationality: Indian. 66he 67 (vi) Passport No. 68, Date of issue. 69ck 705. \\n71Place of issue. 72 (vii) Religion: Muslim. 73 (viii) Whether SC/ST/OBC- 74 (ix) Occupation:- \\nDriver 75 (x) Address:- At present Camurlim, Bardez Goa 76r/o C-10-38-1, Salmo wado, \\nNear Church, 77Saligao, Bardez Goa, n/o Haveri, Karnataka. 78 Whether verified. Yes 79 ( ) \\n\\n \\n\\x0cProvisional criminal No: A-1. 80 (Nit) Regular criminal No. (if known). -- 81 (xiii) Date of \\narrest: Arrested on 01.08.2023 at 82Scanned with OKEN Scanner 83 \\n\\n--- PAGE 10 ---<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_24.txt...vLLM STDOUT: INFO 12-14 05:20:16 [engine.py:317] Added request chatcmpl-3200a88578834712ae5f80bb66f8b44c.\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_24.txt...vLLM STDOUT: INFO:     127.0.0.1:57396 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_24.txt...vLLM STDOUT: INFO 12-14 05:20:31 [logger.py:43] Received request chatcmpl-e902b49f17b946a49337f5c674f19d91: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n80 (Nit) Regular criminal No. (if known). -- 81 (xiii) Date of \\narrest: Arrested on 01.08.2023 at 82Scanned with OKEN Scanner 83 \\n\\n--- PAGE 10 --- \\n\\n14.21 hrs. 84 (Nix) Date of release on bail: -------- 85 (NV) Date on which forwarded to \\nCourt.---.. 86 (xvi) Under Acts & Sections: U/s 376 IPC. 87 (xvii) Details of Bailers/Sureties: -- 88 \\n(xviii) Previous c 89onviction with case reference.- 90 (xix) Status of the accused: In Judicial \\nCustody. 91Forwarded Beiled by Police/Bailed by Court/Police 92Custody/Judicial \\nCustody/Absconding /Proclaimed 93 offender. (tick \\'\\' applicable portion). 94 12. Particulars of \\naccused persons not Charge sheeted: 95NIL 96 (Use separate sheet for each suspect). 97 Sl. \\nNo: NIL. 98 (i)Name:--- 99Whether verified: 100Father\\'s/lusband\\'s name: 101 (in) Date/Year of \\nbirth: 102TIN) Sex 103Scanned with OKEN Scanner 104 \\n\\n--- PAGE 11 --- \\n\\n(v) Nationality: -- 105 (vi) Passport No:- Date of issue-... Place of 106issue...-- 107 (vii)Religion 108 \\n(viii) Whether SC/ST/OBC......- 109 (<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:20:31 [engine.py:317] Added request chatcmpl-e902b49f17b946a49337f5c674f19d91.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_24.txt...vLLM STDOUT: INFO:     127.0.0.1:34292 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 44 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_24_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_24_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_24.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_24_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:58698 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:58714 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:20:49 [logger.py:43] Received request chatcmpl-3441ef0295f54b8487bc56a56ad2bb44: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nwith OKEN Scanner 104 \\n\\n--- PAGE 11 --- \\n\\n(v) Nationality: -- 105 (vi) Passport No:- Date of issue-... Place of 106issue...-- 107 (vii)Religion 108 \\n(viii) Whether SC/ST/OBC......- 109 (ix) Occupation: 110 (x)Address......... Whether verified......... 111 \\n(xi) Provisional criminal No. 112 (xii) Suspicion Approved: Yes/No. 113 (xiii) Status of the accused \\n(suspect): 114Forwarded / Bailed by Police / Bailed by court / 115ne 116Police Custody / \\nAbsconding/ 117Without Arrest/ 118 k Proclaimed offender (tick'' applicable portion) 1195. 120 \\n(xiv) Under Acts & Sections:--- 121 (xv) Any special remarks including reasons for not 122‡∏ß \\n123Charge sheeting......-- 124 t 1 1251/06/ 12630 12715-12005 12816 129Scanned with OKEN Scanner \\n130 \\n\\n--- PAGE 12 --- \\n\\n13. Particulars of witnesses to be examined: 131 \\n\\nSr. No. \\n\\n1. \\n\\nOccupation \\n\\nType of evidence \\nto be rendered \\n\\nEmployed \\n\\nComplainant \\n\\nName, age, \\nfather's/Husband'\\ns name and \\naddress. \\n\\nMiss Mary D/o \\nBenito Fernandes, \\nage 18 years, r/o H. \\nNo 309, Nerul, \\n\\n \\n \\n \\n \\n\\x0c2. \\n\\n3. \\n\\n4. \\n\\nBhati, Waddo, \\nBardez, Goa. \\n\\nDr. Aseefa Ghouse, \\nMajor in age, GMC \\nReg. No. 3921, \\nMedical Officer, \\nDept of Obstetrics \\n& Gynecology, \\nGMC Bambolim. \\n\\nMiss Sania d/o \\nSuleman \\nPanchmaldar, age \\n17 years, r/o \\nJuichiry Arradi, \\nCandolim, Bardez \\nGoa. \\n\\nMiss Aloysia \\nAndrade, Major in \\nage, NGO, Victim \\nassistance Unit, \\nGMC Bambolim. \\n\\nService Govt. \\n\\nMedical witness \\n\\nUnemployed \\n\\nWitness \\n\\nNGO \\n\\nWitness \\n\\nScanned with OKEN Scanner 132 \\n\\n--- PAGE 13 --- \\n\\n5. 1337 134 \\n\\nSr. No. \\n\\n5. \\n\\nName, age, \\nfather's/Husband'\\ns name and \\naddress. \\n\\nMiss Vaibhavi \\nBorkar, Major in \\n\\nOccupation \\n\\nType of evidence \\nto be rendered \\n\\nNGO \\n\\nWitness \\n\\n \\n \\n\\x0c6. \\n\\n7. \\n\\n8. \\n\\n9. \\n\\nPvt. Job. \\n\\nPanch witness \\n\\nBusiness \\n\\nPanch witness \\n\\nPvt. Job \\n\\nPanch witness \\n\\nBusiness \\n\\nWitness \\n\\nage. NGO, Victim \\nassistance Unit. \\nGMC Bambolim \\n\\nShri. Sanjay Kumar \\nJena s/o Bisheswar \\nJena, age- 23 \\nyears, r/o Arpora, \\nBardez Goa, n/o \\nDunda, Mukulishi, \\nBasta, Baleshwar, \\nOdisha. \\n\\nShri. Harshvardhan \\ns/o Sandeep, age- \\n21 years, r/o \\nDevashri Garden. \\nSucorro, Porvorim, \\nBardez Goa. \\n9787277280 \\n\\nShri. Tusarkanta \\nDehury s/o \\nBrahmananda \\nDehury, age- 32 \\nyears, Occp- \\nPrivate Service, r/o \\nc/o Sandeep Baghi, \\nArpora, Bardez \\nGoa, no Muktapasi, \\nMahulpal, \\nDhenkanai, Odisha \\n\\nShri. Sandeep \\nBhagi s/o Yashpal \\nBaghi. age- 47 \\nyears, Occp- \\nBusiness, r/o \\nG-008, Devashri \\nGarden, near \\nCorporation Bank, \\n\\n\\x0cAlto Porvorim, \\nBardez Goa, \\n403521 \\n\\nG 135POLOC 136Scanned with OKEN Scanner 137 \\n\\n--- PAGE 14 --- \\n\\n10. Mr. Pr<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:20:49 [engine.py:317] Added request chatcmpl-3441ef0295f54b8487bc56a56ad2bb44.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_25.txt...vLLM STDOUT: INFO:     127.0.0.1:58716 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:20:53 [logger.py:43] Received request chatcmpl-0a6376b0565e4cbdb6b660778cec2510: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n with OKEN Scanner 104 \\n\\n--- PAGE 11 --- \\n\\n(v) Nationality: -- 105 (vi) Passport No:- Date of issue-... Place of 106issue...-- 107 (vii)Religion 108 \\n(viii) Whether SC/ST/OBC......- 109 (ix) Occupation: 110 (x)Address......... Whether verified......... 111 \\n(xi) Provisional criminal No. 112 (xii) Suspicion Approved: Yes/No. 113 (xiii) Status of the accused \\n(suspect): 114Forwarded / Bailed by Police / Bailed by court / 115ne 116Police Custody / \\nAbsconding/ 117Without Arrest/ 118 k Proclaimed offender (tick\\'\\' applicable portion) 1195. 120 \\n(xiv) Under Acts & Sections:--- 121 (xv) Any special remarks including reasons for not 122‡∏ß \\n123Charge sheeting......-- 124 t 1 1251/06/ 12630 12715-12005 12816 129Scanned with OKEN Scanner \\n130 \\n\\n--- PAGE 12 --- \\n\\n13. Particulars of witnesses to be examined: 131 \\n\\nSr. No. \\n\\n1. \\n\\nOccupation \\n\\nType of evidence \\nto be rendered \\n\\nEmployed \\n\\nComplainant \\n\\nName, age, \\nfather\\'s/Husband\\'\\ns name and \\naddress. \\n\\nMiss Mary D/o \\nBenito Fernandes, \\nage 18 years, r/o H. \\nNo 309, Nerul,<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:20:53 [engine.py:317] Added request chatcmpl-0a6376b0565e4cbdb6b660778cec2510.\n",
            "\u001b[2KProcessing 3 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_25.txt...vLLM STDOUT: INFO:     127.0.0.1:58730 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:21:08 [logger.py:43] Received request chatcmpl-6c8beec8f376437b81e21c8f6e54031e: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n\\nOccupation \\n\\nType of evidence \\nto be rendered \\n\\nEmployed \\n\\nComplainant \\n\\nName, age, \\nfather\\'s/Husband\\'\\ns name and \\naddress. \\n\\nMiss Mary D/o \\nBenito Fernandes, \\nage 18 years, r/o H. \\nNo 309, Nerul, \\n\\n \\n \\n \\n \\n\\x0c2. \\n\\n3. \\n\\n4. \\n\\nBhati, Waddo, \\nBardez, Goa. \\n\\nDr. Aseefa Ghouse, \\nMajor in age, GMC \\nReg. No. 3921, \\nMedical Officer, \\nDept of Obstetrics \\n& Gynecology, \\nGMC Bambolim. \\n\\nMiss Sania d/o \\nSuleman \\nPanchmaldar, age \\n17 years, r/o \\nJuichiry Arradi, \\nCandolim, Bardez \\nGoa. \\n\\nMiss Aloysia \\nAndrade, Major in \\nage, NGO, Victim \\nassistance Unit, \\nGMC Bambolim. \\n\\nService Govt. \\n\\nMedical witness \\n\\nUnemployed \\n\\nWitness \\n\\nNGO \\n\\nWitness \\n\\nScanned with OKEN Scanner 132 \\n\\n--- PAGE 13 --- \\n\\n5. 1337 134 \\n\\nSr. No. \\n\\n5. \\n\\nName, age, \\nfather\\'s/Husband\\'\\ns name and \\naddress. \\n\\nMiss Vaibhavi \\nBorkar, Major in \\n\\nOccupation \\n\\nType of evidence \\nto be rendered \\n\\nNGO \\n\\nWitness \\n\\n \\n \\n\\x0c6. \\n\\n7. \\n\\n8. \\n\\n9. \\n\\nPvt. Job. \\n\\nPanch witness \\n\\nBusiness \\n\\nPanch witness \\n\\nPvt. Job \\n\\nPanch witness \\n\\nBusiness \\n\\nWitness<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:21:08 [engine.py:317] Added request chatcmpl-6c8beec8f376437b81e21c8f6e54031e.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_25.txt...vLLM STDOUT: INFO:     127.0.0.1:53736 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:21:23 [logger.py:43] Received request chatcmpl-00209b4d3cc54579838819f33ea874c3: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nJob. \\n\\nPanch witness \\n\\nBusiness \\n\\nPanch witness \\n\\nPvt. Job \\n\\nPanch witness \\n\\nBusiness \\n\\nWitness \\n\\nage. NGO, Victim \\nassistance Unit. \\nGMC Bambolim \\n\\nShri. Sanjay Kumar \\nJena s/o Bisheswar \\nJena, age- 23 \\nyears, r/o Arpora, \\nBardez Goa, n/o \\nDunda, Mukulishi, \\nBasta, Baleshwar, \\nOdisha. \\n\\nShri. Harshvardhan \\ns/o Sandeep, age- \\n21 years, r/o \\nDevashri Garden. \\nSucorro, Porvorim, \\nBardez Goa. \\n9787277280 \\n\\nShri. Tusarkanta \\nDehury s/o \\nBrahmananda \\nDehury, age- 32 \\nyears, Occp- \\nPrivate Service, r/o \\nc/o Sandeep Baghi, \\nArpora, Bardez \\nGoa, no Muktapasi, \\nMahulpal, \\nDhenkanai, Odisha \\n\\nShri. Sandeep \\nBhagi s/o Yashpal \\nBaghi. age- 47 \\nyears, Occp- \\nBusiness, r/o \\nG-008, Devashri \\nGarden, near \\nCorporation Bank, \\n\\n\\x0cAlto Porvorim, \\nBardez Goa, \\n403521 \\n\\nG 135POLOC 136Scanned with OKEN Scanner 137 \\n\\n--- PAGE 14 --- \\n\\n10. Mr. Pr<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_25.txt...vLLM STDOUT: INFO 12-14 05:21:24 [engine.py:317] Added request chatcmpl-00209b4d3cc54579838819f33ea874c3.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_25.txt...vLLM STDOUT: INFO:     127.0.0.1:44200 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 37 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_25_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_25_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_25.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_25_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:45392 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:45404 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:21:41 [logger.py:43] Received request chatcmpl-65cf293833884038bdf649ce70300cda: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n/o \\nG-008, Devashri \\nGarden, near \\nCorporation Bank, \\n\\n\\x0cAlto Porvorim, \\nBardez Goa, \\n403521 \\n\\nG 135POLOC 136Scanned with OKEN Scanner 137 \\n\\n--- PAGE 14 --- \\n\\n10. Mr. Prashant s/o Nirmala Bhovi, Occp- Business, r/o H. No. 802, Soranto waddo, Near Cajy \\nPharmacy, Anjuna, Bardez Goa 138Business 139Witness 140 11. Dr. Ankush B. Patil, Major in \\nage, Police Surgeon, GMC, Reg. No. 2715, GMC Bambolim Goa 141Govt. service 142Witness \\n143 12. Shri. Khalil s/o Abid Khedagi, age- 17 years, Occp- Private Service, r/o c/o \\nJeetandra, Near St. Joseph school, Hotel Nilaya road, Arpora, Bardez Goa, n/o Near \\nJumma Masjid, Salotagi, Bijapur, Karnataka. 8010574299. 144Pvt. job 145Witness 146 13. Dr. \\nGirish S. Kamat, Major in age, Police Surgeon, GMC, Reg. No. 1919, GMC Bambolim Goa \\n147Govt. service 148 14. Shri. Mohammad S/o Salim Shaikh, age- 28 years, r/o H. No. 373/10, \\nGanganagar, Khorlim, Bardez Goa. 149Private Service 150Witness 151Panch 152Scanned with \\nOKEN Scanner 153 \\n\\n--- PAGE 15 --- \\n\\nShaikh, age- 28 years, r/o H. No. Service witness 154373/10, Ganganagar, Khorlim, 155Bardez \\nGoa. 156Shri Baidyanath s/o Amulya Driver 157Behera, age-27 years, r/o Soranto 158Panch \\n159witness 160waddo, Anjuna, Bardez, Goa 16116 162Miss Sneha S. Sawal, Major in Service 1.0. \\n16361012 164 age. LPSI, Anjuna P.S. 165Pieli Maya Nair - (Expert) 166 14. If FIR is false, indicate \\naction taken or proposed to be taken U/s 182/211 I.P.C- 167 15. Result of Laboratory analysis. - \\nPreserved exhibits are 168being forwarded to Central Forensic Science Laboratory, Kharadi \\nPune, Maharashtra for examination and report. 169 16. Brief Facts of the case:- 170 (Add \\nseparate sheet, if necessary) 171MAY IT PLEASE YOUR HONOUR 172In the limits of your Hon'ble \\nCourt and within the Jurisdiction of Anjuna Police Station, that on 30/07/23 between 16.45 hrs \\nto 17. 50 hrs at Arpora Grand guest house, Arpora, Bardez Goa, accused person mentioned at \\nserial No. 11 at Col. No. A-1 disrobe the complainant lady and further 173Trosecuto 174Scanned \\nwith OKEN Scanner 175 \\n\\n--- PAGE 16 --- \\n\\nhad forcible sexual intercourse with her against her will and 176thus committed rape of the \\nvictim/complainant. 177Thus the accused person committed an offence 178punishable U/s 376 \\n\\n \\n \\n \\n\\x0cIPC. 179HENCE THE CHARGE 180 17. Refer Notice served: Yes/No. -- Date. /09/2023 181 \\n(Acknowledgement to be placed) 182 18. Dispatched on: 183 19. No. of enclosures: As per Index. \\n184 20. List of enclosures: As annexed. 185Forwarded by Officer in charge 186Signature of \\ninvestigating 187Of Police Station. 188Officer 189Submitting Charge sheet 190f 191PS2 192 Name: \\n-Shri. Prashal P.N. Dessai. Name:- Miss. Sneha<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:21:41 [engine.py:317] Added request chatcmpl-65cf293833884038bdf649ce70300cda.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_26.txt...vLLM STDOUT: INFO:     127.0.0.1:45406 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:21:46 [logger.py:43] Received request chatcmpl-ef3a0c8d0bc74fbbabcc772483aedfbe: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n/o \\nG-008, Devashri \\nGarden, near \\nCorporation Bank, \\n\\n\\x0cAlto Porvorim, \\nBardez Goa, \\n403521 \\n\\nG 135POLOC 136Scanned with OKEN Scanner 137 \\n\\n--- PAGE 14 --- \\n\\n10. Mr. Prashant s/o Nirmala Bhovi, Occp- Business, r/o H. No. 802, Soranto waddo, Near Cajy \\nPharmacy, Anjuna, Bardez Goa 138Business 139Witness 140 11. Dr. Ankush B. Patil, Major in \\nage, Police Surgeon, GMC, Reg. No. 2715, GMC Bambolim Goa 141Govt. service 142Witness \\n143 12. Shri. Khalil s/o Abid Khedagi, age- 17 years, Occp- Private Service, r/o c/o \\nJeetandra, Near St. Joseph school, Hotel Nilaya road, Arpora, Bardez Goa, n/o Near \\nJumma Masjid, Salotagi, Bijapur, Karnataka. 8010574299. 144Pvt. job 145Witness 146 13. Dr. \\nGirish S. Kamat, Major in age, Police Surgeon, GMC, Reg. No. 1919, GMC Bambolim Goa \\n147Govt. service 148 14. Shri. Mohammad S/o Salim Shaikh, age- 28 years, r/o H. No. 373/10, \\nGanganagar, Khorlim, Bardez Goa. 149Private Service 150Witness 151Panch 152Scanned with \\nOKEN Scanner 153 \\n\\n--- PAGE 15 ---<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:21:46 [engine.py:317] Added request chatcmpl-ef3a0c8d0bc74fbbabcc772483aedfbe.\n",
            "\u001b[2KProcessing 3 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_26.txt...vLLM STDOUT: INFO:     127.0.0.1:45416 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:22:02 [logger.py:43] Received request chatcmpl-da4609bb4f6b4436aa0e45998bba64fa: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nNo. 373/10, \\nGanganagar, Khorlim, Bardez Goa. 149Private Service 150Witness 151Panch 152Scanned with \\nOKEN Scanner 153 \\n\\n--- PAGE 15 --- \\n\\nShaikh, age- 28 years, r/o H. No. Service witness 154373/10, Ganganagar, Khorlim, 155Bardez \\nGoa. 156Shri Baidyanath s/o Amulya Driver 157Behera, age-27 years, r/o Soranto 158Panch \\n159witness 160waddo, Anjuna, Bardez, Goa 16116 162Miss Sneha S. Sawal, Major in Service 1.0. \\n16361012 164 age. LPSI, Anjuna P.S. 165Pieli Maya Nair - (Expert) 166 14. If FIR is false, indicate \\naction taken or proposed to be taken U/s 182/211 I.P.C- 167 15. Result of Laboratory analysis. - \\nPreserved exhibits are 168being forwarded to Central Forensic Science Laboratory, Kharadi \\nPune, Maharashtra for examination and report. 169 16. Brief Facts of the case:- 170 (Add \\nseparate sheet, if necessary) 171MAY IT PLEASE YOUR HONOUR 172In the limits of your Hon\\'ble \\nCourt and within the Jurisdiction of Anjuna Police Station, that on 30/07/23 between 16.45 hrs \\nto 17. 50 hrs at Arpora Grand guest house, Arpora, Bardez Goa, accused person mentioned at \\nserial No. 11 at Col. No. A-1 disrobe the complainant lady and further 173Trosecuto 174Scanned \\nwith OKEN Scanner 175<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:22:02 [engine.py:317] Added request chatcmpl-da4609bb4f6b4436aa0e45998bba64fa.\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_26.txt...vLLM STDOUT: INFO:     127.0.0.1:51532 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:22:17 [logger.py:43] Received request chatcmpl-b76cac70809146c9baadae0f90a14b76: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n11 at Col. No. A-1 disrobe the complainant lady and further 173Trosecuto 174Scanned \\nwith OKEN Scanner 175 \\n\\n--- PAGE 16 --- \\n\\nhad forcible sexual intercourse with her against her will and 176thus committed rape of the \\nvictim/complainant. 177Thus the accused person committed an offence 178punishable U/s 376 \\n\\n \\n \\n \\n\\x0cIPC. 179HENCE THE CHARGE 180 17. Refer Notice served: Yes/No. -- Date. /09/2023 181 \\n(Acknowledgement to be placed) 182 18. Dispatched on: 183 19. No. of enclosures: As per Index. \\n184 20. List of enclosures: As annexed. 185Forwarded by Officer in charge 186Signature of \\ninvestigating 187Of Police Station. 188Officer 189Submitting Charge sheet 190f 191PS2 192 Name: \\n-Shri. Prashal P.N. Dessai. Name:- Miss. Sneha<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:22:17 [engine.py:317] Added request chatcmpl-b76cac70809146c9baadae0f90a14b76.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_26.txt...vLLM STDOUT: INFO:     127.0.0.1:42652 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 47 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_26_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_26_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_26.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_26_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:56140 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:56148 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:22:35 [logger.py:43] Received request chatcmpl-a02415c9415b4c92af2f35ac7833b08c: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nannexed. 185Forwarded by Officer in charge 186Signature of \\ninvestigating 187Of Police Station. 188Officer 189Submitting Charge sheet 190f 191PS2 192 Name: \\n-Shri. Prashal P.N. Dessai. Name:- Miss. Sneha 193Sawal. 194Rank: - Police Inspector. 195Rank: \\nLPSI, Anjuna PS. 196Scanned with OKEN Scanner 197 \\n\\n--- PAGE 17 --- \\n\\n[Stamp of Police Inspector, Mapusa Police Station, Mapusa-Goa] 198case to 199tim 200SCINO \\n20195/2016 202MPRNO 51/2016 2031 204INSPECTOR, MAPUSA POLICE STA 205POLICE 206* \\n207MAPUSA-GOA 208FINAL FORM/REPORT (Under Section 173 Cr. P.C.) 209MAPUSA POLICE \\nSTATION 1.W. ow 7621 21116 210IN THE CHILDREN'S COURT FOR THE STATE OF GOA, AT \\nPANAJI GOA. 211 1. District: N.Goa. P.S.: Mapusa Year: 2016 FIR No. 99/2016 Date: 29.03.2016. \\n212 2. Charge Sheet No. 110/2016 2133) Date: 27/6/2016 214 4. (i) Act: I.P.C. 215Sections: 363, 342, \\n427, 376, 509, 354, 216354-A, 354-C, 354-D, 323, 506 IPC 217 (ii) Act: Goa Children's Act \\n218Sections: 8 of Goa Children's Act. 219 (iii) Act: POCSO Act 220Sections: 4, 8, 11, 12 of POCSO \\nAct. 221 (iv) Other Acts & Sections: 2224,8,1 223Claw in 224 5.Type of final Form/Report; Charge \\nsheet/Not Charge Sheeted for want of evidence/FR True, Undetected true, Untraced/FR true, \\noffence abated/FR Unoccurred. 225 (Tick 'v' applicable portion). CHARGE SHEET 226 6. If FR \\nUnoccurred: False/Mistake of fact/mistake of law/Non cognizable/Civil Nature. (Tick 'V' \\napplicable portion). N.A. 227 7. If Charge sheet: Original/Supplementary. Original 228 (Tick'\\napplicable portion). 229 8. Name of 1.O.: Shri Tejeshkumar P. Naik Rank: Police Sub Inspector (at \\nthe time of charge sheet). 230Scanned with OKEN Scanner 231 \\n\\n--- PAGE 18 --- \\n\\n7.  (a) Name of Complainant/informant: Mrs. Sunita Jadhav 232 (b) Husband's Name/address: \\n\\nVijay Jadhav R/o Taliyawado, Chicalim Colvale Goa. 233 10. Details of \\nproperties/Articles/Documents recovered/Seized during investigation and relied Upon \\n(Separate list can be attached, if necessary). 234 \\n\\nSI. No. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs). \\n\\nDisposal \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\nFrom \\nwhom \\n/Where \\nrecovered \\nor seized \\n\\n \\n \\n \\n\\x0c21/16 \\n\\nRs. \\n25,00,000/\\n- \\n\\nReleased as \\nper order of \\nHon'ble \\nCourt. \\n\\nAttached \\nunder \\nAttachment \\nPanchanam\\na \\nconducted \\non \\n29.03.2016. \\n\\nRs. 10/- \\n\\nSent \\nherewith \\nalongwith \\nCharge \\nSheet. \\n\\nAttached \\nunder \\nAttachment \\nPanchanam\\na \\nconducted \\non \\n29.03.2016. \\n\\n01 \\n\\n02 \\n\\nThis brown \\ncolour \\nTruck \\nbearing No. \\nGA-01-Z-15\\n17, attached \\nin Mapusa \\nP.S. Cr. No. \\n99/2016 U/s<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:22:35 [engine.py:317] Added request chatcmpl-a02415c9415b4c92af2f35ac7833b08c.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_27.txt...vLLM STDOUT: INFO:     127.0.0.1:56150 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:22:43 [logger.py:43] Received request chatcmpl-74e0b59edd1b4df9aafbc8db1dcfc5b3: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n annexed. 185Forwarded by Officer in charge 186Signature of \\ninvestigating 187Of Police Station. 188Officer 189Submitting Charge sheet 190f 191PS2 192 Name: \\n-Shri. Prashal P.N. Dessai. Name:- Miss. Sneha 193Sawal. 194Rank: - Police Inspector. 195Rank: \\nLPSI, Anjuna PS. 196Scanned with OKEN Scanner 197 \\n\\n--- PAGE 17 ---<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2KProcessing 3 chunks to generate QA pairs...\n",
            "\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_27.txt...vLLM STDOUT: INFO 12-14 05:22:43 [engine.py:317] Added request chatcmpl-74e0b59edd1b4df9aafbc8db1dcfc5b3.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_27.txt...vLLM STDOUT: INFO:     127.0.0.1:55316 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:22:58 [logger.py:43] Received request chatcmpl-ce7892c1101441768789b92cf2a4bce8: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n194Rank: - Police Inspector. 195Rank: \\nLPSI, Anjuna PS. 196Scanned with OKEN Scanner 197 \\n\\n--- PAGE 17 --- \\n\\n[Stamp of Police Inspector, Mapusa Police Station, Mapusa-Goa] 198case to 199tim 200SCINO \\n20195/2016 202MPRNO 51/2016 2031 204INSPECTOR, MAPUSA POLICE STA 205POLICE 206* \\n207MAPUSA-GOA 208FINAL FORM/REPORT (Under Section 173 Cr. P.C.) 209MAPUSA POLICE \\nSTATION 1.W. ow 7621 21116 210IN THE CHILDREN\\'S COURT FOR THE STATE OF GOA, AT \\nPANAJI GOA. 211 1. District: N.Goa. P.S.: Mapusa Year: 2016 FIR No. 99/2016 Date: 29.03.2016. \\n212 2. Charge Sheet No. 110/2016 2133) Date: 27/6/2016 214 4. (i) Act: I.P.C. 215Sections: 363, 342, \\n427, 376, 509, 354, 216354-A, 354-C, 354-D, 323, 506 IPC 217 (ii) Act: Goa Children\\'s Act \\n218Sections: 8 of Goa Children\\'s Act. 219 (iii) Act: POCSO Act 220Sections: 4, 8, 11, 12 of POCSO \\nAct. 221 (iv) Other Acts & Sections: 2224,8,1 223Claw in 224 5.Type of final Form/Report; Charge \\nsheet/Not Charge Sheeted for want of evidence/FR True, Undetected true, Untraced/FR true, \\noffence abated/FR Unoccurred. 225 (Tick \\'v\\' applicable portion). CHARGE SHEET 226 6. If FR \\nUnoccurred: False/Mistake of fact/mistake of law/Non cognizable/Civil Nature. (Tick \\'V\\' \\napplicable portion). N.A. 227 7. If Charge sheet: Original/Supplementary. Original 228 (Tick\\'\\napplicable portion). 229 8. Name of 1.O.: Shri Tejeshkumar P. Naik Rank: Police Sub Inspector (at \\nthe time of charge sheet). 230Scanned with OKEN Scanner 231<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:22:58 [engine.py:317] Added request chatcmpl-ce7892c1101441768789b92cf2a4bce8.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_27.txt...vLLM STDOUT: INFO:     127.0.0.1:38416 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:23:14 [logger.py:43] Received request chatcmpl-30b4eda7864b4e43921511e55e8d9601: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nName of 1.O.: Shri Tejeshkumar P. Naik Rank: Police Sub Inspector (at \\nthe time of charge sheet). 230Scanned with OKEN Scanner 231 \\n\\n--- PAGE 18 --- \\n\\n7.  (a) Name of Complainant/informant: Mrs. Sunita Jadhav 232 (b) Husband\\'s Name/address: \\n\\nVijay Jadhav R/o Taliyawado, Chicalim Colvale Goa. 233 10. Details of \\nproperties/Articles/Documents recovered/Seized during investigation and relied Upon \\n(Separate list can be attached, if necessary). 234 \\n\\nSI. No. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs). \\n\\nDisposal \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\nFrom \\nwhom \\n/Where \\nrecovered \\nor seized \\n\\n \\n \\n \\n\\x0c21/16 \\n\\nRs. \\n25,00,000/\\n- \\n\\nReleased as \\nper order of \\nHon\\'ble \\nCourt. \\n\\nAttached \\nunder \\nAttachment \\nPanchanam\\na \\nconducted \\non \\n29.03.2016. \\n\\nRs. 10/- \\n\\nSent \\nherewith \\nalongwith \\nCharge \\nSheet. \\n\\nAttached \\nunder \\nAttachment \\nPanchanam\\na \\nconducted \\non \\n29.03.2016. \\n\\n01 \\n\\n02 \\n\\nThis brown \\ncolour \\nTruck \\nbearing No. \\nGA-01-Z-15\\n17, attached \\nin Mapusa \\nP.S. Cr. No. \\n99/2016 U/s<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:23:14 [engine.py:317] Added request chatcmpl-30b4eda7864b4e43921511e55e8d9601.\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_27.txt...vLLM STDOUT: INFO:     127.0.0.1:49110 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 48 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_27_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_27_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_27.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_27_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:55348 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:55356 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:23:32 [logger.py:43] Received request chatcmpl-f3089c7a799844ecb586a1e433e7062b: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nanchanam\\na \\nconducted \\non \\n29.03.2016. \\n\\n01 \\n\\n02 \\n\\nThis brown \\ncolour \\nTruck \\nbearing No. \\nGA-01-Z-15\\n17, attached \\nin Mapusa \\nP.S. Cr. No. \\n99/2016 U/s \\n363, 342, \\n427, 376, \\n509, 354, \\n354-A, \\n354-C, \\n354-D, 323, \\n506 IPC, 8 \\nof Goa \\nChildren's \\nAct & Sec. \\n4,8,11,12 of \\nPOCSO \\nAct,, \\nconducted \\non \\n29.03.2016. \\n\\nThis packed \\nand sealed \\nenvelope \\ncontains \\none note of \\nIndian \\nCurrency of \\nRupees \\nTen, \\nattached \\nduring \\nPanchanam\\na \\nconcerned \\nin Mapusa \\nP.S. Cr. No. \\n\\n \\n\\x0c03 \\n\\n99/2016 U/s \\n363, 342, \\n427, 376, \\n509, 354, \\n354-A, \\n354-C, \\n354-D, 323, \\n506 IPC, 8 \\nof Goa \\nChildren's \\nAct & Sec. \\n4,8,11,12 of \\nPOCSO \\nAct, \\nconducted \\non \\n29.03.2016. \\n\\nThis packed \\nand sealed \\ncloth line \\nenvelope \\ncontains 1) \\nOne White \\ncolour Top \\n2) One blue \\ncolour Skirt \\nwhich is \\nattached \\nfrom the \\ninstance of \\nMrs. Sunita \\nw/o Vijay \\nJadhav, \\nmother of \\nvictim \\nunder \\nAttachment \\nPanchanam\\na \\nconducted \\non \\n\\nRs. 300/- \\n\\nSent \\nherewith \\nalongwith \\nCharge \\nSheet. \\n\\nAttached \\nunder \\nAttachment \\nPanchanam\\na \\nconducted \\non \\n29.03.2016. \\n\\n \\n\\x0c29/03/2016 \\nconcerned \\nin Mapusa \\nP.S. Cr. No. \\n99/16 U/s \\n363, 342, \\n427, 376, \\n509, 354, \\n354-A, \\n354-C, \\n354-D, 323, \\n506 IPC, \\nSec. 8 of \\nGoa \\nChildren \\nAct, Sec. 4, \\n8, 11, 12 of \\nPOCSO \\nAct. \\n\\nyelide 235Ve 236Estimated 237Value 238Panchua 239- 240Cell 241fee 2424 2431 244Scanned with OKEN \\nScanner 245 \\n\\n--- PAGE 19 --- \\n\\nSI. No. \\n\\n04 \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs). \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\nRs. 500/- \\n\\nThis packed \\nand scaled \\ncloth line \\nenvelope \\nbag \\ncontains \\none Sky \\nblue colour \\njeans and \\n\\nDisposal \\n\\nSent \\nherewith \\nalongwith \\nCharge \\nSheet. \\n\\nFrom \\nwhom \\n/Where \\nrecovered \\nor seized \\n\\nAttached \\nunder \\nAttachment \\nPanchanam\\na \\nconducted \\non \\n29.03.2016. \\n\\n \\n \\n\\x0cone inner \\nwear of \\ncoffee \\ncolour \\nbelongs to \\naccused \\nperson \\nnamely \\nAppaji s/o \\nMaruti Naik, \\nattached \\nfrom the \\ninstance of \\nAppaji s/o \\nMaruti Naik \\nduring \\nAttachment \\nPanchanam\\na \\nconducted \\non \\n29.03.2016 \\nat Mapusa \\nPolice \\nStation \\nconcerned \\nin Mapusa \\nP.S. Cr. No. \\n99/16 U/s \\n363, 342, \\n427, 376, \\n509, 354, \\n354-A, \\n354-C, \\n354-D, 323, \\n506 IPC, \\nSec. 8 of \\nGoa \\nChildren \\nAct, Sec. 4, \\n8, 11, 12 of \\nPOCSO \\n\\n\\x0cAct. \\n\\n(10/kes 246Accese 247t 248 11. Particulars of accused person charge sheeted (Use separate \\nsheet for each accused) 249 Sl. No: A-1 250 (i<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:23:32 [engine.py:317] Added request chatcmpl-f3089c7a799844ecb586a1e433e7062b.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_28.txt...vLLM STDOUT: INFO:     127.0.0.1:55360 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:23:37 [logger.py:43] Received request chatcmpl-49eeeb6d6b8a4146915c2457902b2e68: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nanchanam\\na \\nconducted \\non \\n29.03.2016. \\n\\n01 \\n\\n02 \\n\\nThis brown \\ncolour \\nTruck \\nbearing No. \\nGA-01-Z-15\\n17, attached \\nin Mapusa \\nP.S. Cr. No. \\n99/2016 U/s \\n363, 342, \\n427, 376, \\n509, 354, \\n354-A, \\n354-C, \\n354-D, 323, \\n506 IPC, 8 \\nof Goa \\nChildren\\'s \\nAct & Sec. \\n4,8,11,12 of \\nPOCSO \\nAct,, \\nconducted \\non \\n29.03.2016. \\n\\nThis packed \\nand sealed \\nenvelope \\ncontains \\none note of \\nIndian \\nCurrency of \\nRupees \\nTen, \\nattached \\nduring \\nPanchanam\\na \\nconcerned \\nin Mapusa \\nP.S. Cr. No. \\n\\n \\n\\x0c03 \\n\\n99/2016 U/s \\n363, 342, \\n427, 376, \\n509, 354, \\n354-A, \\n354-C, \\n354-D, 323, \\n506 IPC, 8 \\nof Goa \\nChildren\\'s \\nAct & Sec. \\n4,8,11,12 of \\nPOCSO \\nAct, \\nconducted \\non \\n29.03.2016. \\n\\nThis packed \\nand sealed \\ncloth line \\nenvelope \\ncontains 1) \\nOne White \\ncolour Top \\n2) One blue \\ncolour Skirt \\nwhich is \\nattached \\nfrom the \\ninstance of \\nMrs. Sunita \\nw/o Vijay \\nJadhav, \\nmother of \\nvictim \\nunder \\nAttachment \\nPanchanam\\na \\nconducted \\non \\n\\nRs. 300/- \\n\\nSent \\nherewith \\nalongwith \\nCharge \\nSheet.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:23:37 [engine.py:317] Added request chatcmpl-49eeeb6d6b8a4146915c2457902b2e68.\n",
            "\u001b[2KProcessing 3 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_28.txt...vLLM STDOUT: INFO:     127.0.0.1:37980 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:23:53 [logger.py:43] Received request chatcmpl-c1bce215587e417aa46a1dfa09dd9f7b: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nSunita \\nw/o Vijay \\nJadhav, \\nmother of \\nvictim \\nunder \\nAttachment \\nPanchanam\\na \\nconducted \\non \\n\\nRs. 300/- \\n\\nSent \\nherewith \\nalongwith \\nCharge \\nSheet. \\n\\nAttached \\nunder \\nAttachment \\nPanchanam\\na \\nconducted \\non \\n29.03.2016. \\n\\n \\n\\x0c29/03/2016 \\nconcerned \\nin Mapusa \\nP.S. Cr. No. \\n99/16 U/s \\n363, 342, \\n427, 376, \\n509, 354, \\n354-A, \\n354-C, \\n354-D, 323, \\n506 IPC, \\nSec. 8 of \\nGoa \\nChildren \\nAct, Sec. 4, \\n8, 11, 12 of \\nPOCSO \\nAct. \\n\\nyelide 235Ve 236Estimated 237Value 238Panchua 239- 240Cell 241fee 2424 2431 244Scanned with OKEN \\nScanner 245 \\n\\n--- PAGE 19 --- \\n\\nSI. No. \\n\\n04 \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs). \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\nRs. 500/- \\n\\nThis packed \\nand scaled \\ncloth line \\nenvelope \\nbag \\ncontains \\none Sky \\nblue colour \\njeans and \\n\\nDisposal \\n\\nSent \\nherewith \\nalongwith \\nCharge \\nSheet. \\n\\nFrom \\nwhom \\n/Where \\nrecovered \\nor seized \\n\\nAttached \\nunder \\nAttachment \\nPanchanam\\na \\nconducted \\non \\n29.03.2016.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:23:53 [engine.py:317] Added request chatcmpl-c1bce215587e417aa46a1dfa09dd9f7b.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_28.txt...vLLM STDOUT: INFO:     127.0.0.1:41456 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:24:08 [logger.py:43] Received request chatcmpl-79eee0474e1446e88f055b49738667a3: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n500/- \\n\\nThis packed \\nand scaled \\ncloth line \\nenvelope \\nbag \\ncontains \\none Sky \\nblue colour \\njeans and \\n\\nDisposal \\n\\nSent \\nherewith \\nalongwith \\nCharge \\nSheet. \\n\\nFrom \\nwhom \\n/Where \\nrecovered \\nor seized \\n\\nAttached \\nunder \\nAttachment \\nPanchanam\\na \\nconducted \\non \\n29.03.2016. \\n\\n \\n \\n\\x0cone inner \\nwear of \\ncoffee \\ncolour \\nbelongs to \\naccused \\nperson \\nnamely \\nAppaji s/o \\nMaruti Naik, \\nattached \\nfrom the \\ninstance of \\nAppaji s/o \\nMaruti Naik \\nduring \\nAttachment \\nPanchanam\\na \\nconducted \\non \\n29.03.2016 \\nat Mapusa \\nPolice \\nStation \\nconcerned \\nin Mapusa \\nP.S. Cr. No. \\n99/16 U/s \\n363, 342, \\n427, 376, \\n509, 354, \\n354-A, \\n354-C, \\n354-D, 323, \\n506 IPC, \\nSec. 8 of \\nGoa \\nChildren \\nAct, Sec. 4, \\n8, 11, 12 of \\nPOCSO \\n\\n\\x0cAct. \\n\\n(10/kes 246Accese 247t 248 11. Particulars of accused person charge sheeted (Use separate \\nsheet for each accused) 249 Sl. No: A-1 250 (i<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:24:08 [engine.py:317] Added request chatcmpl-79eee0474e1446e88f055b49738667a3.\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_28.txt...vLLM STDOUT: INFO:     127.0.0.1:37114 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 45 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_28_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_28_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_28.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_28_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:50112 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:50124 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:24:26 [logger.py:43] Received request chatcmpl-2fe3f9bd574248c28d2cbf596adf8755: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n8, 11, 12 of \\nPOCSO \\n\\n\\x0cAct. \\n\\n(10/kes 246Accese 247t 248 11. Particulars of accused person charge sheeted (Use separate \\nsheet for each accused) 249 Sl. No: A-1 250 (i) Name: Appaji Naik 251 (ii) Father's Name: Maruti \\nNaik 252Whether Verified: Yes. 253 (iii) Date/Year of birth: 30 yrs. 254 (iv)Sex: Male. 255 (v) \\nNationality: Indian 256 (vi) Passport No.: 257Date of issue: 258Place of issue:- 259 (vii) Religion: \\nHindu 260 (viii) Whether SC/ST/OBC:-- (ix) Occupation: Driver 261 (x) Address: C/o Manoj \\nHarmalkar, Teen Maad, Sodiem Siolim Bardez Goa. 262 (xi) Provisional criminal No. 263 (xii) \\nRegular criminal No. (if Known)..... (xiii) Date of arrest: 29.03.2016. 264 (xiv) Date of release on \\nbail: ----- ( ) Date on which forwarded to court:- 265 (xvi) Under Acts & Sections: U/s \\n363,342,427,376,509,354,354-4,354-C,354-D,323, 266 506 IPC, 8 of Goa Children's Act & Sec. \\n4,8,11,12 of POCSO Act. 267 (xvii) Details of bailers/sureties Name: 268Father's name: \\n269Occupation................ 270Address: 271Identification......... 272 (xvii) Previous convictions with \\ncase references... 273 (xix) Status of the accused: In Judicial Custody. 274Forwarded / Bailed by \\nPolice / Bailed by Court / Police Custody / Judicial Custody 275/Absconding/proclaimed \\noffender (tick 'V' applicable portion) 276Scanned with OKEN Scanner 277 12. Par 278for 279 \\n\\n--- PAGE 20 --- \\n\\nSent 280herewith 281ngwith 282 12. Particulars of accused persons-not charge sheeted \\n(suspect): (Use separate sheet 283for each suspect) 284 Sl. No: NIL. 285 (i) Name:--- 286Whether \\nverified: 287 (ii) Father's/Husband's name: 288 (iii) Date/Year of birth: 289 (iv)Sex................ 290 (v) \\nNationality: -- 291 (vi) Passport No: 292Date of issue................. 293Place of issue........ 294 (vii) \\nReligion.... 295 (viii) Whether SC/ST/OBC....... 296 (ix) Occupation: ---- 297 (x) Address.... \\n298Whether verified............ 299 (xi) Provisional criminal No.......... 300 (xii) Suspicion Approved: \\nYes/No. 301 (xiii) Status of the accused (suspect): 302Bailed by Police/Bailed by court/Judicial \\nCustody/Not arrested 303 (tick'' applicable portion). 304 (xiv) Under Acts & Sections......... 305 \\n(xv) Any special remarks including reasons for not charge sheeting........ 306 13. Particulars of \\nwitnesses to be examined: 307Sl. 308No 309Name 310Father's/ Husband's Name 311Date/ Year of \\nbirth 312Occupation 313Address 314Type of Evidence to be tendered 315254 objcz 316 \\n\\nSr. No. \\n\\nName \\n\\nFather's/ \\nHusband\\n's Name \\n\\nDate/ \\nYear of \\nbirth \\n\\nOccupat\\nion \\n\\nAddress \\n\\nType of \\nEvidence \\nto be \\nrendered \\n\\n \\n \\n\\x0c1 \\n\\n2 \\n\\n3 \\n\\n4 \\n\\n5 \\n\\n6 \\n\\n7 \\n\\nMrs. \\nSunita \\nJadhav \\n\\nVijay \\nJadhav \\n\\n30 yrs \\n\\nHouse \\nwife \\n\\nShri \\nMohan \\nSawant \\n\\nRavalu \\nSawant \\n\\n52 yrs<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:24:26 [engine.py:317] Added request chatcmpl-2fe3f9bd574248c28d2cbf596adf8755.\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_29.txt...vLLM STDOUT: INFO:     127.0.0.1:50128 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:24:30 [logger.py:43] Received request chatcmpl-175148a6e0c34419b4ab9311e73fee5b: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 20 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n8, 11, 12 of \\nPOCSO \\n\\n\\x0cAct.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:24:30 [engine.py:317] Added request chatcmpl-175148a6e0c34419b4ab9311e73fee5b.\n",
            "\u001b[2KProcessing 5 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_29.txt...vLLM STDOUT: INFO:     127.0.0.1:57978 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_29.txt...vLLM STDOUT: INFO 12-14 05:24:45 [logger.py:43] Received request chatcmpl-c87a29eae90e46738e3f426ee1c62c4c: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 20 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n(10/kes 246Accese 247t 248 11. Particulars of accused person charge sheeted (Use separate \\nsheet for each accused) 249 Sl. No: A-1 250 (i) Name: Appaji Naik 251 (ii) Father\\'s Name: Maruti \\nNaik 252Whether Verified: Yes. 253 (iii) Date/Year of birth: 30 yrs. 254 (iv)Sex: Male. 255 (v) \\nNationality: Indian 256 (vi) Passport No.: 257Date of issue: 258Place of issue:- 259 (vii) Religion: \\nHindu 260 (viii) Whether SC/ST/OBC:-- (ix) Occupation: Driver 261 (x) Address: C/o Manoj \\nHarmalkar, Teen Maad, Sodiem Siolim Bardez Goa. 262 (xi) Provisional criminal No. 263 (xii) \\nRegular criminal No. (if Known)..... (xiii) Date of arrest: 29.03.2016. 264 (xiv) Date of release on \\nbail: ----- ( ) Date on which forwarded to court:- 265 (xvi) Under Acts & Sections: U/s \\n363,342,427,376,509,354,354-4,354-C,354-D,323, 266 506 IPC, 8 of Goa Children\\'s Act & Sec. \\n4,8,11,12 of POCSO Act. 267 (xvii) Details of bailers/sureties Name: 268Father\\'s name: \\n269Occupation................ 270Address: 271Identification......... 272 (xvii) Previous convictions with \\ncase references... 273 (xix) Status of the accused: In Judicial Custody. 274Forwarded / Bailed by \\nPolice / Bailed by Court / Police Custody / Judicial Custody 275/Absconding/proclaimed \\noffender (tick \\'V\\' applicable portion) 276Scanned with OKEN Scanner 277 12. Par 278for 279<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:24:45 [engine.py:317] Added request chatcmpl-c87a29eae90e46738e3f426ee1c62c4c.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_29.txt...vLLM STDOUT: INFO:     127.0.0.1:41202 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:25:01 [logger.py:43] Received request chatcmpl-bbb23ff412934bcbab4da7669ba6c36c: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 20 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n273 (xix) Status of the accused: In Judicial Custody. 274Forwarded / Bailed by \\nPolice / Bailed by Court / Police Custody / Judicial Custody 275/Absconding/proclaimed \\noffender (tick \\'V\\' applicable portion) 276Scanned with OKEN Scanner 277 12. Par 278for 279 \\n\\n--- PAGE 20 ---<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:25:01 [engine.py:317] Added request chatcmpl-bbb23ff412934bcbab4da7669ba6c36c.\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/output2/ilovepdf_merged_29.txt...vLLM STDOUT: INFO:     127.0.0.1:39990 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:25:15 [logger.py:43] Received request chatcmpl-103913bb9706419195bb455a2d50afc0: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 20 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nSent 280herewith 281ngwith 282 12. Particulars of accused persons-not charge sheeted \\n(suspect): (Use separate sheet 283for each suspect) 284 Sl. No: NIL. 285 (i) Name:--- 286Whether \\nverified: 287 (ii) Father\\'s/Husband\\'s name: 288 (iii) Date/Year of birth: 289 (iv)Sex................ 290 (v) \\nNationality: -- 291 (vi) Passport No: 292Date of issue................. 293Place of issue........ 294 (vii) \\nReligion.... 295 (viii) Whether SC/ST/OBC....... 296 (ix) Occupation: ---- 297 (x) Address.... \\n298Whether verified............ 299 (xi) Provisional criminal No.......... 300 (xii) Suspicion Approved: \\nYes/No. 301 (xiii) Status of the accused (suspect): 302Bailed by Police/Bailed by court/Judicial \\nCustody/Not arrested 303 (tick\\'\\' applicable portion). 304 (xiv) Under Acts & Sections......... 305 \\n(xv) Any special remarks including reasons for not charge sheeting........ 306 13. Particulars of \\nwitnesses to be examined: 307Sl. 308No 309Name 310Father\\'s/ Husband\\'s Name 311Date/ Year of \\nbirth 312Occupation 313Address 314Type of Evidence to be tendered 315254 objcz 316<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:25:15 [engine.py:317] Added request chatcmpl-103913bb9706419195bb455a2d50afc0.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_29.txt...vLLM STDOUT: INFO:     127.0.0.1:50642 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:25:30 [logger.py:43] Received request chatcmpl-2427e734ff7441d49ce4813576c82103: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 20 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n306 13. Particulars of \\nwitnesses to be examined: 307Sl. 308No 309Name 310Father\\'s/ Husband\\'s Name 311Date/ Year of \\nbirth 312Occupation 313Address 314Type of Evidence to be tendered 315254 objcz 316 \\n\\nSr. No. \\n\\nName \\n\\nFather\\'s/ \\nHusband\\n\\'s Name \\n\\nDate/ \\nYear of \\nbirth \\n\\nOccupat\\nion \\n\\nAddress \\n\\nType of \\nEvidence \\nto be \\nrendered \\n\\n \\n \\n\\x0c1 \\n\\n2 \\n\\n3 \\n\\n4 \\n\\n5 \\n\\n6 \\n\\n7 \\n\\nMrs. \\nSunita \\nJadhav \\n\\nVijay \\nJadhav \\n\\n30 yrs \\n\\nHouse \\nwife \\n\\nShri \\nMohan \\nSawant \\n\\nRavalu \\nSawant \\n\\n52 yrs<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_29.txt...vLLM STDOUT: INFO 12-14 05:25:30 [engine.py:317] Added request chatcmpl-2427e734ff7441d49ce4813576c82103.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_29.txt...vLLM STDOUT: INFO:     127.0.0.1:51350 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 76 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_29_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_29_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_29.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_29_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:56474 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:56484 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:25:48 [logger.py:43] Received request chatcmpl-88674003bfc84ad880f603d7ea31db7e: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\ned \\n\\n \\n \\n\\x0c1 \\n\\n2 \\n\\n3 \\n\\n4 \\n\\n5 \\n\\n6 \\n\\n7 \\n\\nMrs. \\nSunita \\nJadhav \\n\\nVijay \\nJadhav \\n\\n30 yrs \\n\\nHouse \\nwife \\n\\nShri \\nMohan \\nSawant \\n\\nRavalu \\nSawant \\n\\n52 yrs \\n\\nService \\n\\nShri Sunil \\nKorgaonk\\nar \\n\\nGuna \\nKorgaonk\\nar \\n\\n29 yrs \\n\\nService \\n\\nShri \\nShivanan\\nd. \\nNavelkar \\n\\nShri \\nAbhiman\\nyu \\nPadwal \\n\\nMiss \\nSanjana \\nJadhav \\n\\nMs. \\nAudrey \\nPinto \\n\\nGangara\\nm \\nNavelkar \\n\\nRamchan\\ndra \\nPadwal \\n\\nVijay \\nJadhav \\n\\n56 yrs \\n\\nService \\n\\n51 yrs \\n\\nTailor \\n\\n08 yrs \\n\\nStudent \\n\\nCo-ordin\\nator \\n\\nMajor \\n\\nComplain\\nant \\n\\nPanch \\n\\nPanch \\n\\nPanch \\n\\nPanch \\n\\nWitness \\n\\nWitness \\n\\nTeliyawad\\no, \\nChicalim \\nColvale \\nBardez \\nGoa. \\n\\nTemwado\\n, Khutwal \\nPernem \\nGoa \\n\\nAframent\\nwado \\nVerla \\nCanca \\nBardez \\nGoa. \\n\\nDattawad\\ni, Mapusa \\nBardez \\nGoa \\n\\nKhorlim \\nMapusa \\nBardez \\nGoa \\n\\nChicalim \\nColvale \\nBardez \\nGoa \\n\\nVictim \\nAssistanc\\ne Unit, \\nPanaji \\nGoa \\n\\n \\n\\x0c8 \\n\\nMast. \\nBhijendra \\nYadav. \\n\\nBabundar \\nYadav \\n\\n10 yrs \\n\\nStudent \\n\\nWitness \\n\\nChicalim \\nColvale \\nBardez \\nGoa. \\n\\nfull 3174 3186 3197 3209 321V 322 Mast. Rohan Ramlal Tirki 323Tirki 324Pup 325Vijaye Sadhow 326Bardez \\nGoa. 327Attachment Rinchrome t 328vehicle 329Scanned with OKEN Scanner 330 \\n\\n--- PAGE 21 --- \\n\\nSr. No. \\n\\nName \\n\\nFather's/ \\nHusband\\n's Name \\n\\nDate/ \\nYear of \\nbirth \\n\\nOccupat\\nion \\n\\nAddress \\n\\n9 \\n\\n10 \\n\\n11 \\n\\n12 \\n\\n13 \\n\\nMast. \\nRohan \\nTirki \\n\\nMiss \\nRoshan \\n\\nMs. \\nVahida \\nYelgar \\n\\nRamlal \\nTirki \\n\\n10 yrs \\n\\nStudent \\n\\nDr. \\nShradha \\nPol \\n\\nMajor \\n\\nCo-ordin\\nator \\n\\nDr. Sunil \\nChimbolk\\nar \\n\\nShrikant \\nChimbolk\\nar \\n\\nMajor \\n\\nSenior \\nResident \\nReg. No. \\n59 yrs \\n\\nAnupa \\nSatardek\\nar \\n\\nAshish \\nKalangut\\nkar \\n\\nMajor \\n\\nAsst. \\nLecturer \\n\\nChicalim \\nColvale \\nBardez \\nGoa. \\n\\nVictim \\nAssistanc\\ne Unit, \\nPanaji \\nGoa \\n\\nGoa \\nMedical \\nCollege, \\nBamboli\\nm Goa \\n\\nGoa \\nMedical \\nCollege, \\nBamboli\\n\\nType of \\nEvidence \\nto be \\nrendered \\n\\nWitness \\n\\nWitness \\n\\nWitness / \\nM.O. \\n\\nWitness / \\nM.O. \\n\\n \\n \\n \\n \\n \\n \\n\\x0c14 \\n\\n15 \\n\\n16 \\n\\n17 \\n\\n18 \\n\\nShri \\nSubhash \\nVolvoikar \\n\\nPandarin\\nath \\nVolvoikar \\n\\nMajor \\n\\nN \\n\\nShri \\nTejeshku\\nmar Naik \\n\\nPrakash \\nNaik \\n\\nMajor \\n\\nPolice \\nSub \\nInspector \\n\\nMrs. \\nKumud \\nMandrek\\nar \\n\\nMrs. \\nSanjal \\nKalangut\\nkar \\n\\nMrs. \\nRukmini \\n\\nSulgonk \\n\\nMajor \\n\\nTeacher \\n\\nMajor \\n\\nHead \\nMistress \\n\\nH.No. \\n573, \\nCostawa\\ndo, \\nCamurlim \\nGoa \\n\\n39 yrs \\n\\nService \\n\\nWitness \\n\\nWitness \\n\\nWitness \\n\\nm Goa \\n\\nH.No. \\n633, St. \\nAnthony \\nwada, \\nGuirim \\nGoa \\n\\nH.No. \\n153, Near \\nLaxmi \\nNarayan \\nTemple, \\nSada \\nMormuga\\no Goa \\n\\nB-258, \\nnear<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:25:48 [engine.py:317] Added request chatcmpl-88674003bfc84ad880f603d7ea31db7e.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_30.txt...vLLM STDOUT: INFO:     127.0.0.1:56486 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_30.txt...vLLM STDOUT: INFO 12-14 05:25:51 [logger.py:43] Received request chatcmpl-acd5782ceb244f998a974466fdef205c: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\ned \\n\\n \\n \\n\\x0c1 \\n\\n2 \\n\\n3 \\n\\n4 \\n\\n5 \\n\\n6 \\n\\n7 \\n\\nMrs. \\nSunita \\nJadhav \\n\\nVijay \\nJadhav \\n\\n30 yrs \\n\\nHouse \\nwife \\n\\nShri \\nMohan \\nSawant \\n\\nRavalu \\nSawant \\n\\n52 yrs \\n\\nService \\n\\nShri Sunil \\nKorgaonk\\nar \\n\\nGuna \\nKorgaonk\\nar \\n\\n29 yrs \\n\\nService \\n\\nShri \\nShivanan\\nd. \\nNavelkar \\n\\nShri \\nAbhiman\\nyu \\nPadwal \\n\\nMiss \\nSanjana \\nJadhav \\n\\nMs. \\nAudrey \\nPinto \\n\\nGangara\\nm \\nNavelkar \\n\\nRamchan\\ndra \\nPadwal \\n\\nVijay \\nJadhav \\n\\n56 yrs \\n\\nService \\n\\n51 yrs \\n\\nTailor \\n\\n08 yrs \\n\\nStudent \\n\\nCo-ordin\\nator \\n\\nMajor \\n\\nComplain\\nant \\n\\nPanch \\n\\nPanch \\n\\nPanch \\n\\nPanch \\n\\nWitness \\n\\nWitness \\n\\nTeliyawad\\no, \\nChicalim \\nColvale \\nBardez \\nGoa. \\n\\nTemwado\\n, Khutwal \\nPernem \\nGoa \\n\\nAframent\\nwado \\nVerla \\nCanca \\nBardez \\nGoa. \\n\\nDattawad\\ni, Mapusa \\nBardez \\nGoa \\n\\nKhorlim \\nMapusa \\nBardez \\nGoa \\n\\nChicalim \\nColvale \\nBardez \\nGoa \\n\\nVictim \\nAssistanc\\ne Unit, \\nPanaji \\nGoa \\n\\n \\n\\x0c8 \\n\\nMast. \\nBhijendra \\nYadav. \\n\\nBabundar \\nYadav \\n\\n10 yrs \\n\\nStudent \\n\\nWitness \\n\\nChicalim \\nColvale \\nBardez \\nGoa.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:25:51 [engine.py:317] Added request chatcmpl-acd5782ceb244f998a974466fdef205c.\n",
            "\u001b[2KProcessing 3 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_30.txt...vLLM STDOUT: INFO:     127.0.0.1:56490 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:26:07 [logger.py:43] Received request chatcmpl-4a812e922d304815b592404a958fb838: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\nBhijendra \\nYadav. \\n\\nBabundar \\nYadav \\n\\n10 yrs \\n\\nStudent \\n\\nWitness \\n\\nChicalim \\nColvale \\nBardez \\nGoa. \\n\\nfull 3174 3186 3197 3209 321V 322 Mast. Rohan Ramlal Tirki 323Tirki 324Pup 325Vijaye Sadhow 326Bardez \\nGoa. 327Attachment Rinchrome t 328vehicle 329Scanned with OKEN Scanner 330 \\n\\n--- PAGE 21 --- \\n\\nSr. No. \\n\\nName \\n\\nFather\\'s/ \\nHusband\\n\\'s Name \\n\\nDate/ \\nYear of \\nbirth \\n\\nOccupat\\nion \\n\\nAddress \\n\\n9 \\n\\n10 \\n\\n11 \\n\\n12 \\n\\n13 \\n\\nMast. \\nRohan \\nTirki \\n\\nMiss \\nRoshan \\n\\nMs. \\nVahida \\nYelgar \\n\\nRamlal \\nTirki \\n\\n10 yrs \\n\\nStudent \\n\\nDr. \\nShradha \\nPol \\n\\nMajor \\n\\nCo-ordin\\nator \\n\\nDr. Sunil \\nChimbolk\\nar \\n\\nShrikant \\nChimbolk\\nar \\n\\nMajor \\n\\nSenior \\nResident \\nReg. No. \\n59 yrs \\n\\nAnupa \\nSatardek\\nar \\n\\nAshish \\nKalangut\\nkar \\n\\nMajor \\n\\nAsst. \\nLecturer \\n\\nChicalim \\nColvale \\nBardez \\nGoa. \\n\\nVictim \\nAssistanc\\ne Unit, \\nPanaji \\nGoa \\n\\nGoa \\nMedical \\nCollege, \\nBamboli\\nm Goa \\n\\nGoa \\nMedical \\nCollege, \\nBamboli\\n\\nType of \\nEvidence \\nto be \\nrendered \\n\\nWitness \\n\\nWitness \\n\\nWitness / \\nM.O. \\n\\nWitness / \\nM.O. \\n\\n \\n \\n \\n \\n \\n \\n\\x0c14 \\n\\n15 \\n\\n16 \\n\\n17 \\n\\n18 \\n\\nShri \\nSubhash \\nVolvoikar<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:26:07 [engine.py:317] Added request chatcmpl-4a812e922d304815b592404a958fb838.\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/output2/ilovepdf_merged_30.txt...vLLM STDOUT: INFO:     127.0.0.1:35800 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:26:22 [logger.py:43] Received request chatcmpl-4a3af6b4d34949989eda78f35fe0867d: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n\\nVictim \\nAssistanc\\ne Unit, \\nPanaji \\nGoa \\n\\nGoa \\nMedical \\nCollege, \\nBamboli\\nm Goa \\n\\nGoa \\nMedical \\nCollege, \\nBamboli\\n\\nType of \\nEvidence \\nto be \\nrendered \\n\\nWitness \\n\\nWitness \\n\\nWitness / \\nM.O. \\n\\nWitness / \\nM.O. \\n\\n \\n \\n \\n \\n \\n \\n\\x0c14 \\n\\n15 \\n\\n16 \\n\\n17 \\n\\n18 \\n\\nShri \\nSubhash \\nVolvoikar \\n\\nPandarin\\nath \\nVolvoikar \\n\\nMajor \\n\\nN \\n\\nShri \\nTejeshku\\nmar Naik \\n\\nPrakash \\nNaik \\n\\nMajor \\n\\nPolice \\nSub \\nInspector \\n\\nMrs. \\nKumud \\nMandrek\\nar \\n\\nMrs. \\nSanjal \\nKalangut\\nkar \\n\\nMrs. \\nRukmini \\n\\nSulgonk \\n\\nMajor \\n\\nTeacher \\n\\nMajor \\n\\nHead \\nMistress \\n\\nH.No. \\n573, \\nCostawa\\ndo, \\nCamurlim \\nGoa \\n\\n39 yrs \\n\\nService \\n\\nWitness \\n\\nWitness \\n\\nWitness \\n\\nm Goa \\n\\nH.No. \\n633, St. \\nAnthony \\nwada, \\nGuirim \\nGoa \\n\\nH.No. \\n153, Near \\nLaxmi \\nNarayan \\nTemple, \\nSada \\nMormuga\\no Goa \\n\\nB-258, \\nnear<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_30.txt...vLLM STDOUT: INFO 12-14 05:26:22 [engine.py:317] Added request chatcmpl-4a3af6b4d34949989eda78f35fe0867d.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_30.txt...vLLM STDOUT: INFO:     127.0.0.1:38072 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 49 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_30_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_30_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_30.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_30_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:41788 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:41794 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:26:40 [logger.py:43] Received request chatcmpl-2d9c138de9ff481a9372f34eb7c55aff: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWitness \\n\\nWitness \\n\\nm Goa \\n\\nH.No. \\n633, St. \\nAnthony \\nwada, \\nGuirim \\nGoa \\n\\nH.No. \\n153, Near \\nLaxmi \\nNarayan \\nTemple, \\nSada \\nMormuga\\no Goa \\n\\nB-258, \\nnear Rain \\nTemple, \\nRam \\nnagar, \\nAlto \\nBetim \\nGoa \\n\\nWitness \\n\\nI.O. \\n\\nMapusa \\nPolice \\nStation, \\nMapusa \\nBardez \\nGoa \\n\\n \\n \\n\\x0ced On: 331nclosures: As per index. 332enclosures: As annexed 333by Officer in charge 334placef \\n335itsich 336inf 337VImp Remzenfi 338who deler in recordy 339 14. If FIR is false, indicate action \\ntaken or proposed to be taken u/s.182/211 I.P.C.:--- 340 15. Result of Laboratory analysis: 341 16. \\nBrief facts of the case (add separate sheet, if necessary). 342As per Annexure A 343why \\n344statement if 345Renzusi recread! 346 17. Refer Notice served: 347Yes/No 348Date: 349 \\n(Acknowledgement to be placed) 350 18. Dispatched On: 351 19. No of enclosures: As per index. \\n352 20. List of enclosures: As annexed 353Forwarded by Officer in charge 354 Name: Shri. Tushar \\nG. Lotliker. 355Rank: Police Inspector. 356Mapusa Police Station 357Signature of investigating \\nofficer 358Submitting Final report/Charge Sheet 359Name: Tejeshkumar P. Naik. 360Rank Police \\nSub Inspector. 361Mapusa Police Station. 362Scanned with OKEN Scanner 363 \\n\\n--- PAGE 22 --- \\n\\n[Stamp of Police Inspector, Mapusa Police Station, Mapusa-Goa] 364107 36512/215-7cognizan \\n36622/ - App 3678/412-ond, adj. 36812/4/m-ord 36917/4/ 370, odj 37126/4/m and commit \\n37210/5/moysenior cont 37310/5/23- ) 374INSPECTOR, RAPUSA POLICE STATIO 375MAPUSA-GOAX \\n376FINAL FORM/REPORT (Under Section 173 Cr. P.C.) 377MAPUSA POLICE STATION 378aw \\n37913570 38012/09/18 381IN THE COURT OF JUDICIAL MAGISTRATE FIRST CLASS AT MAPUSA \\nGOA. 382 1. District: N.Goa. P.S.: Mapusa Year: 2018 FIR No. 154/2018 Date: 14.05.2018 383 2. \\nCharge Sheet/Report No. 193/2018 3843) Date: 05/09/2018 385 4. (i) Act: I.P.C. 386Sections: 376, \\n417 387 (ii) Act: 388Sections: 389 (iii) Act: 390Sections: 391 (iv)Other Acts & Sections: 392 5.Type of \\nfinal Form/Report; Charge sheet/Not Charge Sheeted for want of evidence/FIR True, \\nUndetected true, Untraced/FIR true, offence abated/FIR Unoccurred. 393 (Tick'' applicable \\nportion). CHARGE SHEET 394 6. If FR Unoccurred: False/Mistake of fact/mistake of law/Non \\ncognizable/Civil Nature. (Tick'' applicable portion). N.A. 395 7. If Charge sheet/Report: \\nOriginal/Supplementary. Original 396 (Tick'' applicable portion). 397 8. Name of 1.0.: Shri \\nYogendra S. Garodi Rank: Police Sub Inspector No: --- (at the time of charge sheet). \\n398Scanned with OKEN Scanner 399 \\n\\n--- PAGE 23 --- \\n\\n9.  (a) Name of Complainant/informant : Miss. Jagruti<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:26:40 [engine.py:317] Added request chatcmpl-2d9c138de9ff481a9372f34eb7c55aff.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_31.txt...vLLM STDOUT: INFO:     127.0.0.1:41798 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:26:44 [logger.py:43] Received request chatcmpl-bbf66be7f71d4df28a6c5a7feb8c24fa: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 20 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nWitness \\n\\nWitness \\n\\nm Goa \\n\\nH.No. \\n633, St. \\nAnthony \\nwada, \\nGuirim \\nGoa \\n\\nH.No. \\n153, Near \\nLaxmi \\nNarayan \\nTemple, \\nSada \\nMormuga\\no Goa \\n\\nB-258, \\nnear Rain \\nTemple, \\nRam \\nnagar, \\nAlto \\nBetim \\nGoa \\n\\nWitness \\n\\nI.O. \\n\\nMapusa \\nPolice \\nStation, \\nMapusa \\nBardez \\nGoa<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:26:44 [engine.py:317] Added request chatcmpl-bbf66be7f71d4df28a6c5a7feb8c24fa.\n",
            "\u001b[2KProcessing 5 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_31.txt...vLLM STDOUT: INFO:     127.0.0.1:41812 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:26:55 [logger.py:43] Received request chatcmpl-709c1ac4cf8a4d008961d21cdcc211b2: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 20 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\nAnthony \\nwada, \\nGuirim \\nGoa \\n\\nH.No. \\n153, Near \\nLaxmi \\nNarayan \\nTemple, \\nSada \\nMormuga\\no Goa \\n\\nB-258, \\nnear Rain \\nTemple, \\nRam \\nnagar, \\nAlto \\nBetim \\nGoa \\n\\nWitness \\n\\nI.O. \\n\\nMapusa \\nPolice \\nStation, \\nMapusa \\nBardez \\nGoa \\n\\n \\n \\n\\x0ced On: 331nclosures: As per index. 332enclosures: As annexed 333by Officer in charge 334placef \\n335itsich 336inf 337VImp Remzenfi 338who deler in recordy 339 14. If FIR is false, indicate action \\ntaken or proposed to be taken u/s.182/211 I.P.C.:--- 340 15. Result of Laboratory analysis: 341 16. \\nBrief facts of the case (add separate sheet, if necessary). 342As per Annexure A 343why \\n344statement if 345Renzusi recread! 346 17. Refer Notice served: 347Yes/No 348Date: 349 \\n(Acknowledgement to be placed) 350 18. Dispatched On: 351 19. No of enclosures: As per index. \\n352 20. List of enclosures: As annexed 353Forwarded by Officer in charge 354 Name: Shri. Tushar \\nG. Lotliker. 355Rank: Police Inspector. 356Mapusa Police Station 357Signature of investigating \\nofficer 358Submitting Final report/Charge Sheet 359Name: Tejeshkumar P. Naik. 360Rank Police \\nSub Inspector. 361Mapusa Police Station. 362Scanned with OKEN Scanner 363<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:26:55 [engine.py:317] Added request chatcmpl-709c1ac4cf8a4d008961d21cdcc211b2.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_31.txt...vLLM STDOUT: INFO:     127.0.0.1:48172 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:27:10 [logger.py:43] Received request chatcmpl-dcf7283c4dce479192d0e1ef9f3f8a11: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 20 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n360Rank Police \\nSub Inspector. 361Mapusa Police Station. 362Scanned with OKEN Scanner 363 \\n\\n--- PAGE 22 ---<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:27:10 [engine.py:317] Added request chatcmpl-dcf7283c4dce479192d0e1ef9f3f8a11.\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_31.txt...vLLM STDOUT: INFO:     127.0.0.1:51466 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:27:25 [logger.py:43] Received request chatcmpl-d730908c12c14b6f80ea40ca3d0f8491: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 20 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n[Stamp of Police Inspector, Mapusa Police Station, Mapusa-Goa] 364107 36512/215-7cognizan \\n36622/ - App 3678/412-ond, adj. 36812/4/m-ord 36917/4/ 370, odj 37126/4/m and commit \\n37210/5/moysenior cont 37310/5/23- ) 374INSPECTOR, RAPUSA POLICE STATIO 375MAPUSA-GOAX \\n376FINAL FORM/REPORT (Under Section 173 Cr. P.C.) 377MAPUSA POLICE STATION 378aw \\n37913570 38012/09/18 381IN THE COURT OF JUDICIAL MAGISTRATE FIRST CLASS AT MAPUSA \\nGOA. 382 1. District: N.Goa. P.S.: Mapusa Year: 2018 FIR No. 154/2018 Date: 14.05.2018 383 2. \\nCharge Sheet/Report No. 193/2018 3843) Date: 05/09/2018 385 4. (i) Act: I.P.C. 386Sections: 376, \\n417 387 (ii) Act: 388Sections: 389 (iii) Act: 390Sections: 391 (iv)Other Acts & Sections: 392 5.Type of \\nfinal Form/Report; Charge sheet/Not Charge Sheeted for want of evidence/FIR True, \\nUndetected true, Untraced/FIR true, offence abated/FIR Unoccurred. 393 (Tick\\'\\' applicable \\nportion). CHARGE SHEET 394 6. If FR Unoccurred: False/Mistake of fact/mistake of law/Non \\ncognizable/Civil Nature. (Tick\\'\\' applicable portion). N.A. 395 7. If Charge sheet/Report: \\nOriginal/Supplementary. Original 396 (Tick\\'\\' applicable portion). 397 8. Name of 1.0.: Shri \\nYogendra S. Garodi Rank: Police Sub Inspector No: --- (at the time of charge sheet). \\n398Scanned with OKEN Scanner 399<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_31.txt...vLLM STDOUT: INFO 12-14 05:27:25 [engine.py:317] Added request chatcmpl-d730908c12c14b6f80ea40ca3d0f8491.\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_31.txt...vLLM STDOUT: INFO:     127.0.0.1:53228 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:27:40 [logger.py:43] Received request chatcmpl-5da74a621bfd41958209c1fc54a256a5: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 20 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nName of 1.0.: Shri \\nYogendra S. Garodi Rank: Police Sub Inspector No: --- (at the time of charge sheet). \\n398Scanned with OKEN Scanner 399 \\n\\n--- PAGE 23 --- \\n\\n9.  (a) Name of Complainant/informant : Miss. Jagruti<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:27:40 [engine.py:317] Added request chatcmpl-5da74a621bfd41958209c1fc54a256a5.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_31.txt...vLLM STDOUT: INFO:     127.0.0.1:35030 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 81 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_31_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_31_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_31.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_31_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:53560 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:53568 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:27:58 [logger.py:43] Received request chatcmpl-674c4473b3184045a3358b1e4bf2eec7: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n.: Shri \\nYogendra S. Garodi Rank: Police Sub Inspector No: --- (at the time of charge sheet). \\n398Scanned with OKEN Scanner 399 \\n\\n--- PAGE 23 --- \\n\\n9.  (a) Name of Complainant/informant : Miss. Jagruti Rokde 400 (b) Father's Name/address: \\nVithal Rokde R/o C/o Mrs. Emeliana Pereira, Flat No. 001. Damodar Apartments, Aradi \\nWaddo, Guirim Bardez Goa, N/o D46, Labour Camp, Anand Nagar, Dr. Ambedkar Road, \\nDharavi Mumbai 90. 401 10. Details of properties/Articles/Documents recovered/Seized \\nduring investigation and relied Upon (Separate list can be attached, if necessary). 402 \\n\\n \\n \\n \\n\\x0cSl. No. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\nDisposal \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\nFrom \\nwhom / \\nWhere \\nrecovered \\nor seized \\n\\n11. Particulars of accused person charge sheeted (Use separate sheet for each accused) 403 \\nSl. No: A-1 404 (i) Name: Mr. Sanjay Naik 405Whether Verified: Yes. 406 (ii) Father's Name: \\nArjun Naik 407 (iii) Date/Year of birth: 30 years 408 (iv) Sex: Male. 409 (v) Nationality: Indian \\n410 (vi) Passport No.: 411Date of issue: - 412Place of issue: 413 (vii) Religion: Hindu 414 (viii) \\nWhether SC/ST/OBC:-- (ix) Occupation: --- 415 (x) Address: H.No. 102 Indira Nagar \\nKaraswada Mapusa Bardez Goa. 416 (xi) Provisional criminal No. 417 (xii) Regular criminal \\nNo. (if Known)...-- (xiii) Date of arrest: ---. 418 (xiv) Date of release of the Accused: --- \\n(xv) Date on which forwarded to court:- 419 (xvi) Under Acts & Sections: U/s 376, 417 IPC. \\n420 (xvii) Details of bailers/sureties Name: 421Father's name:............ 422Occupation............... \\n423Address: 424Identification............... 425 (xvii) Previous convictions with case references... \\n426 (xix) Status of the accused: Granted Anticipatory Bail by Hon'ble Additional Sessions \\n427Judge Mapusa in Anticipatory Bail Application No. 186/2018 428Forwarded / Bailed by \\nPolice / Bailed by Court / Police Custody / Absconding 429/Without Arrest / Proclaimed \\noffender (tick 'v' applicable portion) 430Scanned with OKEN Scanner 431 \\n\\n--- PAGE 24 --- \\n\\n001. 432nd 433 12. Particulars of accused persons-not charge sheeted (suspect): (Use separate \\nsheet 434for each suspect) 435 Sl. No: NIL. 436 (i) Name:--- 437Whether verified: 438 (ii) \\nFather's/Husband's name: 439 (iii) Date/Year of birth: 440 (iv)Sex................... 441 (v) Nationality: -- \\n442 (vi) Passport No: 443Date of issue.................. 444Place of issue........... 445 (vii) Religion...--......... \\n446 (viii) Whether SC/ST/OBC....... 447 (ix) Occupation: 448 (x)Address....... 449Whether \\nverified............ 450 (xi) Provisional criminal No. 451 (xii) Suspicion Approved: Yes/No. 452 (xiii) \\nStatus of the accused (suspect): 453Bailed by Police/Bailed by court/Judicial Custody/Not \\narrested 454 (tick'' applicable portion). 455 (xiv) Under Acts & Sections................ 456 (xv) Any \\nspecial remarks including reasons for not charge sheeting........ 457Sl. 458No 459 1. Part<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:27:58 [engine.py:317] Added request chatcmpl-674c4473b3184045a3358b1e4bf2eec7.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_32.txt...vLLM STDOUT: INFO:     127.0.0.1:53584 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:28:02 [logger.py:43] Received request chatcmpl-97b42b322f6e4676a1616c3bd5a75397: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n.: Shri \\nYogendra S. Garodi Rank: Police Sub Inspector No: --- (at the time of charge sheet). \\n398Scanned with OKEN Scanner 399 \\n\\n--- PAGE 23 --- \\n\\n9.  (a) Name of Complainant/informant : Miss. Jagruti Rokde 400 (b) Father\\'s Name/address: \\nVithal Rokde R/o C/o Mrs. Emeliana Pereira, Flat No. 001. Damodar Apartments, Aradi \\nWaddo, Guirim Bardez Goa, N/o D46, Labour Camp, Anand Nagar, Dr. Ambedkar Road, \\nDharavi Mumbai 90. 401 10. Details of properties/Articles/Documents recovered/Seized \\nduring investigation and relied Upon (Separate list can be attached, if necessary). 402 \\n\\n \\n \\n \\n\\x0cSl. No. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\nDisposal \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\nFrom \\nwhom / \\nWhere \\nrecovered \\nor seized<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:28:02 [engine.py:317] Added request chatcmpl-97b42b322f6e4676a1616c3bd5a75397.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_32.txt...vLLM STDOUT: INFO:     127.0.0.1:53592 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:28:18 [logger.py:43] Received request chatcmpl-aa0c21b910b44dfb8cc3fbe265dce7d0: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue (Rs.) \\n\\nDisposal \\n\\nP.S. \\nProperty \\nRegister \\nNo. \\n\\nFrom \\nwhom / \\nWhere \\nrecovered \\nor seized \\n\\n11. Particulars of accused person charge sheeted (Use separate sheet for each accused) 403 \\nSl. No: A-1 404 (i) Name: Mr. Sanjay Naik 405Whether Verified: Yes. 406 (ii) Father\\'s Name: \\nArjun Naik 407 (iii) Date/Year of birth: 30 years 408 (iv) Sex: Male. 409 (v) Nationality: Indian \\n410 (vi) Passport No.: 411Date of issue: - 412Place of issue: 413 (vii) Religion: Hindu 414 (viii) \\nWhether SC/ST/OBC:-- (ix) Occupation: --- 415 (x) Address: H.No. 102 Indira Nagar \\nKaraswada Mapusa Bardez Goa. 416 (xi) Provisional criminal No. 417 (xii) Regular criminal \\nNo. (if Known)...-- (xiii) Date of arrest: ---. 418 (xiv) Date of release of the Accused: --- \\n(xv) Date on which forwarded to court:- 419 (xvi) Under Acts & Sections: U/s 376, 417 IPC. \\n420 (xvii) Details of bailers/sureties Name: 421Father\\'s name:............ 422Occupation............... \\n423Address: 424Identification............... 425 (xvii) Previous convictions with case references... \\n426 (xix) Status of the accused: Granted Anticipatory Bail by Hon\\'ble Additional Sessions \\n427Judge Mapusa in Anticipatory Bail Application No. 186/2018 428Forwarded / Bailed by \\nPolice / Bailed by Court / Police Custody / Absconding 429/Without Arrest / Proclaimed \\noffender (tick \\'v\\' applicable portion) 430Scanned with OKEN Scanner 431<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:28:18 [engine.py:317] Added request chatcmpl-aa0c21b910b44dfb8cc3fbe265dce7d0.\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/output2/ilovepdf_merged_32.txt...vLLM STDOUT: INFO:     127.0.0.1:42210 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:28:33 [logger.py:43] Received request chatcmpl-b504712c5c8c43399dbb2b01db1721c0: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n425 (xvii) Previous convictions with case references... \\n426 (xix) Status of the accused: Granted Anticipatory Bail by Hon\\'ble Additional Sessions \\n427Judge Mapusa in Anticipatory Bail Application No. 186/2018 428Forwarded / Bailed by \\nPolice / Bailed by Court / Police Custody / Absconding 429/Without Arrest / Proclaimed \\noffender (tick \\'v\\' applicable portion) 430Scanned with OKEN Scanner 431 \\n\\n--- PAGE 24 ---<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:28:33 [engine.py:317] Added request chatcmpl-b504712c5c8c43399dbb2b01db1721c0.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_32.txt...vLLM STDOUT: INFO:     127.0.0.1:54450 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_32.txt...vLLM STDOUT: INFO 12-14 05:28:48 [logger.py:43] Received request chatcmpl-8572c8afe39f4d6aa7fa370918325b07: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n001. 432nd 433 12. Particulars of accused persons-not charge sheeted (suspect): (Use separate \\nsheet 434for each suspect) 435 Sl. No: NIL. 436 (i) Name:--- 437Whether verified: 438 (ii) \\nFather\\'s/Husband\\'s name: 439 (iii) Date/Year of birth: 440 (iv)Sex................... 441 (v) Nationality: -- \\n442 (vi) Passport No: 443Date of issue.................. 444Place of issue........... 445 (vii) Religion...--......... \\n446 (viii) Whether SC/ST/OBC....... 447 (ix) Occupation: 448 (x)Address....... 449Whether \\nverified............ 450 (xi) Provisional criminal No. 451 (xii) Suspicion Approved: Yes/No. 452 (xiii) \\nStatus of the accused (suspect): 453Bailed by Police/Bailed by court/Judicial Custody/Not \\narrested 454 (tick\\'\\' applicable portion). 455 (xiv) Under Acts & Sections................ 456 (xv) Any \\nspecial remarks including reasons for not charge sheeting........ 457Sl. 458No 459 1. Part<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:28:48 [engine.py:317] Added request chatcmpl-8572c8afe39f4d6aa7fa370918325b07.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_32.txt...vLLM STDOUT: INFO:     127.0.0.1:41122 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 57 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_32_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_32_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_32.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_32_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:57138 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:57154 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:29:06 [logger.py:43] Received request chatcmpl-4f6983618b7f4a65bde62fded1f83b80: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nailed by court/Judicial Custody/Not \\narrested 454 (tick'' applicable portion). 455 (xiv) Under Acts & Sections................ 456 (xv) Any \\nspecial remarks including reasons for not charge sheeting........ 457Sl. 458No 459 1. Particulars of \\nwitnesses to be examined: 460Name 461Father's/ 462Husband's 463Name 464Date/ 465Year 466of \\n467birth 468Occupation 469Address 470Type of 471Evidence 472to be 473rendered 4741 4753 4762 4774 \\n4785 4796 4807 481 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cSr. No. \\n\\nName \\n\\nFather's/ \\nHusband\\n's Name \\n\\nDate/ \\nYear of \\nbirth \\n\\nOccupat\\nion \\n\\nAddress \\n\\nType of \\nEvidence \\nto be \\nrendered \\n\\nComplain\\nant \\n\\nPanch \\n\\nVithal \\nRokde \\n\\n22 yrs \\n\\nService \\n\\nMiss. \\nJagruti \\nRokde \\n74482196\\n62 \\n\\nMr. \\nSantosh \\nRaikar \\n\\nKalidas \\nRaikar \\n\\n33 yrs \\n\\nBusiness \\n\\nC/o Mrs. \\nEmeliana \\nPereira, \\nFlat No. \\n001. \\nDamodar \\nApartme\\nnts, Aradi \\nWaddo, \\nGuirim \\nBardez \\nGoa, N/o \\nD46, \\nLabour \\nCamp, \\nAnand \\nNagar, Dr. \\nAmbedka\\nr Road, \\nDharavi \\nMumbai \\n90. \\n\\nH.No. 09, \\nDeulwad\\na, Near \\nKalika \\nMandir, \\nKasarpal, \\nLatambar\\ncem, \\nNorh \\nGoa, Goa \\n\\nMrs. \\nPooja \\n\\nSatish \\nArabekar \\n\\n39 Years \\n\\nBusiness \\n\\nH.No. \\n530 P20, \\n\\nPanch \\n\\n1 \\n\\n2 \\n\\n3 \\n\\n\\x0cArabekar \\n\\n4 \\n\\nShri. \\nRudan \\nKundaike\\nr \\n\\nDattu \\nKundaike\\nr \\n\\n23 yrs \\n\\nService \\n\\nWitness \\n\\nVerem \\nRais \\nMagos \\nBardez \\nGoa \\n\\nH.No. \\nUD-6, \\nUttam \\nDarshan, \\nKadamba \\nBy-pass \\nRoad, \\nNear \\nSaiBaba \\ntemple, \\nChimbel \\nRibandar \\nTsiwadi \\nGoa \\n\\nScanned with OKEN Scanner 482 \\n\\n--- PAGE 25 --- \\n\\nScanned with OKEN Scanner 483 \\n\\nSr. No. \\n\\nName \\n\\nFather's/ \\nHusband\\n's Name \\n\\nDate/ \\nYear of \\nbirth \\n\\nOccupat\\nion \\n\\nAddress \\n\\n5 \\n\\nMiss. \\nArchana \\nArondeka\\nr \\n\\nRavindra \\nArondeka\\nr \\n\\n21 years \\n\\nService \\n\\nH.No. \\n217/C/4, \\nBilwan \\nWaddo, \\nPeddem \\nMapusa \\nBardez \\n\\nType of \\nEvidence \\nto be \\nrendered \\n\\nWitness \\n\\n \\n \\n\\x0c6 \\n\\n7 \\n\\nShri. \\nVithal \\nRokde \\n\\nMurlidhar \\nRokde \\n\\n48 years \\n\\nBusiness \\n\\nMrs. \\nMangal \\nRokde \\n\\nVithal \\nRokde \\nmothe \\n\\n42 yrs \\n\\nHouse \\nWife \\n\\n8 \\n\\nMr. Jay \\nRokde \\n\\nVithal \\nRokde \\nMothe \\n\\n19 Years \\n\\nStudent \\n\\nWitness \\n\\nWitness \\n\\nWitness \\n\\nGoa \\n\\nD46, \\nLabour \\nCamp, \\nAnand \\nNagar, Dr. \\nAmbedka\\nr Road, \\nDharavi \\nMumbai \\n90. \\n\\nC/o Mrs. \\nEmeliana \\nPereira, \\nFlat No. \\n001. \\nDamodar \\nApartme\\nnts, Aradi \\nWaddo, \\nGuirim \\nBardez \\nGoa, N/o \\nD46, \\nLabour \\nCamp, \\nAnand \\nNagar, Dr. \\nAmbedka\\nr Road, \\nDharavi \\nMumbai \\n90. \\n\\nD46, \\nLabour \\nCamp, \\nAnand \\nNagar, Dr. \\n\\n\\x0c9 \\n\\n10 \\n\\n11 \\n\\n12<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:29:06 [engine.py:317] Added request chatcmpl-4f6983618b7f4a65bde62fded1f83b80.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_33.txt...vLLM STDOUT: INFO:     127.0.0.1:57156 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:29:10 [logger.py:43] Received request chatcmpl-352623b7dfb342ea88178ccc65634e66: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nailed by court/Judicial Custody/Not \\narrested 454 (tick\\'\\' applicable portion). 455 (xiv) Under Acts & Sections................ 456 (xv) Any \\nspecial remarks including reasons for not charge sheeting........ 457Sl. 458No 459 1. Particulars of \\nwitnesses to be examined: 460Name 461Father\\'s/ 462Husband\\'s 463Name 464Date/ 465Year 466of \\n467birth 468Occupation 469Address 470Type of 471Evidence 472to be 473rendered 4741 4753 4762 4774 \\n4785 4796 4807 481 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cSr. No. \\n\\nName \\n\\nFather\\'s/ \\nHusband\\n\\'s Name \\n\\nDate/ \\nYear of \\nbirth \\n\\nOccupat\\nion \\n\\nAddress \\n\\nType of \\nEvidence \\nto be \\nrendered \\n\\nComplain\\nant \\n\\nPanch \\n\\nVithal \\nRokde \\n\\n22 yrs \\n\\nService \\n\\nMiss. \\nJagruti \\nRokde \\n74482196\\n62 \\n\\nMr. \\nSantosh \\nRaikar \\n\\nKalidas \\nRaikar \\n\\n33 yrs \\n\\nBusiness \\n\\nC/o Mrs. \\nEmeliana \\nPereira, \\nFlat No. \\n001. \\nDamodar \\nApartme\\nnts, Aradi \\nWaddo, \\nGuirim \\nBardez \\nGoa, N/o \\nD46, \\nLabour \\nCamp, \\nAnand \\nNagar, Dr. \\nAmbedka\\nr Road, \\nDharavi \\nMumbai \\n90.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:29:10 [engine.py:317] Added request chatcmpl-352623b7dfb342ea88178ccc65634e66.\n",
            "\u001b[2KProcessing 3 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_33.txt...vLLM STDOUT: INFO:     127.0.0.1:43476 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:29:25 [logger.py:43] Received request chatcmpl-48ef5251e6b5461e8ec580bd43305cca: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\nDamodar \\nApartme\\nnts, Aradi \\nWaddo, \\nGuirim \\nBardez \\nGoa, N/o \\nD46, \\nLabour \\nCamp, \\nAnand \\nNagar, Dr. \\nAmbedka\\nr Road, \\nDharavi \\nMumbai \\n90. \\n\\nH.No. 09, \\nDeulwad\\na, Near \\nKalika \\nMandir, \\nKasarpal, \\nLatambar\\ncem, \\nNorh \\nGoa, Goa \\n\\nMrs. \\nPooja \\n\\nSatish \\nArabekar \\n\\n39 Years \\n\\nBusiness \\n\\nH.No. \\n530 P20, \\n\\nPanch \\n\\n1 \\n\\n2 \\n\\n3 \\n\\n\\x0cArabekar \\n\\n4 \\n\\nShri. \\nRudan \\nKundaike\\nr \\n\\nDattu \\nKundaike\\nr \\n\\n23 yrs \\n\\nService \\n\\nWitness \\n\\nVerem \\nRais \\nMagos \\nBardez \\nGoa \\n\\nH.No. \\nUD-6, \\nUttam \\nDarshan, \\nKadamba \\nBy-pass \\nRoad, \\nNear \\nSaiBaba \\ntemple, \\nChimbel \\nRibandar \\nTsiwadi \\nGoa \\n\\nScanned with OKEN Scanner 482 \\n\\n--- PAGE 25 --- \\n\\nScanned with OKEN Scanner 483 \\n\\nSr. No. \\n\\nName \\n\\nFather\\'s/ \\nHusband\\n\\'s Name \\n\\nDate/ \\nYear of \\nbirth \\n\\nOccupat\\nion \\n\\nAddress \\n\\n5 \\n\\nMiss. \\nArchana \\nArondeka\\nr \\n\\nRavindra \\nArondeka\\nr \\n\\n21 years \\n\\nService \\n\\nH.No. \\n217/C/4, \\nBilwan \\nWaddo, \\nPeddem \\nMapusa \\nBardez \\n\\nType of \\nEvidence \\nto be \\nrendered \\n\\nWitness \\n\\n \\n \\n\\x0c6 \\n\\n7 \\n\\nShri. \\nVithal \\nRokde \\n\\nMurlidhar \\nRokde \\n\\n48 years \\n\\nBusiness \\n\\nMrs. \\nMangal \\nRokde<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_33.txt...vLLM STDOUT: INFO 12-14 05:29:25 [engine.py:317] Added request chatcmpl-48ef5251e6b5461e8ec580bd43305cca.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_33.txt...vLLM STDOUT: INFO:     127.0.0.1:55220 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:29:41 [logger.py:43] Received request chatcmpl-268071ad4eba421f82220c942d73012b: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\n217/C/4, \\nBilwan \\nWaddo, \\nPeddem \\nMapusa \\nBardez \\n\\nType of \\nEvidence \\nto be \\nrendered \\n\\nWitness \\n\\n \\n \\n\\x0c6 \\n\\n7 \\n\\nShri. \\nVithal \\nRokde \\n\\nMurlidhar \\nRokde \\n\\n48 years \\n\\nBusiness \\n\\nMrs. \\nMangal \\nRokde \\n\\nVithal \\nRokde \\nmothe \\n\\n42 yrs \\n\\nHouse \\nWife \\n\\n8 \\n\\nMr. Jay \\nRokde \\n\\nVithal \\nRokde \\nMothe \\n\\n19 Years \\n\\nStudent \\n\\nWitness \\n\\nWitness \\n\\nWitness \\n\\nGoa \\n\\nD46, \\nLabour \\nCamp, \\nAnand \\nNagar, Dr. \\nAmbedka\\nr Road, \\nDharavi \\nMumbai \\n90. \\n\\nC/o Mrs. \\nEmeliana \\nPereira, \\nFlat No. \\n001. \\nDamodar \\nApartme\\nnts, Aradi \\nWaddo, \\nGuirim \\nBardez \\nGoa, N/o \\nD46, \\nLabour \\nCamp, \\nAnand \\nNagar, Dr. \\nAmbedka\\nr Road, \\nDharavi \\nMumbai \\n90. \\n\\nD46, \\nLabour \\nCamp, \\nAnand \\nNagar, Dr. \\n\\n\\x0c9 \\n\\n10 \\n\\n11 \\n\\n12<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:29:41 [engine.py:317] Added request chatcmpl-268071ad4eba421f82220c942d73012b.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_33.txt...vLLM STDOUT: INFO:     127.0.0.1:57658 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 41 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_33_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_33_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_33.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_33_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:56240 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:56252 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:29:59 [logger.py:43] Received request chatcmpl-80a41cad3cad4bedb854671a00418f91: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n/o \\nD46, \\nLabour \\nCamp, \\nAnand \\nNagar, Dr. \\nAmbedka\\nr Road, \\nDharavi \\nMumbai \\n90. \\n\\nD46, \\nLabour \\nCamp, \\nAnand \\nNagar, Dr. \\n\\n\\x0c9 \\n\\n10 \\n\\n11 \\n\\n12 \\n\\n13 \\n\\nMrs. \\nPoonam \\nNeogi \\n\\nPushkar \\nNeogi \\n\\n36 yrs \\n\\nDoctor \\n\\nReina S \\nFernande\\ns \\n\\nS. \\nFernande\\ns \\n\\nMajor \\n\\nCivil \\nJudge, \\nJunior \\nDivision \\n& JMFC \\n\\'F\\' court \\n\\nMrs. Indu \\nNaik \\n\\nArjun \\nNaik \\n\\n58 Years \\n\\nHousewif\\ne \\n\\nMr. Anil \\nNaik \\n\\nArjun \\nNaik \\n\\n31Years \\n\\nService \\n\\nFlorence \\nMendes \\n\\nMajor \\n\\nNGO \\n\\nAmbedka\\nr Road, \\nDharavi \\nMumbai \\n90. \\n\\nC/o \\nBhagyod\\nay \\nHospital \\nDattawad\\ni, Mapusa \\nBardez \\nGoa \\n\\nJMFC \\nMapusa \\nBardez \\nGoa \\n\\nH.No. \\n102/3, \\nIndira \\nNagar \\nKaraswad\\na Bardez \\nGoa \\n\\nH.No. \\n102/3, \\nIndira \\nNagar \\nKaraswad\\na Bardez \\nGoa \\n\\nFMMMC\\nC, Moira \\nBardez \\n\\nWitness \\n\\nWitness \\n\\nWitness \\n\\nWitness \\n\\nWitness \\n\\n \\n\\x0c14 \\n\\nDr. Rini \\nNaik \\n\\nR. Naik \\n\\nMajor \\n\\nSenior \\nResident \\n\\nWitness \\n\\nGoa \\n\\nGMC \\nBamboli\\nm Dept. \\nof \\nObstetric\\ns & \\nGynecolo\\ngy \\n\\n15 \\n\\n16 \\n\\n17 \\n\\nDr. Clare \\nD\\'Mello \\n\\nS. \\nD\\'Mello \\n\\nMajor \\n\\nDoctor \\nGMC \\n\\nBamboli\\nm Goa \\n\\nWitness \\n\\nP. Kantak \\n\\nMajor \\n\\nDr. \\nMandar \\nKantak \\n\\nMedical \\nOfficer \\nAssistant \\nProfessor \\n\\nS. Garodi  Major \\n\\nShri \\nYogendra \\nGarodi \\n\\nPolice \\nsub \\nInspector \\n\\nWitness \\n\\nI.O. \\n\\nBlood \\nBank \\nGMC & \\nForensic \\nMedicine \\n& \\nToxicolog\\ny Goa \\nMedical \\nCollege \\n\\nMapusa \\nPolice \\nStation, \\nMapusa \\nBardez \\nGoa \\n\\n--- PAGE 26 --- \\n\\n\"ANNEXURE A\" 484Brief fact of the case: 485MAY IT PLEASE YOUR HONOUR 486In the limits of \\nyour Hon\\'ble Court and within the jurisdiction of Mapusa Police Station that on 14.05.2018 at \\n14.00 hrs an offence vide Mapusa P. S. Cr. 487No. 154/2018 U/s 376 IPC registered upon the \\ncomplaint of Miss. Jagruti D/o Vithal Rokde R/o C/o Mrs. Emeliana Pereira, Flat No. 001. \\nDamodar Apartments, Aradi Waddo, Guirim Bardez Goa, N/o D46, Labour Camp, Anand Nagar, \\nDr. Ambedkar Road, Dharavi Mumbai 90 to the effect that between October 2017 to \\n22.04.2018 TNK at Guirim Bardez Goa the accused shown in Column No. 11 at Serial No. A-1, \\n\\n\\x0cunder the false pretext of marriage had forcible sexual intercourse with the complainant on \\nmany occasion. 488During the course of investigation prepared FIR copies and submitted to \\nHon\\'ble Court and concerned superiors. 489During the course of investigation the \\nComplainant/victim was medically examined at GMC Bambolim by Senior Resident Doctor, \\nDept. of Obstetrics & Gynecology. 490Further necessary,materials were preserved and blood \\ngrouping of the victim was done during Medical examination, The report of Medical \\nexamination in sexual offences for female of the victim obtained after medical examination \\nvide No. GMC/OBG/So/F/58/2018 revealed evidence of Vaginal penetration, the reports are \\nappended to the case papers. 491During the course of investigation visited the scene of \\noffence and conducted the scene panchanama in presence of two pancha\\'s<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:29:59 [engine.py:317] Added request chatcmpl-80a41cad3cad4bedb854671a00418f91.\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/output2/ilovepdf_merged_34.txt...vLLM STDOUT: INFO:     127.0.0.1:56256 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KProcessing 3 chunks to generate QA pairs...\n",
            "\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_34.txt...vLLM STDOUT: INFO 12-14 05:30:04 [logger.py:43] Received request chatcmpl-80f4ef18f4f1493b9c3270ecb87b03e7: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n/o \\nD46, \\nLabour \\nCamp, \\nAnand \\nNagar, Dr. \\nAmbedka\\nr Road, \\nDharavi \\nMumbai \\n90. \\n\\nD46, \\nLabour \\nCamp, \\nAnand \\nNagar, Dr. \\n\\n\\x0c9 \\n\\n10 \\n\\n11 \\n\\n12 \\n\\n13 \\n\\nMrs. \\nPoonam \\nNeogi \\n\\nPushkar \\nNeogi \\n\\n36 yrs \\n\\nDoctor \\n\\nReina S \\nFernande\\ns \\n\\nS. \\nFernande\\ns \\n\\nMajor \\n\\nCivil \\nJudge, \\nJunior \\nDivision \\n& JMFC \\n\\'F\\' court \\n\\nMrs. Indu \\nNaik \\n\\nArjun \\nNaik \\n\\n58 Years \\n\\nHousewif\\ne \\n\\nMr. Anil \\nNaik \\n\\nArjun \\nNaik \\n\\n31Years \\n\\nService \\n\\nFlorence \\nMendes \\n\\nMajor \\n\\nNGO \\n\\nAmbedka\\nr Road, \\nDharavi \\nMumbai \\n90. \\n\\nC/o \\nBhagyod\\nay \\nHospital \\nDattawad\\ni, Mapusa \\nBardez \\nGoa \\n\\nJMFC \\nMapusa \\nBardez \\nGoa \\n\\nH.No. \\n102/3, \\nIndira \\nNagar \\nKaraswad\\na Bardez \\nGoa \\n\\nH.No. \\n102/3, \\nIndira \\nNagar \\nKaraswad\\na Bardez \\nGoa \\n\\nFMMMC\\nC, Moira \\nBardez \\n\\nWitness \\n\\nWitness \\n\\nWitness \\n\\nWitness \\n\\nWitness \\n\\n \\n\\x0c14 \\n\\nDr. Rini \\nNaik \\n\\nR. Naik \\n\\nMajor \\n\\nSenior \\nResident \\n\\nWitness \\n\\nGoa \\n\\nGMC \\nBamboli\\nm Dept. \\nof \\nObstetric\\ns & \\nGynecolo\\ngy \\n\\n15 \\n\\n16 \\n\\n17 \\n\\nDr. Clare \\nD\\'Mello \\n\\nS. \\nD\\'Mello \\n\\nMajor \\n\\nDoctor \\nGMC \\n\\nBamboli\\nm Goa \\n\\nWitness \\n\\nP. Kantak \\n\\nMajor<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:30:04 [engine.py:317] Added request chatcmpl-80f4ef18f4f1493b9c3270ecb87b03e7.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_34.txt...vLLM STDOUT: INFO:     127.0.0.1:56266 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_34.txt...vLLM STDOUT: INFO 12-14 05:30:20 [logger.py:43] Received request chatcmpl-0eb174612c1243e7a2353359a56bb271: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nClare \\nD\\'Mello \\n\\nS. \\nD\\'Mello \\n\\nMajor \\n\\nDoctor \\nGMC \\n\\nBamboli\\nm Goa \\n\\nWitness \\n\\nP. Kantak \\n\\nMajor \\n\\nDr. \\nMandar \\nKantak \\n\\nMedical \\nOfficer \\nAssistant \\nProfessor \\n\\nS. Garodi  Major \\n\\nShri \\nYogendra \\nGarodi \\n\\nPolice \\nsub \\nInspector \\n\\nWitness \\n\\nI.O. \\n\\nBlood \\nBank \\nGMC & \\nForensic \\nMedicine \\n& \\nToxicolog\\ny Goa \\nMedical \\nCollege \\n\\nMapusa \\nPolice \\nStation, \\nMapusa \\nBardez \\nGoa \\n\\n--- PAGE 26 --- \\n\\n\"ANNEXURE A\" 484Brief fact of the case: 485MAY IT PLEASE YOUR HONOUR 486In the limits of \\nyour Hon\\'ble Court and within the jurisdiction of Mapusa Police Station that on 14.05.2018 at \\n14.00 hrs an offence vide Mapusa P. S. Cr. 487No. 154/2018 U/s 376 IPC registered upon the \\ncomplaint of Miss. Jagruti D/o Vithal Rokde R/o C/o Mrs. Emeliana Pereira, Flat No. 001. \\nDamodar Apartments, Aradi Waddo, Guirim Bardez Goa, N/o D46, Labour Camp, Anand Nagar, \\nDr. Ambedkar Road, Dharavi Mumbai 90 to the effect that between October 2017 to \\n22.04.2018 TNK at Guirim Bardez Goa the accused shown in Column No. 11 at Serial No. A-1,<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:30:20 [engine.py:317] Added request chatcmpl-0eb174612c1243e7a2353359a56bb271.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_34.txt...vLLM STDOUT: INFO:     127.0.0.1:57040 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:30:35 [logger.py:43] Received request chatcmpl-7e77bf3d2240483d977a3237fdd3a4aa: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nAmbedkar Road, Dharavi Mumbai 90 to the effect that between October 2017 to \\n22.04.2018 TNK at Guirim Bardez Goa the accused shown in Column No. 11 at Serial No. A-1, \\n\\n\\x0cunder the false pretext of marriage had forcible sexual intercourse with the complainant on \\nmany occasion. 488During the course of investigation prepared FIR copies and submitted to \\nHon\\'ble Court and concerned superiors. 489During the course of investigation the \\nComplainant/victim was medically examined at GMC Bambolim by Senior Resident Doctor, \\nDept. of Obstetrics & Gynecology. 490Further necessary,materials were preserved and blood \\ngrouping of the victim was done during Medical examination, The report of Medical \\nexamination in sexual offences for female of the victim obtained after medical examination \\nvide No. GMC/OBG/So/F/58/2018 revealed evidence of Vaginal penetration, the reports are \\nappended to the case papers. 491During the course of investigation visited the scene of \\noffence and conducted the scene panchanama in presence of two pancha\\'s<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:30:35 [engine.py:317] Added request chatcmpl-7e77bf3d2240483d977a3237fdd3a4aa.\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_34.txt...vLLM STDOUT: INFO:     127.0.0.1:50836 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 49 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_34_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_34_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_34.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_34_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:41300 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:41310 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:30:53 [logger.py:43] Received request chatcmpl-e754f5bb92d24df4a28e723954b37054: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nvide No. GMC/OBG/So/F/58/2018 revealed evidence of Vaginal penetration, the reports are \\nappended to the case papers. 491During the course of investigation visited the scene of \\noffence and conducted the scene panchanama in presence of two pancha's namely Mr. \\nSantosh S/o Kalidas Raikar R/o Near Kalika Mandir, Kasarpal, Latambarcem, North Goa Goa \\nand Mrs. Pooja W/o Satish Arabekar R/po H.No. 492 530 P20, Verem Rais Magos Bardez Goa. \\nAlso recodred the supplementary statement of the victim same is appended to the case \\npaper's. 493During the course of investigation recorded the statements of the witnesses \\nnamely Shri. 494Rudan S/o Dattu Kundaikar R/o UD-6, Uttam Darshan, Kadamba By-Pass Road, \\nNear Sai Baba Temple Chimbel Ribandar Tiswadi Goa, Miss. Archana D/o Ravindra Arondekar \\nR/o 217/C/4 Bilwan Waddo, Peddem Mapusa Bardez Goa which reveals that the accused \\nperson was in relationship with the complainant the statements are appended to the case \\npapers. 495Further during the course of the investigation the statements of the family \\nmembers of the Victim was recorded namely Mr. Vithal S/o Murlidhar Rokde, Mrs. Mangal W/o \\nVithal Rokde, Mr. Jay S/o Vithal Rokde All R/o C/o Mrs. Emeliana Pereira, Flat No. 001. Damodar \\nApartments, Aradi Waddo, Guirim Bardez Goa, N/o D46, Labour Camp, Anand Nagar, Dr. \\nAmbedkar Road, Dharavi Mumbai 90, which revealed that the accused person was in \\nrelationship with the complainant and that he would get married to the complainant after \\nDiwali 2018,the above statements are appended to the case papers. 496Further During the \\nCourse of investigation recorded the statement of Dr. Poonam Neugi C/o Bhagyoday Hospital \\nDattawadi, Mapusa. 497Bardez Goa, same is appended to the case papers. 498Further the \\nstatement of the victim was recorded as per the provision u/s 164 Cr.PC before the Hon'ble \\nJMFC F Court and same is appended to the case papers. 499During the Course of investigation \\nthe accused preferred Anticipatory bail and same was granted by the Hon'ble Additional \\nSession's Judge Mapusa Goa, Further the accused person was medically examined at GMC \\nBambolim for sexual offences by police surgeon Further necessary, materials were preserved \\nand blood grouping of the victim was done during Medical examination, The report of Medical \\nexamination in sexual offences for Males 500Scanned with OKEN Scanner 501 \\n\\n--- PAGE 27 --- \\n\\nof the accused obtained after medical examination vide No. FM/GMC/So/M/48/2018, Blood \\ngroup report appended to the case papers. 502During the course of the investigation the \\ncomplainant was requested to furnish the copies of Medical papers pertaining to the \\ntreatment taken by her at neo Clinic or at Bhagyoday Hospital Dattawadi Mapusa Bardez Goa \\n\\n \\n\\x0cin regards to the medical termination of pregnancy/ abortion of Child/ regularization of \\nMenstrual Cycle, Copies of the Medical prescription prescribed by the doctor in respect to the \\nabove case. 503 and any other information in regards to the same. In reply the complainant \\nsubmitted colour printout copies of all the whatsapp chat screenshots from her mobile phone \\nfrom 22/04/2018 to 05/05/2018 between the complainant and the accused, coloured copies \\nof the photographs of complainant and the accused person, One Compact Disc containing all \\nthe photos and whatsapp chat screenshot and videos of complainant and the accused \\nperson. 504Invoice copy of a finger ring purchased by the complainant to gift Mr. Sanjay Naik \\nduring their engagement. 505however the complainant stated that she will submit the original \\ninvoice and the phone containing the above evidence as and when directed by<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:30:53 [engine.py:317] Added request chatcmpl-e754f5bb92d24df4a28e723954b37054.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_35.txt...vLLM STDOUT: INFO:     127.0.0.1:41314 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:30:57 [logger.py:43] Received request chatcmpl-06c1670dc2844ad7b0d5358878f07d1f: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n \\nvide No. GMC/OBG/So/F/58/2018 revealed evidence of Vaginal penetration, the reports are \\nappended to the case papers. 491During the course of investigation visited the scene of \\noffence and conducted the scene panchanama in presence of two pancha\\'s namely Mr. \\nSantosh S/o Kalidas Raikar R/o Near Kalika Mandir, Kasarpal, Latambarcem, North Goa Goa \\nand Mrs. Pooja W/o Satish Arabekar R/po H.No. 492 530 P20, Verem Rais Magos Bardez Goa. \\nAlso recodred the supplementary statement of the victim same is appended to the case \\npaper\\'s. 493During the course of investigation recorded the statements of the witnesses \\nnamely Shri. 494Rudan S/o Dattu Kundaikar R/o UD-6, Uttam Darshan, Kadamba By-Pass Road, \\nNear Sai Baba Temple Chimbel Ribandar Tiswadi Goa, Miss. Archana D/o Ravindra Arondekar \\nR/o 217/C/4 Bilwan Waddo, Peddem Mapusa Bardez Goa which reveals that the accused \\nperson was in relationship with the complainant the statements are appended to the case \\npapers. 495Further during the course of the investigation the statements of the family \\nmembers of the Victim was recorded namely Mr. Vithal S/o Murlidhar Rokde, Mrs. Mangal W/o \\nVithal Rokde, Mr. Jay S/o Vithal Rokde All R/o C/o Mrs. Emeliana Pereira, Flat No. 001. Damodar \\nApartments, Aradi Waddo, Guirim Bardez Goa, N/o D46, Labour Camp, Anand Nagar, Dr. \\nAmbedkar Road, Dharavi Mumbai 90, which revealed that the accused person was in \\nrelationship with the complainant and that he would get married to the complainant after \\nDiwali 2018,the above statements are appended to the case papers. 496Further During the \\nCourse of investigation recorded the statement of Dr. Poonam Neugi C/o Bhagyoday Hospital \\nDattawadi, Mapusa. 497Bardez Goa, same is appended to the case papers. 498Further the \\nstatement of the victim was recorded as per the provision u/s 164 Cr.PC before the Hon\\'ble \\nJMFC F Court and same is appended to the case papers. 499During the Course of investigation \\nthe accused preferred Anticipatory bail and same was granted by the Hon\\'ble Additional \\nSession\\'s Judge Mapusa Goa, Further the accused person was medically examined at GMC \\nBambolim for sexual offences by police surgeon Further necessary, materials were preserved \\nand blood grouping of the victim was done during Medical examination, The report of Medical \\nexamination in sexual offences for Males 500Scanned with OKEN Scanner 501<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:30:57 [engine.py:317] Added request chatcmpl-06c1670dc2844ad7b0d5358878f07d1f.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_35.txt...vLLM STDOUT: INFO:     127.0.0.1:60624 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:31:13 [logger.py:43] Received request chatcmpl-799e772257b94155a07b643111e797e9: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n497Bardez Goa, same is appended to the case papers. 498Further the \\nstatement of the victim was recorded as per the provision u/s 164 Cr.PC before the Hon\\'ble \\nJMFC F Court and same is appended to the case papers. 499During the Course of investigation \\nthe accused preferred Anticipatory bail and same was granted by the Hon\\'ble Additional \\nSession\\'s Judge Mapusa Goa, Further the accused person was medically examined at GMC \\nBambolim for sexual offences by police surgeon Further necessary, materials were preserved \\nand blood grouping of the victim was done during Medical examination, The report of Medical \\nexamination in sexual offences for Males 500Scanned with OKEN Scanner 501 \\n\\n--- PAGE 27 ---<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:31:13 [engine.py:317] Added request chatcmpl-799e772257b94155a07b643111e797e9.\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_35.txt...vLLM STDOUT: INFO:     127.0.0.1:47654 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:31:29 [logger.py:43] Received request chatcmpl-1d505d79461d4bad96f91ebc703fb208: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nof the accused obtained after medical examination vide No. FM/GMC/So/M/48/2018, Blood \\ngroup report appended to the case papers. 502During the course of the investigation the \\ncomplainant was requested to furnish the copies of Medical papers pertaining to the \\ntreatment taken by her at neo Clinic or at Bhagyoday Hospital Dattawadi Mapusa Bardez Goa<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:31:29 [engine.py:317] Added request chatcmpl-1d505d79461d4bad96f91ebc703fb208.\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_35.txt...vLLM STDOUT: INFO:     127.0.0.1:43924 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:31:44 [logger.py:43] Received request chatcmpl-9da46d4a399443af8cd2bd7030ecd2f3: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n \\n\\x0cin regards to the medical termination of pregnancy/ abortion of Child/ regularization of \\nMenstrual Cycle, Copies of the Medical prescription prescribed by the doctor in respect to the \\nabove case. 503 and any other information in regards to the same. In reply the complainant \\nsubmitted colour printout copies of all the whatsapp chat screenshots from her mobile phone \\nfrom 22/04/2018 to 05/05/2018 between the complainant and the accused, coloured copies \\nof the photographs of complainant and the accused person, One Compact Disc containing all \\nthe photos and whatsapp chat screenshot and videos of complainant and the accused \\nperson. 504Invoice copy of a finger ring purchased by the complainant to gift Mr. Sanjay Naik \\nduring their engagement. 505however the complainant stated that she will submit the original \\ninvoice and the phone containing the above evidence as and when directed by<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:31:44 [engine.py:317] Added request chatcmpl-9da46d4a399443af8cd2bd7030ecd2f3.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_35.txt...vLLM STDOUT: INFO:     127.0.0.1:51178 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 63 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_35_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_35_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/output2/ilovepdf_merged_35.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_35_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:54986 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:54990 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:32:02 [logger.py:43] Received request chatcmpl-cd0530d174ec41a9b8b08f064011c928: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nand videos of complainant and the accused \\nperson. 504Invoice copy of a finger ring purchased by the complainant to gift Mr. Sanjay Naik \\nduring their engagement. 505however the complainant stated that she will submit the original \\ninvoice and the phone containing the above evidence as and when directed by the Hon'ble \\ncourt. 506During the course of investigation received wireless Message from casualty police \\nGMC Bambolim informing that the victim is admitted in ward no 106 as a case of poisoning \\naccordingly visited GMC Bambolim and recorded the statement of the Victim wherein it is \\nrevealed that the accused got married to another girl and due to which the victim went under \\ndepression and consumed home cleaning liquid to harm herself, the detail statement is \\nappended to the case papers. 507Further during the course of investigation recorded the \\nstatement of the mother and brother of the accused namely Mrs. Indu W/o Arjun Naik and Mr. \\nAnil S/o Arjun Naik both r/o Indira Nagar Karaswada Mapusa Bardez Goa, which revealed that \\nmarriage of the accused was fixed in the month of December 2017 to another girl, and as per \\nthe complainant the accused had last sexual intercourse with the complainant on 22/04/2018 \\nwhich is evident that the accused intentionally having full knowledge that his marriage was \\nfixed with another girl, had sexual intercourse with the complainant, accordingly section 417 \\nIPC was 508adduced to the above crime, the copy of the statements of the mother and the \\nbrother of the accused are appended to the case papers. 509During the course of \\ninvestigation moved request letter to obtain the Certified copies of the CAF forms, SDR of the \\ncontact numbers used by the of victim and the accused person to communicate, same are \\nawaited. 510During the course of investigation the material preserved of accused as well as \\nvictim during medical examination at GMC Bambolim were forwarded to Goa State Forensic \\nScience Laboratory, Verna for examination and report and same is awaited. 511From the so far \\nconducted Investigation it is evident that the accused shown in Column No. 11 at Serial No. A-1 \\nintentionally with full knowledge committed offence punishable under section 376, 417 IPC \\n512Hence Charge.. 513M 514 (Yogendra S. Garodi, PSI) 515Mapusa Police Station. 516Scanned with \\nOKEN Scanner 517 \\n\\n--- PAGE 28 --- \\n\\n[Signature] Forwarded by Officer in charge 518 14. If FIR is false, indicate action taken or \\nproposed to be taken u/s.182/211 I.P.C.:--- 519 15. Result of Laboratory analysis: 520As per \\nAnnexure A 521 16. Brief facts of the case (add separate sheet, if necessary). 522 17. Refer \\nNotice served: 523Yes/No 524Date: 525 (Acknowledgement to be placed) 526 18. Dispatched On: \\n527 19. No of enclosures: As per index. 528 20. List of enclosures: As annexed 529 Name: Shri. \\n\\n \\n\\x0cTushar G. Lotliker. 530Rank: Police Inspector. 531Mapusa Police Station 532Ph 533Signature of \\ninvestigating officer 534Submitting Final report/Charge Sheet 535Name: Yogendra S. Garodi. \\n536Rank: Police Sub Inspector. 537Mapusa Police Station. 538Note: More evidence will be addund \\nif found necessary. 539Scanned with OKEN Scanner 540 \\n\\n--- PAGE 29 --- \\n\\nScanned with OKEN Scanner 541] 542 Sp. Case No.34/2019 543PERNLHF 544 OW. 6472 545Date: \\n14/6/19 546FINAL FORM/REPORT 547 (Under section 173 Cr.P.C.) 548IN THE COURT OF \\nPRESIDENT CHILDREN COURT AT PANAJI 549 1. *Distt. NORTH-GOA. 550 *P.S. PERNEM POLICE \\nSTATION. 551Year 2019 552 * FIR No. 102/19 553 * Date:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:32:02 [engine.py:317] Added request chatcmpl-cd0530d174ec41a9b8b08f064011c928.\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_36.txt...vLLM STDOUT: INFO:     127.0.0.1:55000 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:32:06 [logger.py:43] Received request chatcmpl-55812b0c5523424e8d15acfd0ac0cd1b: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n and videos of complainant and the accused \\nperson. 504Invoice copy of a finger ring purchased by the complainant to gift Mr. Sanjay Naik \\nduring their engagement. 505however the complainant stated that she will submit the original \\ninvoice and the phone containing the above evidence as and when directed by the Hon\\'ble \\ncourt. 506During the course of investigation received wireless Message from casualty police \\nGMC Bambolim informing that the victim is admitted in ward no 106 as a case of poisoning \\naccordingly visited GMC Bambolim and recorded the statement of the Victim wherein it is \\nrevealed that the accused got married to another girl and due to which the victim went under \\ndepression and consumed home cleaning liquid to harm herself, the detail statement is \\nappended to the case papers. 507Further during the course of investigation recorded the \\nstatement of the mother and brother of the accused namely Mrs. Indu W/o Arjun Naik and Mr. \\nAnil S/o Arjun Naik both r/o Indira Nagar Karaswada Mapusa Bardez Goa, which revealed that \\nmarriage of the accused was fixed in the month of December 2017 to another girl, and as per \\nthe complainant the accused had last sexual intercourse with the complainant on 22/04/2018 \\nwhich is evident that the accused intentionally having full knowledge that his marriage was \\nfixed with another girl, had sexual intercourse with the complainant, accordingly section 417 \\nIPC was 508adduced to the above crime, the copy of the statements of the mother and the \\nbrother of the accused are appended to the case papers. 509During the course of \\ninvestigation moved request letter to obtain the Certified copies of the CAF forms, SDR of the \\ncontact numbers used by the of victim and the accused person to communicate, same are \\nawaited. 510During the course of investigation the material preserved of accused as well as \\nvictim during medical examination at GMC Bambolim were forwarded to Goa State Forensic \\nScience Laboratory, Verna for examination and report and same is awaited. 511From the so far \\nconducted Investigation it is evident that the accused shown in Column No. 11 at Serial No. A-1 \\nintentionally with full knowledge committed offence punishable under section 376, 417 IPC \\n512Hence Charge.. 513M 514 (Yogendra S. Garodi, PSI) 515Mapusa Police Station. 516Scanned with \\nOKEN Scanner 517<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2KProcessing 3 chunks to generate QA pairs...\n",
            "\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_36.txt...vLLM STDOUT: INFO 12-14 05:32:06 [engine.py:317] Added request chatcmpl-55812b0c5523424e8d15acfd0ac0cd1b.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_36.txt...vLLM STDOUT: INFO:     127.0.0.1:55004 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:32:22 [logger.py:43] Received request chatcmpl-22bd5cbb9fde4d23a9e4ba8859503ea3: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n513M 514 (Yogendra S. Garodi, PSI) 515Mapusa Police Station. 516Scanned with \\nOKEN Scanner 517 \\n\\n--- PAGE 28 --- \\n\\n[Signature] Forwarded by Officer in charge 518 14. If FIR is false, indicate action taken or \\nproposed to be taken u/s.182/211 I.P.C.:--- 519 15. Result of Laboratory analysis: 520As per \\nAnnexure A 521 16. Brief facts of the case (add separate sheet, if necessary). 522 17. Refer \\nNotice served: 523Yes/No 524Date: 525 (Acknowledgement to be placed) 526 18. Dispatched On: \\n527 19. No of enclosures: As per index. 528 20. List of enclosures: As annexed 529 Name: Shri. \\n\\n \\n\\x0cTushar G. Lotliker. 530Rank: Police Inspector. 531Mapusa Police Station 532Ph 533Signature of \\ninvestigating officer 534Submitting Final report/Charge Sheet 535Name: Yogendra S. Garodi. \\n536Rank: Police Sub Inspector. 537Mapusa Police Station. 538Note: More evidence will be addund \\nif found necessary. 539Scanned with OKEN Scanner 540 \\n\\n--- PAGE 29 ---<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:32:22 [engine.py:317] Added request chatcmpl-22bd5cbb9fde4d23a9e4ba8859503ea3.\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_36.txt...vLLM STDOUT: INFO:     127.0.0.1:54136 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:32:38 [logger.py:43] Received request chatcmpl-57a6bbe6ff7e42cba32341154bb55f86: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n537Mapusa Police Station. 538Note: More evidence will be addund \\nif found necessary. 539Scanned with OKEN Scanner 540 \\n\\n--- PAGE 29 --- \\n\\nScanned with OKEN Scanner 541] 542 Sp. Case No.34/2019 543PERNLHF 544 OW. 6472 545Date: \\n14/6/19 546FINAL FORM/REPORT 547 (Under section 173 Cr.P.C.) 548IN THE COURT OF \\nPRESIDENT CHILDREN COURT AT PANAJI 549 1. *Distt. NORTH-GOA. 550 *P.S. PERNEM POLICE \\nSTATION. 551Year 2019 552 * FIR No. 102/19 553 * Date:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_36.txt...vLLM STDOUT: INFO 12-14 05:32:38 [engine.py:317] Added request chatcmpl-57a6bbe6ff7e42cba32341154bb55f86.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_36.txt...vLLM STDOUT: INFO:     127.0.0.1:49452 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 46 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_36_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_36_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_36.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_36_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:48576 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:48584 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:32:56 [logger.py:43] Received request chatcmpl-2963b33c299044a79ba5d7374026a024: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTHE COURT OF \\nPRESIDENT CHILDREN COURT AT PANAJI 549 1. *Distt. NORTH-GOA. 550 *P.S. PERNEM POLICE \\nSTATION. 551Year 2019 552 * FIR No. 102/19 553 * Date: 06.05.2019 554 2. Charge Sheet No. 129/19. \\n555 * Date: 12/06/2019 5564. 557 (i)  Act: I.P.C 558 * Section:- 376 AB IPC 559 (ii) *Act:- POCSO Act \\n560 * Sections:- 4, 6, 8, 12 561 (iii) *Act :- Children Act 2003 562 * Sections:- 8 563 (iv)Other Acts & \\nSection: - - 5645 Type of Final Report: Charge sheet/Untraced/Unoccured/Not Charge sheeted \\nfor want of evidence 565Charge sheet. 566 6.*If F.I.R. Unoccured: False/Mistake of Fact/Mistake \\nof Law/Non- Cognizable/Civil Nature - 5677.*If supplementary or Original 568ORIGINAL 569 8. \\nName of the I.O. Alvito Rodrigues, 570 Rank. Police Sub Inspector, 571Pernem Police Station 572 9. \\n(a) Name of the complainant/Informant: Smt. Sanjana Naik r/o H. No. 16, Deulwada, Hankhane, \\nPernem Goa 573 (b) Father's/Husbands name 574: W/o Santosh Naik 575 \\n\\n--- PAGE 30 --- \\n\\nSr. No. \\n\\n1 \\n\\n1. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue \\n\\nP.S. \\nProperty \\nRegister \\n\\nDisposal \\n\\nFrom \\nwhom \\n/where \\nRecovered \\nor seized \\n\\n2 \\n\\n3 \\n\\n4 \\n\\n5 \\n\\n6 \\n\\n---NIL \\n\\n--2-- 576investigation and relied upon (Separate list can be attached, if necessary) 577 10. \\nDetails of Properties/Articles/Documents recovered/Seized during 578 11. Particulars of \\naccused person charge sheeted: 579 (Use separate sheet for each accused) 580Sl.No.A-1) * \\nName Shri Balkrishna Mapari 581Father's/Husband's Name:- S/o Ladu Mapari 582Whether \\nVerified: Yes 583 (ii) Date/Year of Birth :- 39 years (iv) Sex Male (v)Nationality:-Indian 584 (vi) \\nPassport No. Nil 585Date of Issue Place of Issue 586 (vii) Religion:-Hindu 587Whether SC/ST- \\n\\n \\n \\n \\n \\n \\n \\n\\x0cOccupation: - 588 (ix) Address:-R/o H. No. 14, Deulwada, Hankhane, Pernem Goa 589Whether \\nverified:- 590 (x) * Provisional Criminal No. A-1 591 (xi) *Regular Criminal No. 592(If known 593 (xii) \\nDate of Arrest:- On 06.05.2019 at 16.40 hrs 594 (xiii) *Date of release on bail: In Judicial \\nCustody 595*Date on which forwarded to court 596 (xii) *Under Acts & Sections:-376 AB IPC, 4, \\n6, 8 & 12 of POCOS Act 597 and Sec. 8 of Goa Children Act 598 (xiii) *Name (s) and Address (es) \\nof sureties: 599 (xiv) Previous convictions with case references: 600 (xv) Status of the accused; - \\nIn Judicial Custody 601Forwarded/Bailed by Police/Under Police Custody/Bailed by Court/In \\nJudicial 602Custody/ Absconding / Proclaimed Offender: 603 12. Particulars of accused person \\nnot charge sheeted (Suspect): (Use separate 604sheet for each 605suspect) :- NIL 606 Sl. No (i) \\nNames - 607whether verified...yes 608 (ii) Father<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:32:56 [engine.py:317] Added request chatcmpl-2963b33c299044a79ba5d7374026a024.\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output2/ilovepdf_merged_37.txt...vLLM STDOUT: INFO:     127.0.0.1:48598 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:33:02 [logger.py:43] Received request chatcmpl-8090e8c913644f65960a35b1f9f07928: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n THE COURT OF \\nPRESIDENT CHILDREN COURT AT PANAJI 549 1. *Distt. NORTH-GOA. 550 *P.S. PERNEM POLICE \\nSTATION. 551Year 2019 552 * FIR No. 102/19 553 * Date: 06.05.2019 554 2. Charge Sheet No. 129/19. \\n555 * Date: 12/06/2019 5564. 557 (i)  Act: I.P.C 558 * Section:- 376 AB IPC 559 (ii) *Act:- POCSO Act \\n560 * Sections:- 4, 6, 8, 12 561 (iii) *Act :- Children Act 2003 562 * Sections:- 8 563 (iv)Other Acts & \\nSection: - - 5645 Type of Final Report: Charge sheet/Untraced/Unoccured/Not Charge sheeted \\nfor want of evidence 565Charge sheet. 566 6.*If F.I.R. Unoccured: False/Mistake of Fact/Mistake \\nof Law/Non- Cognizable/Civil Nature - 5677.*If supplementary or Original 568ORIGINAL 569 8. \\nName of the I.O. Alvito Rodrigues, 570 Rank. Police Sub Inspector, 571Pernem Police Station 572 9. \\n(a) Name of the complainant/Informant: Smt. Sanjana Naik r/o H. No. 16, Deulwada, Hankhane, \\nPernem Goa 573 (b) Father\\'s/Husbands name 574: W/o Santosh Naik 575 \\n\\n--- PAGE 30 --- \\n\\nSr. No. \\n\\n1 \\n\\n1. \\n\\nProperty \\nDescriptio\\nn<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:33:02 [engine.py:317] Added request chatcmpl-8090e8c913644f65960a35b1f9f07928.\n",
            "\u001b[2KProcessing 3 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_37.txt...vLLM STDOUT: INFO:     127.0.0.1:49048 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:33:17 [logger.py:43] Received request chatcmpl-b2b32226b2fc4c49a580100b1c2b97f2: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nNo. \\n\\n1 \\n\\n1. \\n\\nProperty \\nDescriptio\\nn \\n\\nEstimated \\nValue \\n\\nP.S. \\nProperty \\nRegister \\n\\nDisposal \\n\\nFrom \\nwhom \\n/where \\nRecovered \\nor seized \\n\\n2 \\n\\n3 \\n\\n4 \\n\\n5 \\n\\n6 \\n\\n---NIL \\n\\n--2-- 576investigation and relied upon (Separate list can be attached, if necessary) 577 10. \\nDetails of Properties/Articles/Documents recovered/Seized during 578 11. Particulars of \\naccused person charge sheeted: 579 (Use separate sheet for each accused) 580Sl.No.A-1) * \\nName Shri Balkrishna Mapari 581Father\\'s/Husband\\'s Name:- S/o Ladu Mapari 582Whether \\nVerified: Yes 583 (ii) Date/Year of Birth :- 39 years (iv) Sex Male (v)Nationality:-Indian 584 (vi) \\nPassport No. Nil 585Date of Issue Place of Issue 586 (vii) Religion:-Hindu 587Whether SC/ST-<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:33:17 [engine.py:317] Added request chatcmpl-b2b32226b2fc4c49a580100b1c2b97f2.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_37.txt...vLLM STDOUT: INFO:     127.0.0.1:55302 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_37.txt...vLLM STDOUT: INFO 12-14 05:33:33 [logger.py:43] Received request chatcmpl-34a30cf3c4b2462a8f92ee109a1387b9: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n\\nDetails of Properties/Articles/Documents recovered/Seized during 578 11. Particulars of \\naccused person charge sheeted: 579 (Use separate sheet for each accused) 580Sl.No.A-1) * \\nName Shri Balkrishna Mapari 581Father\\'s/Husband\\'s Name:- S/o Ladu Mapari 582Whether \\nVerified: Yes 583 (ii) Date/Year of Birth :- 39 years (iv) Sex Male (v)Nationality:-Indian 584 (vi) \\nPassport No. Nil 585Date of Issue Place of Issue 586 (vii) Religion:-Hindu 587Whether SC/ST- \\n\\n \\n \\n \\n \\n \\n \\n\\x0cOccupation: - 588 (ix) Address:-R/o H. No. 14, Deulwada, Hankhane, Pernem Goa 589Whether \\nverified:- 590 (x) * Provisional Criminal No. A-1 591 (xi) *Regular Criminal No. 592(If known 593 (xii) \\nDate of Arrest:- On 06.05.2019 at 16.40 hrs 594 (xiii) *Date of release on bail: In Judicial \\nCustody 595*Date on which forwarded to court 596 (xii) *Under Acts & Sections:-376 AB IPC, 4, \\n6, 8 & 12 of POCOS Act 597 and Sec. 8 of Goa Children Act 598 (xiii) *Name (s) and Address (es) \\nof sureties: 599 (xiv) Previous convictions with case references: 600 (xv) Status of the accused; - \\nIn Judicial Custody 601Forwarded/Bailed by Police/Under Police Custody/Bailed by Court/In \\nJudicial 602Custody/ Absconding / Proclaimed Offender: 603 12. Particulars of accused person \\nnot charge sheeted (Suspect): (Use separate 604sheet for each 605suspect) :- NIL 606 Sl. No (i) \\nNames - 607whether verified...yes 608 (ii) Father<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:33:33 [engine.py:317] Added request chatcmpl-34a30cf3c4b2462a8f92ee109a1387b9.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_37.txt...vLLM STDOUT: INFO:     127.0.0.1:36118 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 48 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_37_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_37_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_37.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_37_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:57958 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:57962 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:33:51 [logger.py:43] Received request chatcmpl-a56d465e0a2a4924b6ff4c3c96bcc9cd: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n/ Proclaimed Offender: 603 12. Particulars of accused person \\nnot charge sheeted (Suspect): (Use separate 604sheet for each 605suspect) :- NIL 606 Sl. No (i) \\nNames - 607whether verified...yes 608 (ii) Father's/Husband's name:- (III)Date/year of Birth: \\n(IV)Sex: - 609 (V) Nationality:- (VI) Passport NO:- 610Date of issue:- 611Place of issue:- \\n(VII)Religion:- 612 (VIII) Whether S.C./S.T:- 613 (IX) Occupation (X)Address 614Whether \\nverified:-Yes 615 (XI) Provisional criminal NO:- 616 (XII) Suspicion Approved: No 617Yes/No 618 (XIII) \\nStatus of accused: Bailed by police/Bail by court/in judicial custody/Absconding/Proclaimed \\noffender/Not arrested:-Bailed by Police 619 (XIV)Under acts and section:- 620 (XV)Any special \\nremarks including reasons for not charge sheeting:- 621Scanned with OKEN Scanner 622 \\n\\n--- PAGE 31 --- \\n\\nyut 623--4-- 624 13. Particulars of Witnesses to be examined:- 625 \\n\\nSr. No. \\n\\nName \\n\\nFather's/ \\nHusband\\n's Name \\n\\nDate/ \\nYear of \\nBirth \\n\\nOccupat\\nion \\n\\nAddress \\n\\nType of \\nEvidence \\nto be \\nrendered \\n\\n1 \\n\\n1. \\n\\n2. \\n\\n2 \\n\\n3 \\n\\n4 \\n\\n5 \\n\\n6 \\n\\n7 \\n\\n37 yrs \\n\\nTailor \\n\\nW/o \\nSantosh \\nNaik \\n\\nSmt. \\nSanjana \\nNaik \\n82756445\\n46 \\n\\nComplain\\nant \\n\\nH. No. 16, \\nDeulwad\\na, \\nHankhan\\ne, \\nPernem \\nGoa \\n\\nMrs. \\nReshma \\n\\nW/o \\nSakhara\\n\\n31 yrs \\n\\nHouse \\nwife \\n\\nH. No. 76, \\nIbrampur, \\n\\nPanch \\nwitness \\n\\n \\n \\n\\x0cm Naik \\n\\nNaik \\n82756445\\n46 \\n\\nMrs. \\nNamita \\nNaik \\n\\nW/o Arun \\nNaik \\n\\n34 yrs \\n\\nHouse \\nwife \\n\\nMiss Kruti \\nNaik \\n\\nd/o \\nSantosh \\nNaik \\n\\n04 yrs \\n\\nMiss \\nKavya \\nNaik \\n\\nd/o \\nSantosh \\nNaik \\n\\n04 yrs \\n\\nPratiksha \\nParvatkar \\n\\nMajor \\n\\nService \\n\\n3. \\n\\n4. \\n\\n5. \\n\\n6. \\n\\n7. \\n\\nPranjali \\nDessai \\n\\nMajor \\n\\nService \\n\\nfor scene \\nof \\noffence \\nPanchan\\nama \\n\\n-do- \\n\\nVictim \\n\\nVictim \\n\\nWitness \\n\\nWitness \\n\\nPernem \\nGoa \\n\\nH. No. 54, \\nNewwad\\na, \\nHankhan\\ne, \\nPernem \\nGoa \\n\\nH. No. 16, \\nHankhan\\ne, \\nPernem \\nGoa \\n\\nH. No. 16, \\nHankhan\\ne, \\nPernem \\nGoa \\n\\nVictim \\nAssistanc\\ne Unit for \\nthe state \\nof Goa, \\nForensic \\nDept. \\nGMC \\nBamboli\\nm \\n\\nVictim \\nAssistanc\\ne Unit for \\nthe state \\n\\n \\n \\n \\n \\n\\x0c8. \\n\\n9. \\n\\n10 \\n\\nMrs. \\nSarika Fal \\nDessai \\n\\nw/o \\nPurushott\\nam Naik \\n\\nMajor \\n\\nJMFC 'A' \\nCourt \\nMapusa \\n& I/C of \\nJMFC \\nPernem \\n\\nShri \\nSantosh \\nNaik \\n\\nS/o \\nRanganat\\nh Naik \\n\\n37 yrs \\n\\nDriver \\n\\nMrs. \\nPratiba \\nNaik \\n\\nw/o \\nPurushott\\nam Naik \\n\\n50 yrs \\n\\nHouse \\nwife \\n\\nof Goa, \\nForensic \\nDept. \\nGMC \\nBamboli\\nm \\n\\nJudicial \\nMagistrat\\ne First \\nClass, \\nPernem \\nGoa \\n\\nH. No. 16, \\nDeulwad\\na, \\nHankhan\\ne, \\nPernem \\nGoa<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:33:51 [engine.py:317] Added request chatcmpl-a56d465e0a2a4924b6ff4c3c96bcc9cd.\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/output2/ilovepdf_merged_38.txt...vLLM STDOUT: INFO:     127.0.0.1:57964 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:33:54 [logger.py:43] Received request chatcmpl-d4f8d6b66039442a82ecc780587649b1: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n / Proclaimed Offender: 603 12. Particulars of accused person \\nnot charge sheeted (Suspect): (Use separate 604sheet for each 605suspect) :- NIL 606 Sl. No (i) \\nNames - 607whether verified...yes 608 (ii) Father\\'s/Husband\\'s name:- (III)Date/year of Birth: \\n(IV)Sex: - 609 (V) Nationality:- (VI) Passport NO:- 610Date of issue:- 611Place of issue:- \\n(VII)Religion:- 612 (VIII) Whether S.C./S.T:- 613 (IX) Occupation (X)Address 614Whether \\nverified:-Yes 615 (XI) Provisional criminal NO:- 616 (XII) Suspicion Approved: No 617Yes/No 618 (XIII) \\nStatus of accused: Bailed by police/Bail by court/in judicial custody/Absconding/Proclaimed \\noffender/Not arrested:-Bailed by Police 619 (XIV)Under acts and section:- 620 (XV)Any special \\nremarks including reasons for not charge sheeting:- 621Scanned with OKEN Scanner 622 \\n\\n--- PAGE 31 --- \\n\\nyut 623--4-- 624 13. Particulars of Witnesses to be examined:- 625 \\n\\nSr. No. \\n\\nName \\n\\nFather\\'s/ \\nHusband\\n\\'s Name \\n\\nDate/ \\nYear of \\nBirth \\n\\nOccupat\\nion \\n\\nAddress<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2KProcessing 3 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_38.txt...vLLM STDOUT: INFO 12-14 05:33:54 [engine.py:317] Added request chatcmpl-d4f8d6b66039442a82ecc780587649b1.\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_38.txt...vLLM STDOUT: INFO:     127.0.0.1:57978 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:34:10 [logger.py:43] Received request chatcmpl-a6b5c80bc3e0479dbc5de1cfe7ca996e: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nParticulars of Witnesses to be examined:- 625 \\n\\nSr. No. \\n\\nName \\n\\nFather\\'s/ \\nHusband\\n\\'s Name \\n\\nDate/ \\nYear of \\nBirth \\n\\nOccupat\\nion \\n\\nAddress \\n\\nType of \\nEvidence \\nto be \\nrendered \\n\\n1 \\n\\n1. \\n\\n2. \\n\\n2 \\n\\n3 \\n\\n4 \\n\\n5 \\n\\n6 \\n\\n7 \\n\\n37 yrs \\n\\nTailor \\n\\nW/o \\nSantosh \\nNaik \\n\\nSmt. \\nSanjana \\nNaik \\n82756445\\n46 \\n\\nComplain\\nant \\n\\nH. No. 16, \\nDeulwad\\na, \\nHankhan\\ne, \\nPernem \\nGoa \\n\\nMrs. \\nReshma \\n\\nW/o \\nSakhara\\n\\n31 yrs \\n\\nHouse \\nwife \\n\\nH. No. 76, \\nIbrampur, \\n\\nPanch \\nwitness \\n\\n \\n \\n\\x0cm Naik \\n\\nNaik \\n82756445\\n46 \\n\\nMrs. \\nNamita \\nNaik \\n\\nW/o Arun \\nNaik \\n\\n34 yrs \\n\\nHouse \\nwife \\n\\nMiss Kruti \\nNaik \\n\\nd/o \\nSantosh \\nNaik \\n\\n04 yrs \\n\\nMiss \\nKavya \\nNaik \\n\\nd/o \\nSantosh \\nNaik \\n\\n04 yrs \\n\\nPratiksha \\nParvatkar \\n\\nMajor \\n\\nService \\n\\n3. \\n\\n4. \\n\\n5. \\n\\n6. \\n\\n7. \\n\\nPranjali \\nDessai \\n\\nMajor \\n\\nService \\n\\nfor scene \\nof \\noffence \\nPanchan\\nama \\n\\n-do- \\n\\nVictim \\n\\nVictim \\n\\nWitness \\n\\nWitness \\n\\nPernem \\nGoa \\n\\nH. No. 54, \\nNewwad\\na, \\nHankhan\\ne, \\nPernem \\nGoa \\n\\nH. No. 16, \\nHankhan\\ne, \\nPernem \\nGoa \\n\\nH. No. 16, \\nHankhan\\ne, \\nPernem \\nGoa<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:34:10 [engine.py:317] Added request chatcmpl-a6b5c80bc3e0479dbc5de1cfe7ca996e.\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/output2/ilovepdf_merged_38.txt...vLLM STDOUT: INFO:     127.0.0.1:43344 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_38.txt...vLLM STDOUT: INFO 12-14 05:34:25 [logger.py:43] Received request chatcmpl-464cb62fe32b4a73b7963971926ffaca: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n16, \\nHankhan\\ne, \\nPernem \\nGoa \\n\\nH. No. 16, \\nHankhan\\ne, \\nPernem \\nGoa \\n\\nVictim \\nAssistanc\\ne Unit for \\nthe state \\nof Goa, \\nForensic \\nDept. \\nGMC \\nBamboli\\nm \\n\\nVictim \\nAssistanc\\ne Unit for \\nthe state \\n\\n \\n \\n \\n \\n\\x0c8. \\n\\n9. \\n\\n10 \\n\\nMrs. \\nSarika Fal \\nDessai \\n\\nw/o \\nPurushott\\nam Naik \\n\\nMajor \\n\\nJMFC \\'A\\' \\nCourt \\nMapusa \\n& I/C of \\nJMFC \\nPernem \\n\\nShri \\nSantosh \\nNaik \\n\\nS/o \\nRanganat\\nh Naik \\n\\n37 yrs \\n\\nDriver \\n\\nMrs. \\nPratiba \\nNaik \\n\\nw/o \\nPurushott\\nam Naik \\n\\n50 yrs \\n\\nHouse \\nwife \\n\\nof Goa, \\nForensic \\nDept. \\nGMC \\nBamboli\\nm \\n\\nJudicial \\nMagistrat\\ne First \\nClass, \\nPernem \\nGoa \\n\\nH. No. 16, \\nDeulwad\\na, \\nHankhan\\ne, \\nPernem \\nGoa<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:34:25 [engine.py:317] Added request chatcmpl-464cb62fe32b4a73b7963971926ffaca.\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_38.txt...vLLM STDOUT: INFO:     127.0.0.1:48318 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 46 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_38_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_38_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/output2/ilovepdf_merged_38.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_38_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:60758 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:60768 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:34:43 [logger.py:43] Received request chatcmpl-26dfd48bd99a43caaa10f73658fee34a: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nForensic \\nDept. \\nGMC \\nBamboli\\nm \\n\\nJudicial \\nMagistrat\\ne First \\nClass, \\nPernem \\nGoa \\n\\nH. No. 16, \\nDeulwad\\na, \\nHankhan\\ne, \\nPernem \\nGoa \\n\\nH. No. 18, \\nDeulwad\\na, \\nHankhan\\ne, \\nPernem \\nGoa \\n\\nWitness \\n\\nWitness \\n\\nWitness \\n\\nPW 626PNaik 627tha 628Amade 6292 630Bangr 631M 632Scanned with OKEN Scanner 633 \\n\\n--- PAGE 32 --- \\n\\nSr. No. \\n\\nName \\n\\nFather's/ \\nHusband\\n's Name \\n\\nDate/ \\nYear of \\nBirth \\n\\nOccupat\\nion \\n\\nAddress \\n\\nType of \\nEvidence \\nto be \\nrendered \\n\\n \\n\\x0c11 \\n\\n12 \\n\\n13 \\n\\n14 \\n\\n15 \\n\\n16 \\n\\nSmt. \\nMahima \\nNaik \\n\\nw/o Babli \\nNaik \\n\\n35 yrs \\n\\nHouse \\nwife \\n\\nSmt. \\nSuchita \\nNaik \\n\\nw/o \\nNarayan \\nNaik \\n\\n59 yrs \\n\\nFarmer \\n\\nMajor \\n\\nDr. \\nLynette \\nFernande\\ns \\n\\nMajor \\n\\nDr. \\nPannag \\nKumar \\n\\nService / \\nSenior \\nResident \\nReg. No. \\n3013 \\n\\nService/ \\nLecturer \\n\\nMajor \\n\\nDr. \\nPascoal \\nD'souza \\n\\nService/ \\nMedical \\nOfficer \\n\\nWitness \\n\\nWitness \\n\\nWitness \\n\\nWitness \\n\\nWitness \\n\\nH. No. 17, \\nDeulwad\\na, \\nHankhan\\ne, \\nPernem \\nGoa \\n\\nH. No. 19, \\nDeulwad\\na, \\nHankhan\\ne, \\nPernem \\nGoa \\n\\nDept. of \\nobstetric\\ns & \\nGynaecol\\nogy, GMC \\nBamboli\\nm \\n\\nDept. of \\nForensic \\nMedicine \\n& \\nToxicolog\\ny, GMC \\nBamboli\\nm \\n\\nBlood \\nBank, \\nGMC \\nBamboli\\nm \\n\\nShri \\nAlvito \\n\\nMajor \\n\\nService \\n\\nPernem \\nPolice \\n\\nI.O. \\n\\n \\n \\n \\n \\n\\x0cRodrigue\\ns \\n\\n/P.S.I. \\n\\nStation \\n\\nchopped 634heasy. 635heasany 6369881334/41 637 14. If F.R. is False, indicate action taken or \\nproposed to be taken u/s 182/211 IPC 638 15. Result of Laboratory Analysis:- ---- 639 Pw9-. \\nMirinalani - 640Scanned with OKEN Scanner 641 \\n\\n--- PAGE 33 --- \\n\\n--5-- 642 16. Brief facts of the case (Add separate sheet if necessary) 643MAY IT PLEASE YOUR \\nHONOUR 644In the limits of your Hon'ble court and within the jurisdiction of Pernem Police \\nstation that on 06.05.2019 Smt. 645Sanjana w/o Santosh Naik, age 37 yrs r/o H. No. 16, \\nDeulwada, Hankhane, Pernem Goa lodged complaint to the effect that about 15 days back at \\nH. No. 141, Deulwada, Hankhane, Pernem Goa accused Krishna s/o Ladu Mapari, age 34 yrs r/o \\nH. No. 141, Deulwada, Hankhane, Pernem Goa sexually exploited her twins minor daughter \\nMiss Kruti d/o Santosh Naik, age 04 yrs and Miss Kavya d/o Santosh Naik, age 04 yrs by \\ntouching their private parts and by inserting his penis into their private parts. 646 In this \\nconnection an offence vide Pernem PS Cr. No. 102/2019 U/s 376 IPC, Sec. 647 4, 8 & 12 of \\nPOCSO Act and Sec. 8 of Goa Children Act stands registered on 06.05.2019 at 14.40 hrs. \\n648During course of investigation accused Mr. Balkrishna s/o Ladu Mapari, age 39 yrs r/o H. No. \\n14<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:34:43 [engine.py:317] Added request chatcmpl-26dfd48bd99a43caaa10f73658fee34a.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_39.txt...vLLM STDOUT: INFO:     127.0.0.1:60780 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:34:48 [logger.py:43] Received request chatcmpl-a8fa8dfb8e9f4909850d75651046fefb: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n \\nForensic \\nDept. \\nGMC \\nBamboli\\nm \\n\\nJudicial \\nMagistrat\\ne First \\nClass, \\nPernem \\nGoa \\n\\nH. No. 16, \\nDeulwad\\na, \\nHankhan\\ne, \\nPernem \\nGoa \\n\\nH. No. 18, \\nDeulwad\\na, \\nHankhan\\ne, \\nPernem \\nGoa \\n\\nWitness \\n\\nWitness \\n\\nWitness \\n\\nPW 626PNaik 627tha 628Amade 6292 630Bangr 631M 632Scanned with OKEN Scanner 633 \\n\\n--- PAGE 32 --- \\n\\nSr. No. \\n\\nName \\n\\nFather\\'s/ \\nHusband\\n\\'s Name \\n\\nDate/ \\nYear of \\nBirth \\n\\nOccupat\\nion \\n\\nAddress \\n\\nType of \\nEvidence \\nto be \\nrendered \\n\\n \\n\\x0c11 \\n\\n12 \\n\\n13 \\n\\n14 \\n\\n15 \\n\\n16 \\n\\nSmt. \\nMahima \\nNaik \\n\\nw/o Babli \\nNaik \\n\\n35 yrs \\n\\nHouse \\nwife \\n\\nSmt. \\nSuchita \\nNaik \\n\\nw/o \\nNarayan \\nNaik \\n\\n59 yrs \\n\\nFarmer \\n\\nMajor \\n\\nDr. \\nLynette \\nFernande\\ns \\n\\nMajor \\n\\nDr. \\nPannag \\nKumar \\n\\nService / \\nSenior \\nResident \\nReg. No. \\n3013 \\n\\nService/ \\nLecturer \\n\\nMajor \\n\\nDr. \\nPascoal \\nD\\'souza \\n\\nService/ \\nMedical \\nOfficer \\n\\nWitness \\n\\nWitness \\n\\nWitness \\n\\nWitness \\n\\nWitness \\n\\nH. No. 17, \\nDeulwad\\na, \\nHankhan\\ne, \\nPernem \\nGoa \\n\\nH. No. 19, \\nDeulwad\\na, \\nHankhan\\ne, \\nPernem \\nGoa \\n\\nDept. of \\nobstetric\\ns & \\nGynaecol\\nogy, GMC \\nBamboli\\nm<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "\u001b[2KProcessing 3 chunks to generate QA pairs...\n",
            "\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_39.txt...vLLM STDOUT: INFO 12-14 05:34:48 [engine.py:317] Added request chatcmpl-a8fa8dfb8e9f4909850d75651046fefb.\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_39.txt...vLLM STDOUT: INFO:     127.0.0.1:45938 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:35:04 [logger.py:43] Received request chatcmpl-9ce060913c7d4e87aa67d2e9435b7c72: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nNo. 19, \\nDeulwad\\na, \\nHankhan\\ne, \\nPernem \\nGoa \\n\\nDept. of \\nobstetric\\ns & \\nGynaecol\\nogy, GMC \\nBamboli\\nm \\n\\nDept. of \\nForensic \\nMedicine \\n& \\nToxicolog\\ny, GMC \\nBamboli\\nm \\n\\nBlood \\nBank, \\nGMC \\nBamboli\\nm \\n\\nShri \\nAlvito \\n\\nMajor \\n\\nService \\n\\nPernem \\nPolice \\n\\nI.O. \\n\\n \\n \\n \\n \\n\\x0cRodrigue\\ns \\n\\n/P.S.I. \\n\\nStation \\n\\nchopped 634heasy. 635heasany 6369881334/41 637 14. If F.R. is False, indicate action taken or \\nproposed to be taken u/s 182/211 IPC 638 15. Result of Laboratory Analysis:- ---- 639 Pw9-. \\nMirinalani - 640Scanned with OKEN Scanner 641 \\n\\n--- PAGE 33 ---<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:35:04 [engine.py:317] Added request chatcmpl-9ce060913c7d4e87aa67d2e9435b7c72.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_39.txt...vLLM STDOUT: INFO:     127.0.0.1:59870 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:35:19 [logger.py:43] Received request chatcmpl-4e35f4bcd8114974bc757212b5f6fe10: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 33 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nis False, indicate action taken or \\nproposed to be taken u/s 182/211 IPC 638 15. Result of Laboratory Analysis:- ---- 639 Pw9-. \\nMirinalani - 640Scanned with OKEN Scanner 641 \\n\\n--- PAGE 33 --- \\n\\n--5-- 642 16. Brief facts of the case (Add separate sheet if necessary) 643MAY IT PLEASE YOUR \\nHONOUR 644In the limits of your Hon\\'ble court and within the jurisdiction of Pernem Police \\nstation that on 06.05.2019 Smt. 645Sanjana w/o Santosh Naik, age 37 yrs r/o H. No. 16, \\nDeulwada, Hankhane, Pernem Goa lodged complaint to the effect that about 15 days back at \\nH. No. 141, Deulwada, Hankhane, Pernem Goa accused Krishna s/o Ladu Mapari, age 34 yrs r/o \\nH. No. 141, Deulwada, Hankhane, Pernem Goa sexually exploited her twins minor daughter \\nMiss Kruti d/o Santosh Naik, age 04 yrs and Miss Kavya d/o Santosh Naik, age 04 yrs by \\ntouching their private parts and by inserting his penis into their private parts. 646 In this \\nconnection an offence vide Pernem PS Cr. No. 102/2019 U/s 376 IPC, Sec. 647 4, 8 & 12 of \\nPOCSO Act and Sec. 8 of Goa Children Act stands registered on 06.05.2019 at 14.40 hrs. \\n648During course of investigation accused Mr. Balkrishna s/o Ladu Mapari, age 39 yrs r/o H. No. \\n14<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:35:19 [engine.py:317] Added request chatcmpl-4e35f4bcd8114974bc757212b5f6fe10.\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/output2/ilovepdf_merged_39.txt...vLLM STDOUT: INFO:     127.0.0.1:38154 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 47 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_39_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_39_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output2/ilovepdf_merged_39.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_39_qa_pairs.json\u001b[0m\n",
            "vLLM STDOUT: INFO:     127.0.0.1:33682 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO:     127.0.0.1:33684 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:35:37 [logger.py:43] Received request chatcmpl-26c3cfc06c5942c087bde80243a3842e: prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nSummarize this document in 3-5 sentences, focusing on the main topic and key concepts.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n12 of \\nPOCSO Act and Sec. 8 of Goa Children Act stands registered on 06.05.2019 at 14.40 hrs. \\n648During course of investigation accused Mr. Balkrishna s/o Ladu Mapari, age 39 yrs r/o H. No. \\n14, Deulwada, Hankhane, Pernem Goa was brought at the Police Station and interrogated \\nwherein he admitted to the commission of the crime, accordingly he was placed under arrest \\non 06.05.2019 at 16.40 hrs after observing all SC guidelines. 649Accused was produced before \\nHon'ble court and initially remanded to police custody and thereafter remanded to judicial \\ncustody. 650The Medical examination of sexual offence of both the victim girls and accused \\nperson were conducted at GMC Bambolim and their medical report are taken on record. \\n651During course of investigation visited at the spot and conducted scene of offence \\npanchanama in presence of two panch witnesses. 652The statement of both the victim girls \\nwere recorded by the victim assistance unit. 653Also recorded their statement u/s 164 of Cr.P.C. \\nwherein they confirm the fact that accused had sexually abused them by inserting his private \\nparts into their private part and also inserted a pencil and leaf into their private part and taken \\non record. 654 Hence section 376 AB IPC and Sec. 6 of POCSO Act was adduced to the case as \\nboth the victims aged 04 years. 655Also recorded statement of more relevant witnesses \\nnamely 1) Shri Santosh s/o Ranganath Naik, age 37 yrs r/o H. No. 16, Deulwada, Hankhane, \\nPernem Goa 2) Mrs. Pratibha w/o Purushottam Naik, age 50 yrs r/o H. No. 18, Deulwada, \\nHankhane, Pernem, 3) Smt. 656Mahima w/o Babli Naik, age 35 yrs r/o H. No. 17, Deulwada, \\nHankhane & 4) Smt. 657Suchita w/o Narayan Naik, age 59 yrs r/o H. No. 19, Deulwada, \\nHankhane, Pernem Goa and taken on record. 658Scanned with OKEN Scanner 659 \\n\\n \\n\\x0c--- PAGE 34 --- \\n\\nFrom the overall investigation conducted so far, evidence on record and statement of victims \\n& witnesses it is evident that the accused person mentioned at Column No. 11 at Sr. No. A-1 \\nMr. Balkrishna s/o Ladu Mapari, age 39 yrs r/o H. No. 14, Deulwada, Hankhane, Pernem Goa \\nsexually exploited complainant twins minor daughters namely Miss Kruti Naik, age 04 yrs and \\nMiss Kavya Naik, age 04 yrs by touching their private parts, inserted his private part into their \\nprivate parts and also inserted finger, pencil and leaf into their private parts thereby \\ncommitted rape of two minor girls. 660Thus the accused person committed an offence \\npunishable Under Section 376 AB IPC, Sec. 661 4, 6, 8 & 12 of POCSO Act & Sec. 8 of Goa \\nChildren Act 2003. 662Hence the charge. 663 17. Refer Notice Served 664/06/2019 665 \\n(Acknowledgement to be placed) 666 18. Dispatched on: 667/06/2019 668 19. No. of enclosures:- \\n669 20. List of enclosures: As Annexed. 670Forwarded by Officer in charge 671 Name: Shri. Harish \\nV. Madkaikar. 672Rank: Police Inspector. 673Pernem Police Station. 674M 675Signature of \\nInvestigating Officer 676Submitting Charge Sheet 677Name:-Alvito F. Rodrigues. 678Rank: Police \\nSub-Inspector. 679Pernem Police Station. 680Scanned with OKEN Scanner 681<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:35:37 [engine.py:317] Added request chatcmpl-26c3cfc06c5942c087bde80243a3842e.\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output2/ilovepdf_merged_40.txt...vLLM STDOUT: INFO:     127.0.0.1:33692 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:35:44 [logger.py:43] Received request chatcmpl-a8fc6c5e27aa42cf8f5d8586f1410b51: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n12 of \\nPOCSO Act and Sec. 8 of Goa Children Act stands registered on 06.05.2019 at 14.40 hrs. \\n648During course of investigation accused Mr. Balkrishna s/o Ladu Mapari, age 39 yrs r/o H. No. \\n14, Deulwada, Hankhane, Pernem Goa was brought at the Police Station and interrogated \\nwherein he admitted to the commission of the crime, accordingly he was placed under arrest \\non 06.05.2019 at 16.40 hrs after observing all SC guidelines. 649Accused was produced before \\nHon\\'ble court and initially remanded to police custody and thereafter remanded to judicial \\ncustody. 650The Medical examination of sexual offence of both the victim girls and accused \\nperson were conducted at GMC Bambolim and their medical report are taken on record. \\n651During course of investigation visited at the spot and conducted scene of offence \\npanchanama in presence of two panch witnesses. 652The statement of both the victim girls \\nwere recorded by the victim assistance unit. 653Also recorded their statement u/s 164 of Cr.P.C. \\nwherein they confirm the fact that accused had sexually abused them by inserting his private \\nparts into their private part and also inserted a pencil and leaf into their private part and taken \\non record. 654 Hence section 376 AB IPC and Sec. 6 of POCSO Act was adduced to the case as \\nboth the victims aged 04 years. 655Also recorded statement of more relevant witnesses \\nnamely 1) Shri Santosh s/o Ranganath Naik, age 37 yrs r/o H. No. 16, Deulwada, Hankhane, \\nPernem Goa 2) Mrs. Pratibha w/o Purushottam Naik, age 50 yrs r/o H. No. 18, Deulwada, \\nHankhane, Pernem, 3) Smt. 656Mahima w/o Babli Naik, age 35 yrs r/o H. No. 17, Deulwada, \\nHankhane & 4) Smt. 657Suchita w/o Narayan Naik, age 59 yrs r/o H. No. 19, Deulwada, \\nHankhane, Pernem Goa and taken on record. 658Scanned with OKEN Scanner 659<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:35:44 [engine.py:317] Added request chatcmpl-a8fc6c5e27aa42cf8f5d8586f1410b51.\n",
            "\u001b[2KProcessing 4 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output2/ilovepdf_merged_40.txt...vLLM STDOUT: INFO:     127.0.0.1:33694 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:35:59 [logger.py:43] Received request chatcmpl-fe80a8ce17054d2baf8ec2925d9d85d2: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nNo. 19, Deulwada, \\nHankhane, Pernem Goa and taken on record. 658Scanned with OKEN Scanner 659 \\n\\n \\n\\x0c--- PAGE 34 ---<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:35:59 [engine.py:317] Added request chatcmpl-fe80a8ce17054d2baf8ec2925d9d85d2.\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/output2/ilovepdf_merged_40.txt...vLLM STDOUT: INFO:     127.0.0.1:33622 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:36:02 [logger.py:43] Received request chatcmpl-564a6b77196e47e68ff261aae605354e: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\nFrom the overall investigation conducted so far, evidence on record and statement of victims \\n& witnesses it is evident that the accused person mentioned at Column No. 11 at Sr. No. A-1 \\nMr. Balkrishna s/o Ladu Mapari, age 39 yrs r/o H. No. 14, Deulwada, Hankhane, Pernem Goa \\nsexually exploited complainant twins minor daughters namely Miss Kruti Naik, age 04 yrs and \\nMiss Kavya Naik, age 04 yrs by touching their private parts, inserted his private part into their \\nprivate parts and also inserted finger, pencil and leaf into their private parts thereby \\ncommitted rape of two minor girls. 660Thus the accused person committed an offence \\npunishable Under Section 376 AB IPC, Sec. 661 4, 6, 8 & 12 of POCSO Act & Sec. 8 of Goa \\nChildren Act 2003. 662Hence the charge. 663 17. Refer Notice Served 664/06/2019 665 \\n(Acknowledgement to be placed) 666 18. Dispatched on: 667/06/2019 668 19. No. of enclosures:- \\n669 20. List of enclosures: As Annexed. 670Forwarded by Officer in charge 671 Name: Shri. Harish \\nV. Madkaikar. 672Rank: Police Inspector. 673Pernem Police Station. 674M 675Signature of \\nInvestigating Officer 676Submitting Charge Sheet 677Name:-Alvito F. Rodrigues. 678Rank: Police \\nSub-Inspector. 679Pernem Police Station. 680Scanned with OKEN Scanner 681<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:36:02 [engine.py:317] Added request chatcmpl-564a6b77196e47e68ff261aae605354e.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_40.txt...vLLM STDOUT: INFO:     127.0.0.1:33638 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "vLLM STDOUT: INFO 12-14 05:36:18 [logger.py:43] Received request chatcmpl-01ad3e78755048d6b2f6e92763814722: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nCreate 25 question-answer pairs from this text for LLM training.\\n\\nRules:\\n1. Questions must be about important facts in the text\\n2. Answers must be directly supported by the text\\n3. Return JSON format only:\\n\\n[\\n  {\\n    \"question\": \"Question 1?\",\\n    \"answer\": \"Answer 1.\"\\n  },\\n  {\\n    \"question\": \"Question 2?\",\\n    \"answer\": \"Answer 2.\"\\n  }\\n]\\n\\nText:\\n678Rank: Police \\nSub-Inspector. 679Pernem Police Station. 680Scanned with OKEN Scanner 681<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.95, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None, prompt_adapter_request: None.\n",
            "vLLM STDOUT: INFO 12-14 05:36:18 [engine.py:317] Added request chatcmpl-01ad3e78755048d6b2f6e92763814722.\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/output2/ilovepdf_merged_40.txt...vLLM STDOUT: INFO:     127.0.0.1:46338 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 36 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/ilovepdf_merged_40_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/ilovepdf_merged_40_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/output2/ilovepdf_merged_40.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/ilovepdf_merged_40_qa_pairs.json\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "# Process all chunks\n",
        "for filename in filenames:\n",
        "    !synthetic-data-kit \\\n",
        "        -c synthetic_data_kit_config.yaml \\\n",
        "        create {filename} \\\n",
        "        --num-pairs 100 \\\n",
        "        --type \"qa\"\n",
        "    time.sleep(2) # Sleep some time to leave some room for processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNkxxvBx7Csp"
      },
      "source": [
        "Optionally, you can clean up the data via pruning \"bad\" or low quality examples and convert the rest to JSON format for finetuning!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMD-izj5OiAK"
      },
      "outputs": [],
      "source": [
        "# !synthetic-data-kit \\\n",
        "#     -c synthetic_data_kit_config.yaml \\\n",
        "#     curate --threshold 0.0 \\\n",
        "#     \"data/generated/arxiv_org_0_qa_pairs.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AScJ5-vAOjYj"
      },
      "source": [
        "We now convert the generated datasets into QA formats so we can load it for finetuning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9Um4Z8SqUTB",
        "outputId": "465f8271-1a1d-40d3-b6e9-6549eb2ac861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_0_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[?25h\r\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_0_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_1_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_1_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_2_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_2_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_3_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_3_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_4_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_4_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_5_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_5_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_6_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_6_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_7_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_7_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_8_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_8_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_9_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_9_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_10_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_10_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_11_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_11_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_12_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_12_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_13_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_13_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_14_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_14_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_15_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_15_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_16_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_16_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_17_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_17_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_18_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_18_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_19_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_19_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_20_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_20_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_21_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_21_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_22_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_22_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_23_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_23_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_24_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_24_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_25_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_25_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_26_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_26_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_27_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_27_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_28_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_28_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_29_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_29_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_30_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_30_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_31_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_31_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_32_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_32_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_33_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_33_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_34_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_34_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_35_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_35_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_36_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_36_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_37_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_37_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_38_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_38_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_39_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_39_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/ilovepdf_merged_40_qa_pairs.json to ft format with \n",
            "json storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\n",
            "\u001b[1;32mdata/final/ilovepdf_merged_40_qa_pairs_ft.json\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "qa_pairs_filenames = [\n",
        "    f\"data/generated/ilovepdf_merged_{i}_qa_pairs.json\"\n",
        "    for i in range(len(filenames))\n",
        "]\n",
        "for filename in qa_pairs_filenames:\n",
        "    !synthetic-data-kit \\\n",
        "        -c synthetic_data_kit_config.yaml \\\n",
        "        save-as {filename} -f ft"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dVK-qza7rPB"
      },
      "source": [
        "Let's load up the data and see what the synthetic data looks like!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "VrBwG2KT7dam"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "final_filenames = [\n",
        "    f\"data/final/ilovepdf_merged_{i}_qa_pairs_ft.json\"\n",
        "    for i in range(len(filenames))\n",
        "]\n",
        "conversations = pd.concat([\n",
        "    pd.read_json(name) for name in final_filenames\n",
        "]).reset_index(drop = True)\n",
        "\n",
        "dataset = Dataset.from_pandas(conversations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaZ3tRP8frSn",
        "outputId": "a220e8dc-474f-4f2a-c82f-435fbc294b76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
              "  {'content': 'What is the name of the court mentioned in the text?',\n",
              "   'role': 'user'},\n",
              "  {'content': 'IN THE COURT OF THE DISTRICT SESSION JUDGE, AT PANAJI-GOA.',\n",
              "   'role': 'assistant'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "504n46Sxfruu",
        "outputId": "702cabf9-e6a6-4536-e820-f77575b0cb87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
              "  {'content': 'What is the date of the FIR mentioned in the text?',\n",
              "   'role': 'user'},\n",
              "  {'content': '11.12.2021', 'role': 'assistant'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "dataset[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BVBp9YXRw_o",
        "outputId": "46d7edcc-37c4-4517-9cc9-6c3e0653d4a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
              "  {'content': 'What scanner was used?', 'role': 'user'},\n",
              "  {'content': 'OKEN Scanner', 'role': 'assistant'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "dataset[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO9qePmP7yaY"
      },
      "source": [
        "Finally free vLLM process to save memory and to allow for finetuning!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8qgTjywzgl6",
        "outputId": "97106c98-765f-4a81-d153-3f234b215574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to terminate the VLLM server gracefully...\n",
            "vLLM STDOUT: INFO 12-14 05:47:33 [launcher.py:80] Shutting down FastAPI HTTP server.\n",
            "Server terminated gracefully.\n"
          ]
        }
      ],
      "source": [
        "generator.cleanup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQo2PR7oqDQE"
      },
      "source": [
        "### Fine-tuning Synthetic Dataset with Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "e09f45bc-0805-43e6-8ea5-6f1601ce84ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.12.5: Fast Llama patching. Transformers: 4.56.2. vLLM: 0.9.2.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "fourbit_models = [\n",
        "    # 4bit dynamic quants for superior accuracy and low memory use\n",
        "    \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-27b-it-unsloth-bnb-4bit\",\n",
        "    # Qwen3 new models\n",
        "    \"unsloth/Qwen3-4B-unsloth-bnb-4bit\",\n",
        "    \"unsloth/Qwen3-8B-unsloth-bnb-4bit\",\n",
        "    # Other very popular models!\n",
        "    \"unsloth/Llama-3.1-8B\",\n",
        "    \"unsloth/Llama-3.2-3B\",\n",
        "    \"unsloth/Llama-3.3-70B\",\n",
        "    \"unsloth/mistral-7b-instruct-v0.3\",\n",
        "    \"unsloth/Phi-4\",\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Llama-3.2-3B-Instruct\",\n",
        "    max_seq_length = 2048, # Choose any for long context!\n",
        "    load_in_4bit = True,  # 4 bit quantization to reduce memory\n",
        "    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory\n",
        "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
        "    # token = \"hf_...\", # use one if using gated models\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "6bZsfBuZDeCL"
      },
      "outputs": [],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the `Llama-3.2` format for conversation style finetunes. The chat template renders conversations like below: (Cutting Knowledge Date is by default there!)\n",
        "\n",
        "```\n",
        "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "Cutting Knowledge Date: December 2023\n",
        "Today Date: 01 May 2025\n",
        "\n",
        "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "What is 1+1?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "2<|eot_id|>\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "353c0192acd14733b204f60f8e58e993",
            "c65910c8f3e64093bcca693c973d9ad8",
            "cee18c6ba58247d69668557140f79ca6",
            "a441ed21d5344803b48aa006b5b434a0",
            "e4ca34c26aac4b02bedaba48864cff8b",
            "d4e0e1dd00584521b490bc3a785bc82f",
            "24fbfbc731c54458841f3e7835e3e49c",
            "cdff6d335fa94ee5921f1757ff3e1d86",
            "629b8655f9494d59ba509a899ff4c35c",
            "4b89c6083b30423885e3f02b1a57c02b",
            "8623f631297c4eff90628aef401b0167"
          ]
        },
        "id": "LjY75GoYUCB8",
        "outputId": "ce01cb46-b760-4f0e-9352-055f9959ab7e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2249 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "353c0192acd14733b204f60f8e58e993"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def formatting_prompts_func(examples):\n",
        "    convos = examples[\"messages\"]\n",
        "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
        "    return { \"text\" : texts, }\n",
        "\n",
        "# Get our previous dataset and format it:\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKA0VEF4CfCB"
      },
      "source": [
        "See result of the first row:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0usAI0M40hpT",
        "outputId": "7744c371-2772-47a2-cc75-1480ef582c2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
              "  {'content': 'What is the name of the court mentioned in the text?',\n",
              "   'role': 'user'},\n",
              "  {'content': 'IN THE COURT OF THE DISTRICT SESSION JUDGE, AT PANAJI-GOA.',\n",
              "   'role': 'assistant'}],\n",
              " 'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 14 Dec 2025\\n\\nYou are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWhat is the name of the court mentioned in the text?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nIN THE COURT OF THE DISTRICT SESSION JUDGE, AT PANAJI-GOA.<|eot_id|>'}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's train our model. We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "35f9a1e5ecfc45129f9b86609423fe47",
            "94e582fee0554361b748d7b047fff64f",
            "e83d1fc99f384ccd890b67434d7fb98f",
            "215a3eff14c840619bd41a0860bf7ea5",
            "cf33c70598a948569ee2859a4fbb8411",
            "fa455b87214b483a9135722900d23054",
            "53a5b46695f24586a40faf669a3ef8a8",
            "8d2fa83330ab4d888221188034e32979",
            "c628a4775a08496d9e5ad6b58b488e9f",
            "b07ac94208844d3cb9e52cbcd6186c0a",
            "119ac18c854c4856852656ea8b1b9200"
          ]
        },
        "id": "95_Nn-89DhsL",
        "outputId": "d610a8e3-0529-4f24-ccd4-9854b335a8a9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/2249 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35f9a1e5ecfc45129f9b86609423fe47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Padding-free auto-enabled, enabling faster training.\n"
          ]
        }
      ],
      "source": [
        "from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    eval_dataset = None, # Can set up evaluation!\n",
        "    args = SFTConfig(\n",
        "        dataset_text_field = \"text\",\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4, # Use GA to mimic batch size!\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.001,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        report_to = \"none\", # Use TrackIO/WandB etc\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "11f7102e-4aed-4389-aab4-35aa346c9df6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "3.441 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "851a5500-c914-405f-a158-6776453de89d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 2,249 | Num Epochs = 1 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 24,313,856 of 3,237,063,680 (0.75% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 01:56, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>5.242100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.199100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.079700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4.558400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.978500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3.781200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>3.188500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.748200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.620500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.328000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.124100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.788100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.795100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.702900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.662600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.572300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.372600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.724200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.308400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.385900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.477300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.308600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.370600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.359900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.454800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.166500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.224100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.356400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.371000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.085100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.172000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.300500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.076400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.130200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.164000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.193900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.209600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.085000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.085200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.078300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.114300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.110500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.088500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.359000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.094300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.006600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.199100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.969400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.053300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.983900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.910100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.187700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.162200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.922400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.088900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.008800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.092100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.204300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1.053200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.877200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCqnaKmlO1U9",
        "outputId": "7d2e126d-42d9-4175-d909-31fe15a4193e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110.0157 seconds used for training.\n",
            "1.83 minutes used for training.\n",
            "Peak reserved memory = 3.441 GB.\n",
            "Peak reserved memory for training = 0.0 GB.\n",
            "Peak reserved memory % of max memory = 23.343 %.\n",
            "Peak reserved memory for training % of max memory = 0.0 %.\n"
          ]
        }
      ],
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model! Use `apply_chat_template` with `add_generation_prompt` set to `True` for inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR3gIAX-SM2q",
        "outputId": "8697db60-102f-4a82-ae7d-7c1d9fce0c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A chargesheet<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"What does a chargesheet contain?\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer,\n",
        "                   max_new_tokens = 256, temperature = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRrr--20Udm9"
      },
      "source": [
        "The model learns about the research paper!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2strt31SUc5W",
        "outputId": "3359dc6a-f533-4960-a875-400af205e20d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Improved inference capabilities, enhanced model robustness, and the ability to scale while maintaining a fixed-inference budget<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"What are some benefits of the BLT?\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer,\n",
        "                   max_new_tokens = 256, temperature = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upcOlWe7A1vc",
        "outputId": "b74c98e2-3909-46ff-f4c2-9ad838c7021b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('lora_model/tokenizer_config.json',\n",
              " 'lora_model/special_tokens_map.json',\n",
              " 'lora_model/tokenizer.json')"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"lora_model\")  # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model\")\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKX_XKs_BNZR",
        "outputId": "93cafd03-c9f7-4fdf-d031-f81e3497a839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It dynamically groups bytes into patches preserving access to the byte-level information<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "if False:\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"What is so special about BLT's tokenization?\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer,\n",
        "                   max_new_tokens = 256, temperature = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f422JgM9sdVT"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHjt_SMYsd3P"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False:\n",
        "    model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: # Change to True to upload finetune\n",
        "    model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False:\n",
        "    model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: # Change to True to upload finetune\n",
        "    model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False:\n",
        "    model.save_pretrained(\"model\")\n",
        "    tokenizer.save_pretrained(\"model\")\n",
        "if False: # Change to True to upload finetune\n",
        "    model.push_to_hub(\"hf/model\", token = \"\")\n",
        "    tokenizer.push_to_hub(\"hf/model\", token = \"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv4vXHd61i7"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqfebeAdT073"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False:\n",
        "    model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "if False: # Change to True to upload finetune\n",
        "    model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False:\n",
        "    model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: # Change to True to upload finetune\n",
        "    model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False:\n",
        "    model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: # Change to True to upload finetune\n",
        "    model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVlK2u7LZhku"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp.\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Train your own reasoning model - Llama GRPO notebook [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ‚≠êÔ∏è <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠êÔ∏è\n",
        "\n",
        "  This notebook and all Unsloth notebooks are licensed [LGPL-3.0](https://github.com/unslothai/notebooks?tab=LGPL-3.0-1-ov-file#readme).\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "353c0192acd14733b204f60f8e58e993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c65910c8f3e64093bcca693c973d9ad8",
              "IPY_MODEL_cee18c6ba58247d69668557140f79ca6",
              "IPY_MODEL_a441ed21d5344803b48aa006b5b434a0"
            ],
            "layout": "IPY_MODEL_e4ca34c26aac4b02bedaba48864cff8b"
          }
        },
        "c65910c8f3e64093bcca693c973d9ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4e0e1dd00584521b490bc3a785bc82f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_24fbfbc731c54458841f3e7835e3e49c",
            "value": "Map:‚Äá100%"
          }
        },
        "cee18c6ba58247d69668557140f79ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdff6d335fa94ee5921f1757ff3e1d86",
            "max": 2249,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_629b8655f9494d59ba509a899ff4c35c",
            "value": 2249
          }
        },
        "a441ed21d5344803b48aa006b5b434a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b89c6083b30423885e3f02b1a57c02b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8623f631297c4eff90628aef401b0167",
            "value": "‚Äá2249/2249‚Äá[00:00&lt;00:00,‚Äá10162.01‚Äáexamples/s]"
          }
        },
        "e4ca34c26aac4b02bedaba48864cff8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4e0e1dd00584521b490bc3a785bc82f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24fbfbc731c54458841f3e7835e3e49c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdff6d335fa94ee5921f1757ff3e1d86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "629b8655f9494d59ba509a899ff4c35c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b89c6083b30423885e3f02b1a57c02b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8623f631297c4eff90628aef401b0167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35f9a1e5ecfc45129f9b86609423fe47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94e582fee0554361b748d7b047fff64f",
              "IPY_MODEL_e83d1fc99f384ccd890b67434d7fb98f",
              "IPY_MODEL_215a3eff14c840619bd41a0860bf7ea5"
            ],
            "layout": "IPY_MODEL_cf33c70598a948569ee2859a4fbb8411"
          }
        },
        "94e582fee0554361b748d7b047fff64f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa455b87214b483a9135722900d23054",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_53a5b46695f24586a40faf669a3ef8a8",
            "value": "Unsloth:‚ÄáTokenizing‚Äá[&quot;text&quot;]‚Äá(num_proc=6):‚Äá100%"
          }
        },
        "e83d1fc99f384ccd890b67434d7fb98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d2fa83330ab4d888221188034e32979",
            "max": 2249,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c628a4775a08496d9e5ad6b58b488e9f",
            "value": 2249
          }
        },
        "215a3eff14c840619bd41a0860bf7ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b07ac94208844d3cb9e52cbcd6186c0a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_119ac18c854c4856852656ea8b1b9200",
            "value": "‚Äá2249/2249‚Äá[00:08&lt;00:00,‚Äá475.94‚Äáexamples/s]"
          }
        },
        "cf33c70598a948569ee2859a4fbb8411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa455b87214b483a9135722900d23054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53a5b46695f24586a40faf669a3ef8a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d2fa83330ab4d888221188034e32979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c628a4775a08496d9e5ad6b58b488e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b07ac94208844d3cb9e52cbcd6186c0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "119ac18c854c4856852656ea8b1b9200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}